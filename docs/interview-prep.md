# 面接準備: 想定質問と回答集

> Argus プロジェクトをベースにした AI エンジニア面接対策
> 各回答は口頭で1〜3分を想定

---

## 目次

1. [プロジェクト概要](#1-プロジェクト概要)
2. [技術的深掘り](#2-技術的深掘り)
3. [AI/LLM 関連](#3-aillm-関連)
4. [設計判断](#4-設計判断)
5. [課題と解決](#5-課題と解決)
6. [チーム・プロセス](#6-チームプロセス)
7. [弱みへの対策](#7-弱みへの対策)
8. [企業別対策](#8-企業別対策)
9. [パーソナル・キャリア](#9-パーソナルキャリア)

---

## 1. プロジェクト概要

### Q1: Argus とは何ですか？一言で説明してください。

**回答:**

Argus は、Claude Agent SDK を中核にしたマルチエージェントシステムです。Slack をインターフェースとして、自然言語でタスク実行・リサーチ・SNSコンテンツ生成を行います。Railway VPS 上で24時間稼働し、全エージェントの行動を Hook ベースで記録する Observation-First アーキテクチャを採用しています。

TypeScript の pnpm monorepo で、12パッケージ、1,165以上のテスト、18の DB テーブルで構成されています。

---

### Q2: なぜこのプロジェクトを作ったのですか？

**回答（STAR）:**

- **Situation**: AI エージェントの実用化が急速に進む中、「動くデモ」はたくさんあるが「本番運用に耐えるシステム」はまだ少ないと感じていました。
- **Task**: AI エージェントを24時間稼働させる際に必要な設計判断 — 観測可能性、障害復旧、コスト管理、人間の介入ポイント — を体系的に解決するシステムを作ることにしました。
- **Action**: Claude Agent SDK のリリースをきっかけに、CLI プロセス起動方式から SDK ベースに全面移行。Hook によるツール実行記録、MCP によるナレッジ統合、Episodic Memory による自己改善を段階的に実装しました。
- **Result**: Slack から自然言語で指示するだけで、タスク実行・リサーチ・SNS投稿まで一貫して処理できるシステムが完成。10プラットフォームへの自動投稿パイプラインや、自律的な Inbox Agent まで発展しました。

---

### Q3: このプロジェクトの一番の技術的チャレンジは何でしたか？

**回答:**

「AIエージェントの行動を信頼するのではなく、検証可能にする」という設計思想を一貫させることです。

具体的には、SDK が `success: true` を返しても、レスポンステキストに「失敗しました」「エラー」などのパターンがあれば失敗として扱う `detectTaskFailure()` のような仕組みが必要でした。AIの出力をそのまま信頼すると、静かに失敗するケースが頻出します。

また、全ツール実行を Hook で記録し、後から「何が起きたか」を再構成できるようにする Observation-First アーキテクチャの設計も大きなチャレンジでした。これは単にログを取るだけでなく、ツール実行の開始・終了・失敗をそれぞれ異なるタイミングで DB に書き込み、かつメインの実行フローをブロックしない設計が求められました。

---

## 2. 技術的深掘り

### Q4: アーキテクチャの全体像を説明してください。

**回答:**

3層構造です。

**アプリケーション層**として、Slack Bot（ユーザーインターフェース）、Agent Orchestrator（Cron スケジューラー + REST API）、Dashboard（Next.js 16 モニタリング UI）の3つのアプリケーションがあります。

**コア層**として、Agent Core が Claude Agent SDK をラップし、Hook 注入・セッション管理・結果正規化を担当。DB パッケージが Drizzle ORM で18テーブルを管理します。

**統合層**として、Knowledge、Personal Knowledge、Gmail、Google Calendar の4つの MCP サーバーがあり、エージェントに外部サービスへのアクセスを提供します。

全アプリケーションが Agent Core と DB を共有し、MCP サーバーはエージェントの子プロセスとして stdio で通信します。Railway VPS 上の単一 Docker コンテナ内で PM2 がプロセス管理を行い、Cloudflare Tunnel で外部公開しています。

---

### Q5: Session-per-Thread モデルについて詳しく説明してください。

**回答:**

1つの Slack スレッドが1つの Claude セッションに対応します。

新しいスレッドでは `query()` で新規セッションを作成し、DB に `sessionId` を保存します。同じスレッドへの返信は `resume()` でセッションを継続します。resume に失敗した場合は、透過的に新規 `query()` にフォールバックします。

このモデルの利点は、ユーザーが「会話の文脈」を意識せずに複数のタスクを並行して進められることです。チャンネルAのスレッドでリサーチしながら、チャンネルBのスレッドでコード生成を依頼できます。

また、Inbox Agent でも同様のパターンを使っています。タスク完了後にユーザーがスレッドでフォローアップすると、同じセッションで会話を継続できます。

---

### Q6: monorepo 構成で工夫した点は？

**回答:**

pnpm workspace を使い、`@argus/` スコープで12パッケージを管理しています。

設計上最も重視したのは**依存関係の方向性**です。アプリ → コア → 統合 の順に依存が流れ、逆方向の依存は一切ありません。例えば、Agent Core は Slack Bot の存在を知らないし、Knowledge MCP サーバーは Orchestrator の存在を知りません。

これにより、パッケージ単体でのテストが可能になり、1,165以上のテストが全て `pnpm test` 一発で実行できます。

もう一つの工夫は、共通の DB スキーマパッケージです。`@argus/db` にスキーマを集約することで、型安全なテーブルアクセスが全パッケージで保証されます。スキーマ変更は1箇所で行い、`pnpm db:push` で反映します。

---

## 3. AI/LLM 関連

### Q7: プロンプトエンジニアリングで意識していることは？

**回答:**

3つのポイントがあります。

**第一に、コンテキストの段階的開示**です。全情報をプロンプトに詰め込むのではなく、MCP サーバー経由で必要な情報を必要なときに取得させます。Knowledge の ID 参照 + オンデマンド取得がこの設計の核です。

**第二に、Episodic Memory の注入**です。`lessons` テーブルに蓄積されたエラーパターンと解決策を `formatLessonsForPrompt()` でフォーマットし、セッション開始時にプロンプトに注入します。これにより、過去に「Gmail トークンが見つからない」で失敗したなら、次回はそのツールをスキップするのではなく、トークン再取得を試みるようになります。

**第三に、intent ベースの prompt 設計**です。Inbox Agent の分類器が返す `executionPrompt` は、ユーザーの自然言語を「エージェントが実行しやすい指示」に変換したものです。「来週の火曜に会議設定して」→「Google Calendar の create_event を使って次の火曜日にイベントを作成してください」のように具体化します。

---

### Q8: エージェントのコスト管理はどうしていますか？

**回答（STAR）:**

- **Situation**: 10プラットフォームの SNS 提案を毎朝生成すると、各提案で複数回の SDK 呼び出しが発生し、コストが膨らむリスクがありました。
- **Task**: 品質を落とさずにコストを最適化する仕組みが必要でした。
- **Action**: 3つのアプローチを採用しました。
  1. **Dual-Mode Execution**: macOS + Claude CLI が存在する環境では Max Plan（ローカル実行、無料）を自動検出。本番サーバー（Linux）では API キーを使用。ローカル開発のコストをゼロにしました。
  2. **分類には安価なモデル**: Inbox Agent の意図分類には Claude Haiku を使い、実行には Sonnet/Opus を使い分けます。分類のコストは1件 $0.001 以下です。
  3. **承認ゲート**: 動画レンダリング（15〜30分）やポッドキャスト生成など、コストの高い処理は Slack の承認ボタンをゲートにして、無駄な実行を防止しています。
- **Result**: ローカル開発は実質無料、本番のランニングコストは $0.04/セッション程度に収まっています。

---

### Q9: Episodic Memory について詳しく教えてください。

**回答:**

`lessons` テーブルが Episodic Memory の実体です。

ツール実行が失敗すると、`PostToolUseFailure` Hook がエラー内容と文脈を `lessons` テーブルに記録します。例えば「Gmail API で認証エラーが発生した → トークン再取得スクリプトを実行して解決した」という情報が保存されます。

次のセッション開始時に、直近のレッスンを `formatLessonsForPrompt()` で整形し、システムプロンプトに注入します。エージェントはこの情報を参照して、同じ失敗を繰り返さないように行動を調整します。

注意点として、stale なレッスンの管理があります。「Gmail トークンが見つからない」というレッスンが残っていると、エージェントが Gmail ツール自体をスキップしてしまうケースがありました。定期的なクリーンアップが必要です。

---

## 4. 設計判断

### Q10: なぜ MCP（Model Context Protocol）を採用したのですか？

**回答（STAR）:**

- **Situation**: エージェントが Knowledge ベース、Gmail、Calendar にアクセスする必要がありました。REST API、プロンプト注入、直接 DB アクセスなど複数の選択肢がありました。
- **Task**: エージェントにとって自然なツール体験を提供しつつ、権限分離を実現する方法を選定する必要がありました。
- **Action**: MCP サーバーを採用しました。理由は3つです。
  1. **ネイティブなツール統合**: MCP ツールは Bash や Read と同じ並びでエージェントのツールパレットに表示されます。REST API を curl で呼ぶ必要がありません。
  2. **権限分離**: Collector ロールは CRUD 全操作、Executor ロールは検索のみ。MCP サーバー側でツールの可視性を制御し、サービス層でも二重チェックします。
  3. **プロセス分離**: MCP サーバーは子プロセスとして動作するため、Knowledge のメモリリークがメインプロセスに影響しません。
- **Result**: 4つの MCP サーバー（Knowledge, Personal, Gmail, Calendar）を同一パターンで実装でき、新しい外部サービス追加時も同じアーキテクチャで拡張できています。

---

### Q11: なぜ Hook ベースの観測を選んだのですか？ログ解析じゃダメですか？

**回答:**

ログ解析は「事後」の観測です。Hook ベースは「リアルタイム」の観測です。

Argus では `PreToolUse` Hook でツール実行開始時刻を DB に記録し、`PostToolUse` Hook で結果・実行時間・ステータスを書き込みます。これにより、エージェントの実行中に Slack へプログレス通知を送ることができます。ユーザーは「今エージェントが何をしているか」をリアルタイムで見られます。

ログ解析の場合、実行完了後にログファイルをパースして「何が起きたか」を復元する必要があり、リアルタイム通知は不可能です。また、ログのフォーマットが変わるたびにパーサーを修正する必要があります。

実装上の工夫として、`buildSDKHooks()` というブリッジ関数を作りました。これは Argus 独自の `ArgusHooks`（シンプルなコールバック3つ）を SDK の `HookCallbackMatcher[]` フォーマットに変換します。消費側（Slack Bot、Orchestrator）は SDK の内部仕様を知らずに、自分の観測ロジックだけ書けば良い設計です。

---

### Q12: CLI プロセス起動から Agent SDK への移行はどう進めましたか？

**回答（STAR）:**

- **Situation**: 当初は `child_process.spawn()` で `claude` CLI を起動し、stdout/stderr をパースしていました。CLI の出力フォーマットが undocumented で、バージョンアップのたびにパーサーが壊れていました。
- **Task**: SDK への移行で、3つのアプリ（Slack Bot, Orchestrator, Dashboard）に影響を出さずに内部実装を置き換える必要がありました。
- **Action**: ファサードパターンで移行しました。`agent-core` パッケージの公開 API（`query()`, `resume()`, `AgentResult`, `ArgusHooks`）は一切変えず、内部だけ SDK の `query()` AsyncGenerator に置き換えました。`consumeSDKStream()` で AsyncGenerator を `AgentResult` に正規化する変換層を挟むことで、消費側のインポートを一行も変えずに済みました。
- **Result**: 消費側3アプリのコード変更ゼロで移行完了。Hook による リアルタイム観測、型安全なメッセージ処理、安定したセッション管理を獲得しました。

---

## 5. 課題と解決

### Q13: 本番運用で最も困った問題は何ですか？

**回答（STAR）:**

- **Situation**: Slack Bot を再起動した後、一部のメッセージが古いコードで処理される問題が間欠的に発生しました。
- **Task**: 原因を特定し、再発しない仕組みを作る必要がありました。
- **Action**: 調査の結果、Slack Socket Mode が原因でした。Socket Mode は接続中の全インスタンスにメッセージをラウンドロビン配信します。新しいプロセスを起動しても、古いプロセスが kill されていないと、メッセージの半分が古いコードで処理されてしまいます。対策として、起動スクリプトに「既存プロセスの全 kill → 新規起動」のシーケンスを組み込みました。`tsx watch` の監視対象から `packages/**/dist/**` を除外し、依存パッケージのビルドで不要な再起動が発生しないようにしました。
- **Result**: 再起動時の間欠的失敗がゼロになり、24時間稼働の安定性が大幅に向上しました。

---

### Q14: Inbox Agent で「成功したのに実は失敗」というケースはどう対処しましたか？

**回答:**

SDK レベルでは `success: true` が返るのに、エージェントのレスポンス本文に「失敗しました」「できません」「認証エラー」と書いてあるケースです。

`detectTaskFailure()` 関数で、レスポンスの末尾500文字を正規表現でスキャンします。「失敗しました」「できません」「エラーが発生」「認証.*エラー」「No.*tokens? found」などのパターンにマッチしたら、タスクを failed に更新し、Slack リアクションを ❌ に変更します。

同様に `detectPendingInput()` では、レスポンス中の疑問符数をカウントし、3つ以上あればエージェントがユーザーに質問中と判断して waiting ステータスにします。

これはヒューリスティクスなので完璧ではありませんが、「静かな失敗」を大幅に減らせました。将来的には、構造化された失敗シグナルを SDK 側に提案したいと考えています。

---

### Q15: テスト戦略はどうしていますか？

**回答:**

1,165以上のテストを12パッケージに分散して管理しています。

**ユニットテスト**が中心です。各 `.ts` ファイルと同じディレクトリに `.test.ts` をコロケーションしています。DB 層は `vi.mock()` でモック、Agent Core は `fakeStream()` で SDK の AsyncGenerator をモックします。

**テストのポイント**は3つあります。

1. **SDK メッセージのモック**: `fakeStream()` で `SDKSystemMessage`, `SDKAssistantMessage`, `SDKResultSuccess` を任意の順序で流せるようにしています。`session_id` は全メッセージで一致させる必要がある（result メッセージが最後に上書きするため）といった SDK の挙動も再現します。
2. **Hook テスト**: `buildSDKHooks()` の変換が正しいことを、入力オブジェクトの型と出力コールバックの呼び出し回数で検証します。
3. **MCP サーバーテスト**: ツールハンドラーの入出力を直接テスト。ロールベースの権限（Collector/Executor）が正しく動作することを検証します。

---

## 6. チーム・プロセス

### Q16: 一人で開発して何が学べましたか？チーム開発との違いは？

**回答:**

最大の学びは「将来の自分のためにドキュメントを書く」ことの重要性です。

ADR（Architecture Decision Record）を5本書きました。各 ADR には Context（なぜその問題が存在するか）、Decision（何を選んだか）、Alternatives（何を選ばなかったか、なぜか）、Consequences（良い点・悪い点）を記載しています。

2ヶ月後に自分のコードを読み返したとき、ADR がなければ「なぜ MCP を使ったのか」「なぜ CLI 起動をやめたのか」を思い出すのに時間がかかります。特に Alternatives セクションは、「検討した上で却下した選択肢」を記録するもので、同じ議論を繰り返さないための保険です。

チーム開発との違いで言えば、レビューアーがいない分、テストとドキュメントの品質を高くする必要がありました。1,165以上のテストは「レビューアーの代わり」でもあります。

---

### Q17: 今後 Argus をどう発展させたいですか？

**回答:**

3つの方向があります。

**第一に、マルチエージェント協調**です。現在は1つのタスクに1つのエージェントが対応していますが、複雑なタスクでは複数のエージェントが協力する設計を入れたいです。例えば、リサーチエージェントが情報を集め、ライティングエージェントが記事を書き、レビューエージェントが品質チェックするパイプラインです。

**第二に、観測データの活用**です。全ツール実行が DB に記録されているので、「どのツールがよく使われるか」「どのパターンで失敗しやすいか」を分析し、エージェントの行動を最適化するフィードバックループを作りたいです。

**第三に、MCP エコシステムの拡張**です。現在4つの MCP サーバーがありますが、Notion、GitHub Issues、Jira など外部サービスをさらに統合し、エージェントの行動範囲を広げたいと考えています。

---

### Q18: （英語版）Can you describe the Observation-First architecture?

**Answer:**

Sure. The core idea is that every tool invocation by every agent is recorded to the database in real-time, not after the fact.

We use a hook-based system. When the Claude Agent SDK executes a tool — say, reading a file or searching the knowledge base — our `PreToolUse` hook fires and records the start timestamp to the `tasks` table. When the tool completes, `PostToolUse` records the result, duration, and status. If it fails, `PostToolUseFailure` captures the error and creates an entry in the `lessons` table for episodic memory.

The key design choice was to build a bridge layer called `buildSDKHooks()`. It converts our simplified `ArgusHooks` interface — which has just three callbacks — into the SDK's `HookCallbackMatcher` format. This means consumer applications like the Slack bot only need to implement simple callback functions for their observation logic, without understanding SDK internals.

The practical benefit is twofold: first, users see real-time progress in Slack threads as tools execute. Second, the dashboard can reconstruct the complete execution history of any session — which tools were called, in what order, how long each took, and whether they succeeded or failed.

---

### Q19: 技術選定で最も重要視することは何ですか？

**回答:**

**観測可能性**と**段階的な劣化**です。

Argus の設計で一貫しているのは、「何が起きたか後から分かる」ことです。エージェントは予測不可能な行動をとることがあります。だからこそ、全行動を記録し、再構成できる必要があります。

段階的な劣化とは、一部が壊れても全体が止まらない設計です。API キーがなければキーワード分類にフォールバック。resume が失敗すれば新規 query にフォールバック。CLI ヘルスチェックが失敗すれば SNS バッチをスキップ。常に「次善の策」が用意されています。

この2つは AI システムに限った話ではなく、あらゆる本番システムに適用できる原則だと考えています。

---

## 7. 弱みへの対策

### Q20: なぜ Rails ではなく TypeScript/Node.js を選んだのですか？

**回答（STAR）:**

- **Situation**: AI エージェントシステムの技術選定をする際、Rails（Ruby）と TypeScript/Node.js のどちらをベースにするかを検討しました。
- **Task**: AI SDK との親和性、型安全性、エコシステムの成熟度を基準に選定する必要がありました。
- **Action**: TypeScript/Node.js を選択した理由は3つです。
  1. **AI SDK のネイティブサポート**: Claude Agent SDK、OpenAI SDK、MCP SDK は全て TypeScript/JavaScript がファーストクラスです。Ruby 版は存在しないか、コミュニティ版で品質にばらつきがあります。AI エージェント開発では SDK との直接的な型の一致が開発速度と安全性に直結します。
  2. **フルスタックの型一貫性**: フロントエンド（Next.js/React）からバックエンド（Node.js）、DB スキーマ（Drizzle ORM）まで TypeScript で統一できます。`@argus/db` で定義した型がダッシュボードの React コンポーネントまでそのまま流れるので、API 境界での型の不一致が起きません。
  3. **AsyncGenerator / Stream 処理**: Claude SDK の `query()` は AsyncGenerator を返します。Node.js のイベントループモデルはストリーミングレスポンスの処理に最適で、`consumeSDKStream()` のような変換層を自然に書けます。
- **Result**: 12パッケージの monorepo 全体が単一の型システムで統合され、SDK の型定義をそのまま活用できています。「Rails でも作れたか」と聞かれれば作れますが、AI エージェント開発においてはTypeScript のメリットが圧倒的でした。

**補足（Rails に対するリスペクト）:**

Rails の Convention over Configuration や ActiveRecord パターンには大きな学びがあります。実際、Argus でも「設定より規約」の思想は取り入れています。例えば、MCP サーバーの実装パターンを4サーバーで統一し、新しいサーバー追加時にゼロから設計する必要がない構成にしています。

---

### Q21: 個人プロジェクトにしては規模が大きいですが、なぜですか？

**回答（STAR）:**

- **Situation**: 「AI エージェントを作ってみよう」というところから始まりましたが、本番運用を始めると次々に必要な機能が見つかりました。
- **Task**: 24時間稼働するシステムには、単なるプロトタイプでは解決できない課題群（観測可能性、障害復旧、コスト管理、権限分離）がありました。
- **Action**: 3つの要因が規模拡大を可能にしました。
  1. **AI 駆動開発**: Argus 自体の開発に AI を活用しました。Claude Code を使った TDD（RED→GREEN→REFACTOR）サイクルで、テスト作成→実装→リファクタリングを高速に回せました。スキル定義やサブエージェント委譲のワークフローを整備し、1人でも大規模な開発を維持できる体制を構築しています。
  2. **monorepo による分離統治**: 12パッケージに分割することで、各パッケージは100〜500行程度の焦点を絞ったコードになっています。個々のパッケージの複雑度は低く、全体の複合によって規模が生まれています。
  3. **段階的な成長**: 最初から12パッケージを設計したわけではありません。ADR（Architecture Decision Records）で判断を記録しながら、CLI→SDK 移行、ファイルシステム→DB 移行、単一ナレッジ→MCP 分離と段階的に進化させました。
- **Result**: 1,165以上のテストがあることで、リファクタリングやパッケージ追加時の安全性が担保され、一人でも継続的にスケールさせることができています。

---

### Q22: AI エージェントの安全性をどう担保していますか？

**回答:**

4層の安全設計を採用しています。

**第1層: 権限分離（Principle of Least Privilege）**
MCP サーバーでロールベースのアクセス制御を実装しています。Collector ロールは CRUD 全操作（5ツール）、Executor ロールは検索のみ（2ツール）。ツールの可視性を MCP サーバー側で制御し、さらにサービス層で `requireCollector()` によるダブルチェックを行います。仮にエージェントが権限外の操作を試みても、2重の壁で阻止されます。

**第2層: 行動の検証（Trust but Verify）**
`detectTaskFailure()` で SDK の `success: true` を鵜呑みにせず、レスポンス本文の失敗パターンをスキャンします。`detectPendingInput()` でエージェントが質問中かどうかを判定し、自律実行の暴走を防ぎます。

**第3層: 観測可能性（Observation-First）**
全ツール実行を `PreToolUse` / `PostToolUse` Hook で DB に記録します。「エージェントが何をしたか」は全て後から再構成可能です。ダッシュボードでリアルタイム監視でき、異常な行動パターン（同じツールの連続失敗、予期しないツール呼び出し）を検出できます。

**第4層: Human-in-the-Loop**
コストの高い操作（動画レンダリング、ポッドキャスト生成）は Slack の承認ボタンをゲートにしています。Inbox Agent の自律レベルも、タスクの分類結果に応じて「自動実行」「承認待ち」「拒否」を分岐させ、全てが自動実行されないように設計しています。

**補足（既知の限界）:**

`detectTaskFailure()` はヒューリスティクスなので完璧ではありません。構造化された失敗シグナル（SDK レベルでの成功/失敗メタデータ）が理想で、将来的には SDK への提案も検討しています。

---

## 8. 企業別対策

### LayerX（設計課題選考 + eval-driven development）

#### Q23: LayerX の PR-Agent や eval-driven development と Argus のアプローチの違いは？

**回答:**

LayerX さんが PR-Agent で取り組んでいる「コードレビューの AI 自動化」と、Argus の「エージェント行動の観測・検証」は、同じ課題の異なるレイヤーを解決しています。

PR-Agent は**コード品質**の自動検証です。diff を解析し、レビューコメントを自動生成する。Argus の Hook ベース観測は**実行品質**の自動記録です。エージェントが「何をしたか」「成功したか」を構造化データとして蓄積します。

eval-driven development との接点で言うと、Argus の `detectTaskFailure()` は一種の eval です。SDK の `success: true` を信頼せず、レスポンスの内容をパターンマッチで検証する。ただし、これはヒューリスティクスベースです。本格的な eval-driven アプローチでは、テストケースとゴールド標準を定義し、regression を定量的に検出する仕組みが必要です。Argus の `lessons` テーブルに蓄積された失敗パターンは、eval データセットの原型と見ることもできます。

設計課題として出された場合は、「観測データから eval データセットを自動生成し、エージェントの行動品質を定量評価するパイプライン」を提案するのが自然な延長線上だと考えています。

#### Q24: 設計課題が出た場合の進め方は？

**回答:**

まず ADR（Architecture Decision Record）を書きます。Argus でも5本の ADR を作成しており、Context → Decision → Alternatives → Consequences の構造で設計判断を記録する習慣があります。

設計課題では、以下のプロセスで進めます:

1. **要件の明確化**: 制約条件（時間、スケーラビリティ要件、技術スタック）を整理
2. **3つのアプローチを比較**: それぞれの Trade-off を図示（例: 整合性 vs 可用性、コスト vs レイテンシ）
3. **プロトタイプコードで説明**: 抽象的な議論ではなく、TypeScript の型定義やインターフェースで設計意図を伝える
4. **テスト戦略を含める**: その設計をどうテストするかまで提案する

---

### PKSHA（ライブコーディング + 研究発表）

#### Q25: ライブコーディングで Argus の設計力を見せるなら？

**回答:**

3つのデモ候補があります。

**候補1: MCP サーバーのライブ実装**（15分）
新しい MCP サーバー（例: Notion 連携）を一からライブコーディングする。Tool 定義 → Handler 実装 → ロールベース権限 → テストの流れで、Argus の設計パターンが再利用可能であることを示す。

**候補2: Hook ベースの観測ロジック追加**（10分）
新しい Hook（例: コスト集計 Hook）を追加する。`ArgusHooks` インターフェースにコールバックを追加し、`buildSDKHooks()` で SDK フォーマットに変換するデモ。抽象化の有効性を実演。

**候補3: AsyncGenerator のストリーム変換**（10分）
`consumeSDKStream()` と同様のパターンで、任意の AsyncGenerator を正規化する関数をライブ実装。TypeScript の型推論を活用したジェネリクス設計を見せる。

#### Q26: 7,000体の AI エージェント（PKSHA の事例）との技術的な違いは？

**回答:**

PKSHA さんの7,000体は「特定タスクに特化したエージェントの大量デプロイ」です。Argus は「汎用エージェントが MCP ツールで多様なタスクを実行する」モデルです。

スケーリングのアプローチが根本的に異なります。PKSHA は水平スケーリング（エージェント数を増やす）、Argus は垂直統合（1つのエージェントのツール数を増やす）です。

Argus のアーキテクチャを大規模化する場合の提案:
- Session-per-Thread モデルを維持しつつ、タスクキューでエージェント実行をスケールアウト
- 現在の `lessons` テーブルを共有学習ストアに拡張し、エージェント間で失敗パターンを共有
- MCP サーバーをマイクロサービス化し、エージェントプールからネットワーク経由でアクセス

---

### SmartHR（TypeScript/React 枠 + AI 開発部）

#### Q27: TypeScript/React のエンジニアとして、AI 開発にどう貢献できるか？

**回答（STAR）:**

- **Situation**: SmartHR さんが2025年8月に AI 開発部を新設されたということは、既存の TypeScript/React エコシステムに AI 機能を統合する段階だと推測します。
- **Task**: 「AI 専門家を雇う」のではなく「TypeScript エンジニアが AI を使いこなす」方が既存コードベースとの親和性が高いはずです。
- **Action**: Argus で培った3つのスキルが直接活かせます。
  1. **Claude Agent SDK の実践経験**: SDK の AsyncGenerator モデル、Hook によるイベント監視、セッション管理を本番運用レベルで実装しています。
  2. **MCP によるツール統合**: 外部サービス（Gmail、Calendar、Knowledge）を MCP サーバーとして統合した経験は、SmartHR の既存 API を AI エージェントに接続する際に直接応用できます。
  3. **安全設計**: ロールベースのアクセス制御、`detectTaskFailure()` による出力検証、Human-in-the-Loop の承認ゲートなど、AI の出力を信頼しすぎない設計思想は、人事情報を扱う SmartHR のシステムで特に重要です。
- **Result**: 「TypeScript が書けて、AI エージェントの本番運用経験がある」エンジニアとして、AI 開発部の立ち上げに貢献できると考えています。

---

### サイボウズ（OSS 文化 + kintone + 生成 AI）

#### Q28: OSS 文化やチーム開発をどう考えていますか？

**回答:**

サイボウズさんの「チームワークあふれる社会を創る」というミッションに強く共感します。

Argus は個人プロジェクトですが、「未来の自分や他者が理解できる設計」を一貫して重視しています。具体的には:

- **ADR 5本**: 設計判断を Context → Decision → Alternatives → Consequences で記録。「なぜ MCP を選んだのか」「なぜ CLI から SDK に移行したのか」を後から辿れます。
- **1,165以上のテスト**: 「コードの意図をテストで伝える」思想。テストがドキュメント代わりになっています。
- **CLAUDE.md によるオンボーディング**: プロジェクトのルール・規約・アーキテクチャを構造化して記述。新しいコントリビューター（AIエージェント含む）が迷わずに開発を始められる設計です。

サイボウズさんが新人研修資料を毎年全公開されているのは「知識の共有がチーム力を高める」という信念の表れだと思います。Argus の Episodic Memory（`lessons` テーブル）も同じ思想です — エージェントの失敗と学びを組織の知識として蓄積し、次の実行に活かす。

OSS コントリビューションの経験としては、Argus の設計パターン（Hook ベース観測、MCP 権限分離、SDK ファサード）を記事やブログで公開する予定で、コミュニティへの還元を意識しています。

---

### note（シニア職 + LLM/推薦/ベクトル検索）

#### Q29: LLM やベクトル検索の実装経験は？

**回答:**

Argus の Knowledge MCP サーバーで、LLM とベクトル検索に近い設計を実践しています。

**Knowledge の検索アーキテクチャ:**
- `search` ツールがクエリを受け取り、PostgreSQL の `text` 型フィールドに対して全文検索を実行
- タグベースのフィルタリング + テキスト検索の組み合わせで、セマンティックな意図をカバー
- 将来的には pgvector による埋め込みベクトル検索を導入予定（スキーマに embedding カラムを追加する設計は準備済み）

**Episodic Memory の推薦的要素:**
- `lessons` テーブルの蓄積データを `formatLessonsForPrompt()` で関連度順にフィルタし、セッション開始時にプロンプトに注入
- これは「過去の類似失敗パターンをレコメンドする」仕組みであり、推薦システムのコンセプトに近いです

**正直な限界:**
本格的なベクトル検索（FAISS, Pinecone, Weaviate）や大規模推薦システムの本番運用経験はまだありません。ただし、PostgreSQL ベースのデータモデル設計、TypeScript での API 実装、MCP プロトコルによるツール統合の経験は、ベクトル検索基盤の上層実装に直接活かせます。

---

## 9. パーソナル・キャリア

> 既存の個人面接Q&A（interview_episodes.md）から抽出・統合。
> 回答は「結論→理由Nつ→1つずつ深掘り」の型で統一。

### Q30: なぜエンジニアになりたいのですか？

**回答:**

理由は2つあります。1つ目は、提案だけで終わらせず、実際に「動くもの」として形にできるのがエンジニアだと思ったからです。2つ目は、自分の性格として、考えるだけでなく手を動かして仕組みを作り切る方がやりがいを感じるからです。

コンサルのように「こうしたらいい」と示すことも重要ですが、私は最終的に成果として残る形まで持っていきたいので、エンジニアを選びました。

---

### Q31: なぜAI駆動開発の会社を志望するのですか？

**回答:**

理由は2つあります。1つ目は、実務を通じて「AIに任せられる範囲が急速に広がっている」と実感しており、開発の前提が変わっていると感じているからです。2つ目は、その最前線の環境で経験を積むことで、自分の成長速度と成果の質を上げられると考えているからです。

根拠としては、1年間の実務でAIに任せられる範囲がどんどん広がっていることを体感しており、新機能追加の際の要件の叩き上げなど、上流の思考の質までAIで上がる手応えがあります。

---

### Q32: フルリモートがいい理由は？

**回答:**

理由は2つあります。1つ目は、集中して実装に没頭でき、任された期間内で成果を出しやすいからです（自宅に3画面やスタンディングデスクを整備済み）。2つ目は、通勤時間を仕事や学習に充てて、成長と成果に直結させたいからです。

出社のメリット（非言語コミュニケーション、雑談からの関係構築、意思決定速度）は認識しています。だからこそリモートでは、目線をカメラに向ける、文章や図で共有して認識を揃える、区切りで「ここまで大丈夫ですか？」と確認する、といった工夫を意識しています。

---

### Q33: ガクチカ — テレアポで常に1位だった話

**回答（STAR）:**

- **Situation**: 大学時代、人見知り克服とコミュニケーション力向上のため、蓄電池販売のテレアポのアルバイトを始めました。
- **Task**: 成果を上げつつ、限られた稼働時間で効率的に働く必要がありました。
- **Action**: 3つのことを行いました。
  1. 成果を出している先輩のやり方を徹底的に観察して"型"を真似た
  2. 真似して終わりにせず、自分の結果を記録して改善を回した
  3. 断られるパターンを分析し「断られる前に対処する」スクリプトに改善した
- **Result**: 常にチーム内1位を維持。作成したスクリプトをチームに共有し、新人教育にも活用。チーム全体の月間アポ獲得数が約1.3倍に向上（約120件→約155件）。

---

### Q34: 転職理由は何ですか？

**回答:**

理由は2つあります。1つ目は、AI駆動開発を組織として本格的に取り入れている環境で経験を積みたいからです。現職では個人レベルでClaude Codeを活用していますが、組織全体としてはまだ浸透途中です。2つ目は、将来のキャリアの伸びしろを見据えた選択をしたいからです。

現職には大きく感謝しています。社会人1年目として、メール・電話対応からチーム開発のお作法、コードレビューまで教えていただきました。その基礎があるからこそ、次のステップとしてAI駆動開発の最前線で成長したいと考えています。

---

### Q35: 浪人・留年について教えてください

**回答（浪人）:**

九州工業大学に行きたかったのですが現役では不合格で、諦めきれず1年浪人して合格しました。こだわった理由は3つあります。1つ目は国立なので学費負担を抑えられること、2つ目は情報工学に特化したカリキュラムで専門を体系的に学べること、3つ目は就職実績も含めて「情報で勝負する」土台が作れることです。

**回答（留年）:**

正直に申し上げると、大学1〜2年の頃は学業よりバイトに時間を取られすぎて、単位を落としてしまいました。原因は2つあります。1つ目は、卒業に必要な単位を逆算して履修計画を立てていなかったこと。2つ目は、バイトと学業の優先順位の線引きが曖昧だったことです。

この経験から「目標から逆算して優先順位をつける」重要性を痛感し、以降は計画的に行動するようになりました。休学期間中はAIのインターンや営業のアルバイトに取り組み、E資格カリキュラム完走やテレアポ1位という成果にも繋げられました。

---

### Q36: 強みと弱みを教えてください

**回答（強み）:**

「観察→分析→仕組み化」のサイクルを回せることです。テレアポでは先輩のやり方を観察してスクリプトを改善し、Argusでは全ツール実行をHookで記録して改善データを蓄積する仕組みを作りました。

**回答（弱み）:**

自分が理解できない状態が続くとストレスを感じます。説明が曖昧だったり前提が違うまま進んだりすると、解消したくなります。対処として、原因の仮説を立てて言語化し、解消のための具体的な行動を取るようにしています。じっと我慢するより、行動で現状を変えるタイプです。

---

### Q37: 「またすぐ辞めるのでは？」という懸念にどう答えますか？

**回答:**

同じ失敗を繰り返すつもりはありません。ポイントは2つあります。

1つ目は、新卒のときは正直、将来を十分に見据えられていなかったことを自覚していて、今回はAI駆動開発の動向、会社の評価制度、将来性まで調べたうえで転職活動をしていることです。2つ目は、一つの会社で長く働くことで得られる成長や信頼があると考えており、腰を据えて成果を出すつもりだということです。

---

### Q38: 5年後はどうなっていたいですか？

**回答:**

3段階で考えています。

**1年後**: チームの戦力として、AI駆動開発のプラクティスを実務で確立し、周囲にも共有できるレベルになりたいです。

**3年後**: アーキテクチャ設計やテックリードの役割を担い、AI×ソフトウェアの設計判断ができるエンジニアになりたいです。

**5年後**: 新規プロダクトやAI機能の立ち上げをリードできる存在になりたいです。技術選定からチーム構築、品質担保まで一貫して携われるエンジニアが目標です。

---

## 付録: 数字で語れるポイント

| 指標                       | 数値                                      |
| -------------------------- | ----------------------------------------- |
| テスト数                   | 1,165+                                    |
| パッケージ数               | 12                                        |
| DB テーブル数              | 18                                        |
| MCP サーバー数             | 4（Knowledge, Personal, Gmail, Calendar） |
| SNS プラットフォーム数     | 10                                        |
| ADR 数                     | 5                                         |
| 稼働時間                   | 24/7（Railway VPS）                       |
| SDK 移行時の消費側変更     | 0行                                       |
| Inbox Agent 最大並列数     | 3                                         |
| Deep Research タイムアウト | 30分                                      |
