# Argus 面接完全ガイド

> Argus プロジェクトをベースにした AI エンジニア面接対策の統合ドキュメント
> 各回答は口頭で1〜3分を想定

---

## 目次

- [エレベーターピッチ](#エレベーターピッチ)
- [数値テーブル](#数値テーブル)
- [自己紹介テンプレート](#自己紹介テンプレート)
- **Part 1**: [技術・設計 Q&A (Q1-Q22)](#part-1-技術設計-qa-q1-q22)
- **Part 2**: [エンタープライズ・品質 Q&A (Q23-Q29)](#part-2-エンタープライズ品質-qa-q23-q29)
- **Part 3**: [キャリア・パーソナル Q&A (Q30-Q38)](#part-3-キャリアパーソナル-qa-q30-q38)
- **Part 4**: [個人エピソード詳細](#part-4-個人エピソード詳細)
- **Appendix A**: [コードベース Q&A](#appendix-a-コードベース-qa)
- **Appendix B**: [技術スタック Q&A](#appendix-b-技術スタック-qa)
- **Appendix C**: [FAQ](#appendix-c-faq)
- **Appendix D**: [改善ポイント](#appendix-d-改善ポイント)

---

## エレベーターピッチ

### 15秒版

> 「Argus は、AI エージェントの運用を自動化するシステムです。Slack から指示を出すと Claude が自律的にタスクを実行し、その過程を全て記録・可視化します。」

### 30秒版

> 「個人で運用している AI エージェントシステムで、Slack Bot、管理ダッシュボード、スケジューラーの3つのアプリと9つの共有パッケージで構成されています。Claude Agent SDK を使ってエージェントを実行し、MCP サーバーで Gmail やカレンダーと連携します。monorepo 設計で型安全性を保ちながら、1,165以上のテストで品質を担保しています。」

### 2分版

> 「Argus は、Claude Agent SDK を中核にしたマルチエージェントシステムです。Slack をインターフェースとして、自然言語でタスク実行・リサーチ・SNSコンテンツ生成を行います。Railway VPS 上で24時間稼働し、全エージェントの行動を Hook ベースで記録する Observation-First アーキテクチャを採用しています。
>
> TypeScript の pnpm monorepo で、12パッケージ、1,165以上のテスト、17の DB テーブルで構成されています。特に力を入れたのは、Claude Agent SDK の統合と MCP によるツール拡張の疎結合設計です。最初は CLI ラッパーで実装していましたが、安定性の問題から SDK に移行する判断をし、公開 API を変えずに内部実装を差し替えました。
>
> AI を「使う」だけでなく、「AI の生産性を最大化するワークフロー」を設計することに興味があり、CLAUDE.md やスキル定義によるコンテキストエンジニアリングも実践しています。」

---

## 数値テーブル

| 指標                       | 数値                                      |
| -------------------------- | ----------------------------------------- |
| テスト数                   | 1,165+                                    |
| パッケージ数               | 12（3 apps + 9 packages）                 |
| DB テーブル数              | 17                                        |
| MCP サーバー数             | 4（Knowledge, Personal, Gmail, Calendar） |
| SNS プラットフォーム数     | 10                                        |
| ADR 数                     | 5                                         |
| 稼働時間                   | 24/7（Railway VPS）                       |
| SDK 移行時の消費側変更     | 0行                                       |
| Inbox Agent 最大並列数     | 3                                         |
| Deep Research タイムアウト | 30分                                      |
| 開発期間                   | 約3ヶ月（2025年12月〜）                   |
| デプロイ環境               | Railway VPS + Cloudflare Tunnel + Access  |

---

## 自己紹介テンプレート

### 2分版

> 九州工業大学情報工学科を2025年3月に卒業し、約1年の実務経験があります。
>
> 技術スタックは TypeScript、React、Next.js、Node.js が中心で、個人開発として「Argus」という AI エージェント運用システムを作っています。
>
> Argus は Slack から指示を出すと Claude が自律的にタスクを実行するシステムで、12パッケージの pnpm monorepo、1,165以上のテストケース、4つの MCP サーバーで構成されています。
>
> 特に力を入れたのは、Claude Agent SDK の統合と MCP によるツール拡張の疎結合設計です。最初は CLI ラッパーで実装していましたが、安定性の問題から SDK に移行する判断をし、公開 API を変えずに内部実装を差し替えました。
>
> AI を「使う」だけでなく、「AI の生産性を最大化するワークフロー」を設計することに興味があり、CLAUDE.md やスキル定義によるコンテキストエンジニアリングも実践しています。
>
> 御社の[事業/技術]に、この経験を活かして貢献したいと考えています。

### 5つのストーリー（深掘り用）

1. **CLI→SDK 移行**: CLI パーサーが壊れた経験から SDK に移行。公開 API を変えずに内部実装を差し替え、消費側3アプリのコード変更ゼロで完了
2. **Observation-First**: 全ツール実行を Hook で DB に記録。リアルタイム進捗通知と事後の実行再構成を実現
3. **MCP 権限分離**: Collector/Executor ロールで最小権限を実現。4つの MCP サーバーを同一パターンで実装
4. **Episodic Memory**: `lessons` テーブルに失敗パターンを蓄積。次回セッションで同じ失敗を回避する自己改善の仕組み
5. **Dual-Mode Execution**: macOS では Max Plan（無料）、Linux サーバーでは API キーを自動切り替え。開発コストをゼロに

---

## Part 1: 技術・設計 Q&A (Q1-Q22)

### 1. プロジェクト概要

#### Q1: Argus とは何ですか？一言で説明してください。

**回答:**

Argus は、Claude Agent SDK を中核にしたマルチエージェントシステムです。Slack をインターフェースとして、自然言語でタスク実行・リサーチ・SNSコンテンツ生成を行います。Railway VPS 上で24時間稼働し、全エージェントの行動を Hook ベースで記録する Observation-First アーキテクチャを採用しています。

TypeScript の pnpm monorepo で、12パッケージ、1,165以上のテスト、17の DB テーブルで構成されています。

---

#### Q2: なぜこのプロジェクトを作ったのですか？

**回答（STAR）:**

- **Situation**: AI エージェントの実用化が急速に進む中、「動くデモ」はたくさんあるが「本番運用に耐えるシステム」はまだ少ないと感じていました。
- **Task**: AI エージェントを24時間稼働させる際に必要な設計判断 — 観測可能性、障害復旧、コスト管理、人間の介入ポイント — を体系的に解決するシステムを作ることにしました。
- **Action**: Claude Agent SDK のリリースをきっかけに、CLI プロセス起動方式から SDK ベースに全面移行。Hook によるツール実行記録、MCP によるナレッジ統合、Episodic Memory による自己改善を段階的に実装しました。
- **Result**: Slack から自然言語で指示するだけで、タスク実行・リサーチ・SNS投稿まで一貫して処理できるシステムが完成。10プラットフォームへの自動投稿パイプラインや、自律的な Inbox Agent まで発展しました。

---

#### Q3: このプロジェクトの一番の技術的チャレンジは何でしたか？

**回答:**

「AIエージェントの行動を信頼するのではなく、検証可能にする」という設計思想を一貫させることです。

具体的には、SDK が `success: true` を返しても、レスポンステキストに「失敗しました」「エラー」などのパターンがあれば失敗として扱う `detectTaskFailure()` のような仕組みが必要でした。AIの出力をそのまま信頼すると、静かに失敗するケースが頻出します。

また、全ツール実行を Hook で記録し、後から「何が起きたか」を再構成できるようにする Observation-First アーキテクチャの設計も大きなチャレンジでした。これは単にログを取るだけでなく、ツール実行の開始・終了・失敗をそれぞれ異なるタイミングで DB に書き込み、かつメインの実行フローをブロックしない設計が求められました。

---

### 2. 技術的深掘り

#### Q4: アーキテクチャの全体像を説明してください。

**回答:**

3層構造です。

**アプリケーション層**として、Slack Bot（ユーザーインターフェース）、Agent Orchestrator（Cron スケジューラー + REST API）、Dashboard（Next.js 16 モニタリング UI）の3つのアプリケーションがあります。

**コア層**として、Agent Core が Claude Agent SDK をラップし、Hook 注入・セッション管理・結果正規化を担当。DB パッケージが Drizzle ORM で17テーブルを管理します。

**統合層**として、Knowledge、Personal Knowledge、Gmail、Google Calendar の4つの MCP サーバーがあり、エージェントに外部サービスへのアクセスを提供します。

全アプリケーションが Agent Core と DB を共有し、MCP サーバーはエージェントの子プロセスとして stdio で通信します。Railway VPS 上の単一 Docker コンテナ内で PM2 がプロセス管理を行い、Cloudflare Tunnel で外部公開しています。

---

#### Q5: Session-per-Thread モデルについて詳しく説明してください。

**回答:**

1つの Slack スレッドが1つの Claude セッションに対応します。

新しいスレッドでは `query()` で新規セッションを作成し、DB に `sessionId` を保存します。同じスレッドへの返信は `resume()` でセッションを継続します。resume に失敗した場合は、透過的に新規 `query()` にフォールバックします。

このモデルの利点は、ユーザーが「会話の文脈」を意識せずに複数のタスクを並行して進められることです。チャンネルAのスレッドでリサーチしながら、チャンネルBのスレッドでコード生成を依頼できます。

また、Inbox Agent でも同様のパターンを使っています。タスク完了後にユーザーがスレッドでフォローアップすると、同じセッションで会話を継続できます。

---

#### Q6: monorepo 構成で工夫した点は？

**回答:**

pnpm workspace を使い、`@argus/` スコープで12パッケージを管理しています。

設計上最も重視したのは**依存関係の方向性**です。アプリ → コア → 統合 の順に依存が流れ、逆方向の依存は一切ありません。例えば、Agent Core は Slack Bot の存在を知らないし、Knowledge MCP サーバーは Orchestrator の存在を知りません。

これにより、パッケージ単体でのテストが可能になり、1,165以上のテストが全て `pnpm test` 一発で実行できます。

もう一つの工夫は、共通の DB スキーマパッケージです。`@argus/db` にスキーマを集約することで、型安全なテーブルアクセスが全パッケージで保証されます。スキーマ変更は1箇所で行い、`pnpm db:push` で反映します。

---

### 3. AI/LLM 関連

#### Q7: プロンプトエンジニアリングで意識していることは？

**回答:**

3つのポイントがあります。

**第一に、コンテキストの段階的開示**です。全情報をプロンプトに詰め込むのではなく、MCP サーバー経由で必要な情報を必要なときに取得させます。Knowledge の ID 参照 + オンデマンド取得がこの設計の核です。

**第二に、Episodic Memory の注入**です。`lessons` テーブルに蓄積されたエラーパターンと解決策を `formatLessonsForPrompt()` でフォーマットし、セッション開始時にプロンプトに注入します。これにより、過去に「Gmail トークンが見つからない」で失敗したなら、次回はそのツールをスキップするのではなく、トークン再取得を試みるようになります。

**第三に、intent ベースの prompt 設計**です。Inbox Agent の分類器が返す `executionPrompt` は、ユーザーの自然言語を「エージェントが実行しやすい指示」に変換したものです。「来週の火曜に会議設定して」→「Google Calendar の create_event を使って次の火曜日にイベントを作成してください」のように具体化します。

---

#### Q8: エージェントのコスト管理はどうしていますか？

**回答（STAR）:**

- **Situation**: 10プラットフォームの SNS 提案を毎朝生成すると、各提案で複数回の SDK 呼び出しが発生し、コストが膨らむリスクがありました。
- **Task**: 品質を落とさずにコストを最適化する仕組みが必要でした。
- **Action**: 3つのアプローチを採用しました。
  1. **Dual-Mode Execution**: macOS + Claude CLI が存在する環境では Max Plan（ローカル実行、無料）を自動検出。本番サーバー（Linux）では API キーを使用。ローカル開発のコストをゼロにしました。
  2. **分類には安価なモデル**: Inbox Agent の意図分類には Claude Haiku を使い、実行には Sonnet/Opus を使い分けます。分類のコストは1件 $0.001 以下です。
  3. **承認ゲート**: 動画レンダリング（15〜30分）やポッドキャスト生成など、コストの高い処理は Slack の承認ボタンをゲートにして、無駄な実行を防止しています。
- **Result**: ローカル開発は実質無料、本番のランニングコストは $0.04/セッション程度に収まっています。

---

#### Q9: Episodic Memory について詳しく教えてください。

**回答:**

`lessons` テーブルが Episodic Memory の実体です。

ツール実行が失敗すると、`PostToolUseFailure` Hook がエラー内容と文脈を `lessons` テーブルに記録します。例えば「Gmail API で認証エラーが発生した → トークン再取得スクリプトを実行して解決した」という情報が保存されます。

次のセッション開始時に、直近のレッスンを `formatLessonsForPrompt()` で整形し、システムプロンプトに注入します。エージェントはこの情報を参照して、同じ失敗を繰り返さないように行動を調整します。

注意点として、stale なレッスンの管理があります。「Gmail トークンが見つからない」というレッスンが残っていると、エージェントが Gmail ツール自体をスキップしてしまうケースがありました。定期的なクリーンアップが必要です。

---

### 4. 設計判断

#### Q10: なぜ MCP（Model Context Protocol）を採用したのですか？

**回答（STAR）:**

- **Situation**: エージェントが Knowledge ベース、Gmail、Calendar にアクセスする必要がありました。REST API、プロンプト注入、直接 DB アクセスなど複数の選択肢がありました。
- **Task**: エージェントにとって自然なツール体験を提供しつつ、権限分離を実現する方法を選定する必要がありました。
- **Action**: MCP サーバーを採用しました。理由は3つです。
  1. **ネイティブなツール統合**: MCP ツールは Bash や Read と同じ並びでエージェントのツールパレットに表示されます。REST API を curl で呼ぶ必要がありません。
  2. **権限分離**: Collector ロールは CRUD 全操作、Executor ロールは検索のみ。MCP サーバー側でツールの可視性を制御し、サービス層でも二重チェックします。
  3. **プロセス分離**: MCP サーバーは子プロセスとして動作するため、Knowledge のメモリリークがメインプロセスに影響しません。
- **Result**: 4つの MCP サーバー（Knowledge, Personal, Gmail, Calendar）を同一パターンで実装でき、新しい外部サービス追加時も同じアーキテクチャで拡張できています。

---

#### Q11: なぜ Hook ベースの観測を選んだのですか？ログ解析じゃダメですか？

**回答:**

ログ解析は「事後」の観測です。Hook ベースは「リアルタイム」の観測です。

Argus では `PreToolUse` Hook でツール実行開始時刻を DB に記録し、`PostToolUse` Hook で結果・実行時間・ステータスを書き込みます。これにより、エージェントの実行中に Slack へプログレス通知を送ることができます。ユーザーは「今エージェントが何をしているか」をリアルタイムで見られます。

ログ解析の場合、実行完了後にログファイルをパースして「何が起きたか」を復元する必要があり、リアルタイム通知は不可能です。また、ログのフォーマットが変わるたびにパーサーを修正する必要があります。

実装上の工夫として、`buildSDKHooks()` というブリッジ関数を作りました。これは Argus 独自の `ArgusHooks`（シンプルなコールバック3つ）を SDK の `HookCallbackMatcher[]` フォーマットに変換します。消費側（Slack Bot、Orchestrator）は SDK の内部仕様を知らずに、自分の観測ロジックだけ書けば良い設計です。

---

#### Q12: CLI プロセス起動から Agent SDK への移行はどう進めましたか？

**回答（STAR）:**

- **Situation**: 当初は `child_process.spawn()` で `claude` CLI を起動し、stdout/stderr をパースしていました。CLI の出力フォーマットが undocumented で、バージョンアップのたびにパーサーが壊れていました。
- **Task**: SDK への移行で、3つのアプリ（Slack Bot, Orchestrator, Dashboard）に影響を出さずに内部実装を置き換える必要がありました。
- **Action**: ファサードパターンで移行しました。`agent-core` パッケージの公開 API（`query()`, `resume()`, `AgentResult`, `ArgusHooks`）は一切変えず、内部だけ SDK の `query()` AsyncGenerator に置き換えました。`consumeSDKStream()` で AsyncGenerator を `AgentResult` に正規化する変換層を挟むことで、消費側のインポートを一行も変えずに済みました。
- **Result**: 消費側3アプリのコード変更ゼロで移行完了。Hook による リアルタイム観測、型安全なメッセージ処理、安定したセッション管理を獲得しました。

---

### 5. 課題と解決

#### Q13: 本番運用で最も困った問題は何ですか？

**回答（STAR）:**

- **Situation**: Slack Bot を再起動した後、一部のメッセージが古いコードで処理される問題が間欠的に発生しました。
- **Task**: 原因を特定し、再発しない仕組みを作る必要がありました。
- **Action**: 調査の結果、Slack Socket Mode が原因でした。Socket Mode は接続中の全インスタンスにメッセージをラウンドロビン配信します。新しいプロセスを起動しても、古いプロセスが kill されていないと、メッセージの半分が古いコードで処理されてしまいます。対策として、起動スクリプトに「既存プロセスの全 kill → 新規起動」のシーケンスを組み込みました。`tsx watch` の監視対象から `packages/**/dist/**` を除外し、依存パッケージのビルドで不要な再起動が発生しないようにしました。
- **Result**: 再起動時の間欠的失敗がゼロになり、24時間稼働の安定性が大幅に向上しました。

---

#### Q14: Inbox Agent で「成功したのに実は失敗」というケースはどう対処しましたか？

**回答:**

SDK レベルでは `success: true` が返るのに、エージェントのレスポンス本文に「失敗しました」「できません」「認証エラー」と書いてあるケースです。

`detectTaskFailure()` 関数で、レスポンスの末尾500文字を正規表現でスキャンします。「失敗しました」「できません」「エラーが発生」「認証.*エラー」「No.*tokens? found」などのパターンにマッチしたら、タスクを failed に更新し、Slack リアクションを変更します。

同様に `detectPendingInput()` では、レスポンス中の疑問符数をカウントし、3つ以上あればエージェントがユーザーに質問中と判断して waiting ステータスにします。

これはヒューリスティクスなので完璧ではありませんが、「静かな失敗」を大幅に減らせました。将来的には、構造化された失敗シグナルを SDK 側に提案したいと考えています。

---

#### Q15: テスト戦略はどうしていますか？

**回答:**

1,165以上のテストを12パッケージに分散して管理しています。

**ユニットテスト**が中心です。各 `.ts` ファイルと同じディレクトリに `.test.ts` をコロケーションしています。DB 層は `vi.mock()` でモック、Agent Core は `fakeStream()` で SDK の AsyncGenerator をモックします。

**テストのポイント**は3つあります。

1. **SDK メッセージのモック**: `fakeStream()` で `SDKSystemMessage`, `SDKAssistantMessage`, `SDKResultSuccess` を任意の順序で流せるようにしています。`session_id` は全メッセージで一致させる必要がある（result メッセージが最後に上書きするため）といった SDK の挙動も再現します。
2. **Hook テスト**: `buildSDKHooks()` の変換が正しいことを、入力オブジェクトの型と出力コールバックの呼び出し回数で検証します。
3. **MCP サーバーテスト**: ツールハンドラーの入出力を直接テスト。ロールベースの権限（Collector/Executor）が正しく動作することを検証します。

---

### 6. チーム・プロセス

#### Q16: 一人で開発して何が学べましたか？チーム開発との違いは？

**回答:**

最大の学びは「将来の自分のためにドキュメントを書く」ことの重要性です。

ADR（Architecture Decision Record）を5本書きました。各 ADR には Context（なぜその問題が存在するか）、Decision（何を選んだか）、Alternatives（何を選ばなかったか、なぜか）、Consequences（良い点・悪い点）を記載しています。

2ヶ月後に自分のコードを読み返したとき、ADR がなければ「なぜ MCP を使ったのか」「なぜ CLI 起動をやめたのか」を思い出すのに時間がかかります。特に Alternatives セクションは、「検討した上で却下した選択肢」を記録するもので、同じ議論を繰り返さないための保険です。

チーム開発との違いで言えば、レビューアーがいない分、テストとドキュメントの品質を高くする必要がありました。1,165以上のテストは「レビューアーの代わり」でもあります。

---

#### Q17: 今後 Argus をどう発展させたいですか？

**回答:**

3つの方向があります。

**第一に、マルチエージェント協調**です。現在は1つのタスクに1つのエージェントが対応していますが、複雑なタスクでは複数のエージェントが協力する設計を入れたいです。例えば、リサーチエージェントが情報を集め、ライティングエージェントが記事を書き、レビューエージェントが品質チェックするパイプラインです。

**第二に、観測データの活用**です。全ツール実行が DB に記録されているので、「どのツールがよく使われるか」「どのパターンで失敗しやすいか」を分析し、エージェントの行動を最適化するフィードバックループを作りたいです。

**第三に、MCP エコシステムの拡張**です。現在4つの MCP サーバーがありますが、Notion、GitHub Issues、Jira など外部サービスをさらに統合し、エージェントの行動範囲を広げたいと考えています。

---

#### Q18:（英語版）Can you describe the Observation-First architecture?

**Answer:**

Sure. The core idea is that every tool invocation by every agent is recorded to the database in real-time, not after the fact.

We use a hook-based system. When the Claude Agent SDK executes a tool -- say, reading a file or searching the knowledge base -- our `PreToolUse` hook fires and records the start timestamp to the `tasks` table. When the tool completes, `PostToolUse` records the result, duration, and status. If it fails, `PostToolUseFailure` captures the error and creates an entry in the `lessons` table for episodic memory.

The key design choice was to build a bridge layer called `buildSDKHooks()`. It converts our simplified `ArgusHooks` interface -- which has just three callbacks -- into the SDK's `HookCallbackMatcher` format. This means consumer applications like the Slack bot only need to implement simple callback functions for their observation logic, without understanding SDK internals.

The practical benefit is twofold: first, users see real-time progress in Slack threads as tools execute. Second, the dashboard can reconstruct the complete execution history of any session -- which tools were called, in what order, how long each took, and whether they succeeded or failed.

---

#### Q19: 技術選定で最も重要視することは何ですか？

**回答:**

**観測可能性**と**段階的な劣化**です。

Argus の設計で一貫しているのは、「何が起きたか後から分かる」ことです。エージェントは予測不可能な行動をとることがあります。だからこそ、全行動を記録し、再構成できる必要があります。

段階的な劣化とは、一部が壊れても全体が止まらない設計です。API キーがなければキーワード分類にフォールバック。resume が失敗すれば新規 query にフォールバック。CLI ヘルスチェックが失敗すれば SNS バッチをスキップ。常に「次善の策」が用意されています。

この2つは AI システムに限った話ではなく、あらゆる本番システムに適用できる原則だと考えています。

---

### 7. 弱みへの対策

#### Q20: なぜ Rails ではなく TypeScript/Node.js を選んだのですか？

**回答（STAR）:**

- **Situation**: AI エージェントシステムの技術選定をする際、Rails（Ruby）と TypeScript/Node.js のどちらをベースにするかを検討しました。
- **Task**: AI SDK との親和性、型安全性、エコシステムの成熟度を基準に選定する必要がありました。
- **Action**: TypeScript/Node.js を選択した理由は3つです。
  1. **AI SDK のネイティブサポート**: Claude Agent SDK、OpenAI SDK、MCP SDK は全て TypeScript/JavaScript がファーストクラスです。Ruby 版は存在しないか、コミュニティ版で品質にばらつきがあります。AI エージェント開発では SDK との直接的な型の一致が開発速度と安全性に直結します。
  2. **フルスタックの型一貫性**: フロントエンド（Next.js/React）からバックエンド（Node.js）、DB スキーマ（Drizzle ORM）まで TypeScript で統一できます。`@argus/db` で定義した型がダッシュボードの React コンポーネントまでそのまま流れるので、API 境界での型の不一致が起きません。
  3. **AsyncGenerator / Stream 処理**: Claude SDK の `query()` は AsyncGenerator を返します。Node.js のイベントループモデルはストリーミングレスポンスの処理に最適で、`consumeSDKStream()` のような変換層を自然に書けます。
- **Result**: 12パッケージの monorepo 全体が単一の型システムで統合され、SDK の型定義をそのまま活用できています。「Rails でも作れたか」と聞かれれば作れますが、AI エージェント開発においてはTypeScript のメリットが圧倒的でした。

**補足（Rails に対するリスペクト）:**

Rails の Convention over Configuration や ActiveRecord パターンには大きな学びがあります。実際、Argus でも「設定より規約」の思想は取り入れています。例えば、MCP サーバーの実装パターンを4サーバーで統一し、新しいサーバー追加時にゼロから設計する必要がない構成にしています。

---

#### Q21: 個人プロジェクトにしては規模が大きいですが、なぜですか？

**回答（STAR）:**

- **Situation**: 「AI エージェントを作ってみよう」というところから始まりましたが、本番運用を始めると次々に必要な機能が見つかりました。
- **Task**: 24時間稼働するシステムには、単なるプロトタイプでは解決できない課題群（観測可能性、障害復旧、コスト管理、権限分離）がありました。
- **Action**: 3つの要因が規模拡大を可能にしました。
  1. **AI 駆動開発**: Argus 自体の開発に AI を活用しました。Claude Code を使った TDD（RED→GREEN→REFACTOR）サイクルで、テスト作成→実装→リファクタリングを高速に回せました。スキル定義やサブエージェント委譲のワークフローを整備し、1人でも大規模な開発を維持できる体制を構築しています。
  2. **monorepo による分離統治**: 12パッケージに分割することで、各パッケージは100〜500行程度の焦点を絞ったコードになっています。個々のパッケージの複雑度は低く、全体の複合によって規模が生まれています。
  3. **段階的な成長**: 最初から12パッケージを設計したわけではありません。ADR（Architecture Decision Records）で判断を記録しながら、CLI→SDK 移行、ファイルシステム→DB 移行、単一ナレッジ→MCP 分離と段階的に進化させました。
- **Result**: 1,165以上のテストがあることで、リファクタリングやパッケージ追加時の安全性が担保され、一人でも継続的にスケールさせることができています。

---

#### Q22: AI エージェントの安全性をどう担保していますか？

**回答:**

4層の安全設計を採用しています。

**第1層: 権限分離（Principle of Least Privilege）**
MCP サーバーでロールベースのアクセス制御を実装しています。Collector ロールは CRUD 全操作（5ツール）、Executor ロールは検索のみ（2ツール）。ツールの可視性を MCP サーバー側で制御し、さらにサービス層で `requireCollector()` によるダブルチェックを行います。仮にエージェントが権限外の操作を試みても、2重の壁で阻止されます。

**第2層: 行動の検証（Trust but Verify）**
`detectTaskFailure()` で SDK の `success: true` を鵜呑みにせず、レスポンス本文の失敗パターンをスキャンします。`detectPendingInput()` でエージェントが質問中かどうかを判定し、自律実行の暴走を防ぎます。

**第3層: 観測可能性（Observation-First）**
全ツール実行を `PreToolUse` / `PostToolUse` Hook で DB に記録します。「エージェントが何をしたか」は全て後から再構成可能です。ダッシュボードでリアルタイム監視でき、異常な行動パターン（同じツールの連続失敗、予期しないツール呼び出し）を検出できます。

**第4層: Human-in-the-Loop**
コストの高い操作（動画レンダリング、ポッドキャスト生成）は Slack の承認ボタンをゲートにしています。Inbox Agent の自律レベルも、タスクの分類結果に応じて「自動実行」「承認待ち」「拒否」を分岐させ、全てが自動実行されないように設計しています。

**補足（既知の限界）:**

`detectTaskFailure()` はヒューリスティクスなので完璧ではありません。構造化された失敗シグナル（SDK レベルでの成功/失敗メタデータ）が理想で、将来的には SDK への提案も検討しています。

---

## Part 2: エンタープライズ・品質 Q&A (Q23-Q29)

### 企業別対策

#### LayerX（設計課題選考 + eval-driven development）

##### Q23: LayerX の PR-Agent や eval-driven development と Argus のアプローチの違いは？

**回答:**

LayerX さんが PR-Agent で取り組んでいる「コードレビューの AI 自動化」と、Argus の「エージェント行動の観測・検証」は、同じ課題の異なるレイヤーを解決しています。

PR-Agent は**コード品質**の自動検証です。diff を解析し、レビューコメントを自動生成する。Argus の Hook ベース観測は**実行品質**の自動記録です。エージェントが「何をしたか」「成功したか」を構造化データとして蓄積します。

eval-driven development との接点で言うと、Argus の `detectTaskFailure()` は一種の eval です。SDK の `success: true` を信頼せず、レスポンスの内容をパターンマッチで検証する。ただし、これはヒューリスティクスベースです。本格的な eval-driven アプローチでは、テストケースとゴールド標準を定義し、regression を定量的に検出する仕組みが必要です。Argus の `lessons` テーブルに蓄積された失敗パターンは、eval データセットの原型と見ることもできます。

設計課題として出された場合は、「観測データから eval データセットを自動生成し、エージェントの行動品質を定量評価するパイプライン」を提案するのが自然な延長線上だと考えています。

---

##### Q24: 設計課題が出た場合の進め方は？

**回答:**

まず ADR（Architecture Decision Record）を書きます。Argus でも5本の ADR を作成しており、Context → Decision → Alternatives → Consequences の構造で設計判断を記録する習慣があります。

設計課題では、以下のプロセスで進めます:

1. **要件の明確化**: 制約条件（時間、スケーラビリティ要件、技術スタック）を整理
2. **3つのアプローチを比較**: それぞれの Trade-off を図示（例: 整合性 vs 可用性、コスト vs レイテンシ）
3. **プロトタイプコードで説明**: 抽象的な議論ではなく、TypeScript の型定義やインターフェースで設計意図を伝える
4. **テスト戦略を含める**: その設計をどうテストするかまで提案する

---

#### PKSHA（ライブコーディング + 研究発表）

##### Q25: ライブコーディングで Argus の設計力を見せるなら？

**回答:**

3つのデモ候補があります。

**候補1: MCP サーバーのライブ実装**（15分）
新しい MCP サーバー（例: Notion 連携）を一からライブコーディングする。Tool 定義 → Handler 実装 → ロールベース権限 → テストの流れで、Argus の設計パターンが再利用可能であることを示す。

**候補2: Hook ベースの観測ロジック追加**（10分）
新しい Hook（例: コスト集計 Hook）を追加する。`ArgusHooks` インターフェースにコールバックを追加し、`buildSDKHooks()` で SDK フォーマットに変換するデモ。抽象化の有効性を実演。

**候補3: AsyncGenerator のストリーム変換**（10分）
`consumeSDKStream()` と同様のパターンで、任意の AsyncGenerator を正規化する関数をライブ実装。TypeScript の型推論を活用したジェネリクス設計を見せる。

---

##### Q26: 7,000体の AI エージェント（PKSHA の事例）との技術的な違いは？

**回答:**

PKSHA さんの7,000体は「特定タスクに特化したエージェントの大量デプロイ」です。Argus は「汎用エージェントが MCP ツールで多様なタスクを実行する」モデルです。

スケーリングのアプローチが根本的に異なります。PKSHA は水平スケーリング（エージェント数を増やす）、Argus は垂直統合（1つのエージェントのツール数を増やす）です。

Argus のアーキテクチャを大規模化する場合の提案:

- Session-per-Thread モデルを維持しつつ、タスクキューでエージェント実行をスケールアウト
- 現在の `lessons` テーブルを共有学習ストアに拡張し、エージェント間で失敗パターンを共有
- MCP サーバーをマイクロサービス化し、エージェントプールからネットワーク経由でアクセス

---

#### SmartHR（TypeScript/React 枠 + AI 開発部）

##### Q27: TypeScript/React のエンジニアとして、AI 開発にどう貢献できるか？

**回答（STAR）:**

- **Situation**: SmartHR さんが2025年8月に AI 開発部を新設されたということは、既存の TypeScript/React エコシステムに AI 機能を統合する段階だと推測します。
- **Task**: 「AI 専門家を雇う」のではなく「TypeScript エンジニアが AI を使いこなす」方が既存コードベースとの親和性が高いはずです。
- **Action**: Argus で培った3つのスキルが直接活かせます。
  1. **Claude Agent SDK の実践経験**: SDK の AsyncGenerator モデル、Hook によるイベント監視、セッション管理を本番運用レベルで実装しています。
  2. **MCP によるツール統合**: 外部サービス（Gmail、Calendar、Knowledge）を MCP サーバーとして統合した経験は、SmartHR の既存 API を AI エージェントに接続する際に直接応用できます。
  3. **安全設計**: ロールベースのアクセス制御、`detectTaskFailure()` による出力検証、Human-in-the-Loop の承認ゲートなど、AI の出力を信頼しすぎない設計思想は、人事情報を扱う SmartHR のシステムで特に重要です。
- **Result**: 「TypeScript が書けて、AI エージェントの本番運用経験がある」エンジニアとして、AI 開発部の立ち上げに貢献できると考えています。

---

#### サイボウズ（OSS 文化 + kintone + 生成 AI）

##### Q28: OSS 文化やチーム開発をどう考えていますか？

**回答:**

サイボウズさんの「チームワークあふれる社会を創る」というミッションに強く共感します。

Argus は個人プロジェクトですが、「未来の自分や他者が理解できる設計」を一貫して重視しています。具体的には:

- **ADR 5本**: 設計判断を Context → Decision → Alternatives → Consequences で記録。「なぜ MCP を選んだのか」「なぜ CLI から SDK に移行したのか」を後から辿れます。
- **1,165以上のテスト**: 「コードの意図をテストで伝える」思想。テストがドキュメント代わりになっています。
- **CLAUDE.md によるオンボーディング**: プロジェクトのルール・規約・アーキテクチャを構造化して記述。新しいコントリビューター（AIエージェント含む）が迷わずに開発を始められる設計です。

サイボウズさんが新人研修資料を毎年全公開されているのは「知識の共有がチーム力を高める」という信念の表れだと思います。Argus の Episodic Memory（`lessons` テーブル）も同じ思想です -- エージェントの失敗と学びを組織の知識として蓄積し、次の実行に活かす。

OSS コントリビューションの経験としては、Argus の設計パターン（Hook ベース観測、MCP 権限分離、SDK ファサード）を記事やブログで公開する予定で、コミュニティへの還元を意識しています。

---

#### note（シニア職 + LLM/推薦/ベクトル検索）

##### Q29: LLM やベクトル検索の実装経験は？

**回答:**

Argus の Knowledge MCP サーバーで、LLM とベクトル検索に近い設計を実践しています。

**Knowledge の検索アーキテクチャ:**

- `search` ツールがクエリを受け取り、PostgreSQL の `text` 型フィールドに対して全文検索を実行
- タグベースのフィルタリング + テキスト検索の組み合わせで、セマンティックな意図をカバー
- 将来的には pgvector による埋め込みベクトル検索を導入予定（スキーマに embedding カラムを追加する設計は準備済み）

**Episodic Memory の推薦的要素:**

- `lessons` テーブルの蓄積データを `formatLessonsForPrompt()` で関連度順にフィルタし、セッション開始時にプロンプトに注入
- これは「過去の類似失敗パターンをレコメンドする」仕組みであり、推薦システムのコンセプトに近いです

**正直な限界:**
本格的なベクトル検索（FAISS, Pinecone, Weaviate）や大規模推薦システムの本番運用経験はまだありません。ただし、PostgreSQL ベースのデータモデル設計、TypeScript での API 実装、MCP プロトコルによるツール統合の経験は、ベクトル検索基盤の上層実装に直接活かせます。

---

## Part 3: キャリア・パーソナル Q&A (Q30-Q38)

> 回答は「結論→理由Nつ→1つずつ深掘り」の型で統一。

### Q30: なぜエンジニアになりたいのですか？

**回答:**

理由は2つあります。1つ目は、提案だけで終わらせず、実際に「動くもの」として形にできるのがエンジニアだと思ったからです。2つ目は、自分の性格として、考えるだけでなく手を動かして仕組みを作り切る方がやりがいを感じるからです。

コンサルのように「こうしたらいい」と示すことも重要ですが、私は最終的に成果として残る形まで持っていきたいので、エンジニアを選びました。

---

### Q31: なぜAI駆動開発の会社を志望するのですか？

**回答:**

理由は2つあります。1つ目は、実務を通じて「AIに任せられる範囲が急速に広がっている」と実感しており、開発の前提が変わっていると感じているからです。2つ目は、その最前線の環境で経験を積むことで、自分の成長速度と成果の質を上げられると考えているからです。

根拠としては、1年間の実務でAIに任せられる範囲がどんどん広がっていることを体感しており、新機能追加の際の要件の叩き上げなど、上流の思考の質までAIで上がる手応えがあります。

---

### Q32: フルリモートがいい理由は？

**回答:**

理由は2つあります。1つ目は、集中して実装に没頭でき、任された期間内で成果を出しやすいからです（自宅に3画面やスタンディングデスクを整備済み）。2つ目は、通勤時間を仕事や学習に充てて、成長と成果に直結させたいからです。

出社のメリット（非言語コミュニケーション、雑談からの関係構築、意思決定速度）は認識しています。だからこそリモートでは、目線をカメラに向ける、文章や図で共有して認識を揃える、区切りで「ここまで大丈夫ですか？」と確認する、といった工夫を意識しています。

---

### Q33: ガクチカ -- テレアポで常に1位だった話

**回答（STAR）:**

- **Situation**: 大学時代、人見知り克服とコミュニケーション力向上のため、蓄電池販売のテレアポのアルバイトを始めました。
- **Task**: 成果を上げつつ、限られた稼働時間で効率的に働く必要がありました。
- **Action**: 3つのことを行いました。
  1. 成果を出している先輩のやり方を徹底的に観察して"型"を真似た
  2. 真似して終わりにせず、自分の結果を記録して改善を回した
  3. 断られるパターンを分析し「断られる前に対処する」スクリプトに改善した
- **Result**: 常にチーム内1位を維持。作成したスクリプトをチームに共有し、新人教育にも活用。チーム全体の月間アポ獲得数が約1.3倍に向上（約120件→約155件）。

---

### Q34: 転職理由は何ですか？

**回答:**

理由は2つあります。1つ目は、AI駆動開発を組織として本格的に取り入れている環境で経験を積みたいからです。現職では個人レベルでClaude Codeを活用していますが、組織全体としてはまだ浸透途中です。2つ目は、将来のキャリアの伸びしろを見据えた選択をしたいからです。

現職には大きく感謝しています。社会人1年目として、メール・電話対応からチーム開発のお作法、コードレビューまで教えていただきました。その基礎があるからこそ、次のステップとしてAI駆動開発の最前線で成長したいと考えています。

---

### Q35: 浪人・留年について教えてください

**回答（浪人）:**

九州工業大学に行きたかったのですが現役では不合格で、諦めきれず1年浪人して合格しました。こだわった理由は3つあります。1つ目は国立なので学費負担を抑えられること、2つ目は情報工学に特化したカリキュラムで専門を体系的に学べること、3つ目は就職実績も含めて「情報で勝負する」土台が作れることです。

**回答（留年）:**

正直に申し上げると、大学1〜2年の頃は学業よりバイトに時間を取られすぎて、単位を落としてしまいました。原因は2つあります。1つ目は、卒業に必要な単位を逆算して履修計画を立てていなかったこと。2つ目は、バイトと学業の優先順位の線引きが曖昧だったことです。

この経験から「目標から逆算して優先順位をつける」重要性を痛感し、以降は計画的に行動するようになりました。休学期間中はAIのインターンや営業のアルバイトに取り組み、E資格カリキュラム完走やテレアポ1位という成果にも繋げられました。

---

### Q36: 強みと弱みを教えてください

**回答（強み）:**

「観察→分析→仕組み化」のサイクルを回せることです。テレアポでは先輩のやり方を観察してスクリプトを改善し、Argusでは全ツール実行をHookで記録して改善データを蓄積する仕組みを作りました。

**回答（弱み）:**

自分が理解できない状態が続くとストレスを感じます。説明が曖昧だったり前提が違うまま進んだりすると、解消したくなります。対処として、原因の仮説を立てて言語化し、解消のための具体的な行動を取るようにしています。じっと我慢するより、行動で現状を変えるタイプです。

---

### Q37: 「またすぐ辞めるのでは？」という懸念にどう答えますか？

**回答:**

同じ失敗を繰り返すつもりはありません。ポイントは2つあります。

1つ目は、新卒のときは正直、将来を十分に見据えられていなかったことを自覚していて、今回はAI駆動開発の動向、会社の評価制度、将来性まで調べたうえで転職活動をしていることです。2つ目は、一つの会社で長く働くことで得られる成長や信頼があると考えており、腰を据えて成果を出すつもりだということです。

---

### Q38: 5年後はどうなっていたいですか？

**回答:**

3段階で考えています。

**1年後**: チームの戦力として、AI駆動開発のプラクティスを実務で確立し、周囲にも共有できるレベルになりたいです。

**3年後**: アーキテクチャ設計やテックリードの役割を担い、AI×ソフトウェアの設計判断ができるエンジニアになりたいです。

**5年後**: 新規プロダクトやAI機能の立ち上げをリードできる存在になりたいです。技術選定からチーム構築、品質担保まで一貫して携われるエンジニアが目標です。

---

## Part 4: 個人エピソード詳細

### E資格インターン（スキルアップAI株式会社）

| 項目 | 内容                                          |
| ---- | --------------------------------------------- |
| 期間 | 約1年間                                       |
| 内容 | E資格（AIエンジニア向け資格）取得カリキュラム |
| 形式 | 2-3ヶ月ごとに動画+資料→テスト→合格者のみ次へ  |
| 結果 | カリキュラム完走（資格試験は未受験）          |

#### なぜ始めたか

AIの仕組みを根本から理解したかった。表面的にAPIを叩くだけでなく、裏で何が動いているかを知ることで、より効果的にAIを活用できると考えた。

**Q: 1年間続けられたモチベーションは？**

> 大学時代にChatGPTを使っていて、そのすごさに感銘を受けていました。「この中身の仕組みはどうなっているんだろう」という好奇心があり、それを知ることが純粋に楽しかったので続けられました。

#### 学んだこと

- 機械学習・深層学習の基礎理論
- PyTorchを使った実装
- AIモデルの評価手法

**Q: AIについて何を知っていますか？**

> E資格のカリキュラムを1年かけて完走し、機械学習・深層学習の基礎から実装まで学びました。今はAIを「ブラックボックス」ではなく、裏の仕組みを理解した上で活用しています。

**Q: 資格を取らなかったのはなぜ？**

> 資格そのものより、カリキュラムで得た知識と実装力を大事にしたかったためです。受験費用も高かったので、その分は別の学習や個人開発に回す選択をしました。学んだ知識は、個人開発のAIニュース要約アプリなどに活かしています。

---

### 卒業研究（AI技術を用いた化学物質の蓄積性予測）

| 項目   | 内容                                                                       |
| ------ | -------------------------------------------------------------------------- |
| テーマ | AI技術を用いた魚類における「代謝されにくさ」を決定づける化学物質の特徴探索 |
| 期間   | 大学4年（令和6年度）                                                       |
| 役割   | **AI解析パート全般を一人で担当**                                           |
| 発表   | 国内学会「ケモインフォマティクス討論会」で口頭発表（2024年12月、金沢）     |
| 連携   | 愛媛大学との共同研究（化学・生物学の知見提供）                             |

#### 自分が担当した範囲（全工程）

| 工程           | 内容                                          |
| -------------- | --------------------------------------------- |
| データ収集     | 1,332種類の化学物質データを収集・整理         |
| 分子記述子生成 | RDKitで201個の分子記述子を生成                |
| 特徴量選択     | RFE（再帰的特徴消去）で重要な記述子を絞り込み |
| モデル構築     | Random Forestで予測モデルを構築               |
| SHAP分析       | 説明可能なAIで予測根拠を可視化                |
| 学会発表       | 発表資料作成・口頭発表（2024年12月、金沢）    |

**Q: 研究内容を簡単に説明してください**

> 化学物質が魚の体内にどれだけ蓄積するかを、AIで予測する研究を行いました。従来の測定方法は時間とコストがかかり、動物実験の倫理的問題もあります。私はAIモデルの構築を担当し、1,300種類以上の化学物質データから、蓄積しやすさを決める重要な特徴を4つ特定しました。特に、SHAPという「説明可能なAI」の手法を使い、なぜその予測になるかを可視化したことがポイントです。2024年12月、ケモインフォマティクス討論会で口頭発表しました。

**Q: なぜこのテーマを選んだ？**

> 化学・生物データをAIで扱うテーマに興味があり、かつE資格で学んだ機械学習がそのまま活かせると知って選びました。

**Q: 研究で一番楽しかったことは？**

> データを加工したり、パラメータを変えたりして精度を上げていくプロセスが楽しかったです。あわせて、動物実験の代替になりうるモデルづくりに携われたことにもやりがいを感じました。

**Q: なぜ説明可能なAI（XAI）を使ったのですか？**

> 予測精度だけでなく、「なぜその予測になるか」を説明できることが、化学物質規制の現場では重要だからです。ブラックボックスのモデルでは、規制の根拠として使えません。SHAPを使うことで、各化学物質の特徴が予測にどう影響するかを定量的に示せるようになりました。

**Q: この研究で苦労したことは？**

> 201個の分子記述子から、本当に重要な4つを選び出すプロセスに苦労しました。単純に相関が高いものを選ぶだけでは多重共線性の問題があり、特徴量選択の手法を複数組み合わせて、解釈性と予測精度のバランスを取る必要がありました。

#### エンジニアリングとの接続

> この研究を通じて、AIは「使う」だけでなく「なぜそうなるか説明する」ことの重要性を学びました。これはプロダクト開発においても、ユーザーに対して透明性のある機能を提供することに通じると考えています。また、大規模なデータを扱い、仮説を立てて検証するサイクルを回した経験は、エンジニアとしてのデータ分析力にも活きています。

---

### ポートフォリオ

#### AIニュース音声要約アプリ

| 項目         | 内容                                                                                |
| ------------ | ----------------------------------------------------------------------------------- |
| リポジトリ   | GitHub公開済み                                                                      |
| 目的         | AI最新情報を効率的にキャッチアップするため                                          |
| 技術スタック | Firebase Functions, TypeScript, Google Cloud Text-to-Speech, Gemini API, RSS Parser |
| 利用状況     | **通勤時に毎日使用**（通勤片道約30分のうち約10分、徒歩中に聴いている）              |

**なぜ作ったか:**

> 自分で使いたい情報を、自分で作るツールにしたかったからです。AI分野は進化が速く、通勤時間をインプット時間に変えれば効率的にキャッチアップできると考え、開発しました。「自分の課題を自分で解決する」という姿勢で取り組みました。

**Q: なぜ「音声」にしたのか？テキストではダメだった理由は？**

> 通勤は片道約30分で、そのうち徒歩の約10分はテキストを読めません。音声にすればその10分を毎日インプットに使えると考え、徒歩中に聴くようにしています。

#### 電子書籍→PDF変換アプリ

| 項目         | 内容                                                                              |
| ------------ | --------------------------------------------------------------------------------- |
| リポジトリ   | GitHub公開済み（Vercelデプロイ）                                                  |
| 目的         | 複数の本から共通点を抽出し、自分の成長に活かすため                                |
| 技術スタック | Next.js 16, React 19, TypeScript, Tailwind CSS, pdf-lib, Playwright, Tesseract.js |
| 利用状況     | **現在も使用中**                                                                  |

**なぜ作ったか:**

> 1冊の本だけを読むと、その著者の思考に偏りがちです。複数の本から共通点を抽出し、普遍的な知見を自分に取り込みたいと考えました。そのために、電子書籍をPDF化し、AIで横断的に分析できる形にするツールを作りました。現時点ではPDF化まで完成しており、AIでの横断分析はこれから活用していく予定です。

---

### テレアポ体験（蓄電池販売）

| 項目 | 内容                               |
| ---- | ---------------------------------- |
| 期間 | 大学3年、約1年間                   |
| 業務 | 蓄電池の販売（アウトバウンド営業） |
| 規模 | 同僚15名のチーム                   |
| 成果 | **在籍期間中、常に売上1位を維持**  |

#### 具体的な実績（数値）

| 指標              | 内容                                |
| ----------------- | ----------------------------------- |
| 勤務頻度          | 月8回（土日のみ）                   |
| 1回あたり勤務時間 | 約8時間                             |
| 1回あたりアポ獲得 | 約2件                               |
| 月間アポ獲得数    | 約16件                              |
| 有効アポ率        | 約50%（実際に商談につながった割合） |
| 商材単価          | 1台あたり200〜300万円               |
| 月間売上貢献      | **約1,000万円**（アポベース）       |

#### 工夫したこと

1. **観察から始める**: 最初は他の人のやり方を徹底的に観察
2. **成功パターンの分析**: 経験を積みながら「どういう話し方が刺さるか」を自分で分析
3. **スクリプトの体系化**: 顧客タイプ別にスクリプトをカスタマイズ

#### 面接用ストーリー（STAR法）

**Situation:** 大学3年生のとき、蓄電池販売のテレアポ営業のアルバイトを始めました。15名ほどのチームで、一人ひとりが成果を競う環境でした。

**Task:** 最初は渡されたスクリプト通りに話していましたが、お客様によって反応が全く異なり、一律のアプローチでは限界があると感じました。

**Action:** まず、成果を出している先輩のトークを徹底的に観察し、パターンを分析しました。そして、自分の経験からも「どんな話し方がどんなお客様に刺さるか」を記録し、顧客タイプ別のスクリプトを作成しました。関心度、よくある質問、年齢層などで分類し、それぞれに最適なアプローチを体系化しました。

**Result:** 在籍した1年間を通じて常に売上1位を維持できました。月8回（土日のみ）の勤務で月間約16件のアポを獲得し、有効アポ率は約50%。蓄電池は1台200〜300万円の商材で、月間約1,000万円の売上に貢献。作成したスクリプトをチーム内に共有したところ、チーム全体の月間アポ獲得数が約1.3倍に増加（約120件→約155件）。

#### エンジニアリングとの接続

> この経験から「観察→分析→仕組み化」のサイクルを回す力が身につきました。これはソフトウェア開発における「現状把握→設計→実装→改善」のサイクルと同じです。また、お客様のタイプ別にスクリプトを分けたことは、ユーザーペルソナを意識した設計思考にも通じると考えています。

---

### 現職について（ラキール株式会社）

| 項目     | 内容                                                      |
| -------- | --------------------------------------------------------- |
| 会社名   | 株式会社ラキール（LaKeel）                                |
| 上場     | 東証グロース（証券コード: 4074）                          |
| 事業     | DX支援プラットフォーム「LaKeel DX」等の自社プロダクト開発 |
| 主要製品 | LaKeel HR（人事システム）、LaKeel BI、LaKeel Data Insight |
| 在籍     | 新卒1年目                                                 |

**入社理由:**

> ラキールを選んだ理由は2つあります。1つ目は、SIerではなく自社プロダクトを持っている企業で経験を積みたかったからです。2つ目は、当時は経験を積める環境と待遇のバランスを踏まえ、自分の市場価値を意識しつつ長く成長できる環境を重視して選びました。

**転職理由:**

> 現職では自社プロダクトの開発に携わり、チーム開発のお作法やコードレビューを通じてエンジニアとしての基礎を身につけることができました。現職には感謝しています。しかし、AI駆動開発をより積極的に取り入れたいと考え、社内で提案もしましたが、金銭面の理由で導入が難しい状況でした。今後のキャリアを考えたとき、AI駆動開発を本格的に導入している環境で経験を積みたいと考え、転職を決意しました。

**1年間で身につけたこと:**

| カテゴリ           | 学んだこと                                                                 |
| ------------------ | -------------------------------------------------------------------------- |
| チーム開発         | GitHubを用いたスプリント管理、Issue駆動開発                                |
| コミュニケーション | レビューのタイミング、分かりやすい伝え方・説明の構成                       |
| コード品質         | 命名規則、責務分離、可読性の高いコードの書き方（レビュー指摘を通じて習得） |
| 社会人基礎         | メールの書き方、電話対応、オリエンテーションの進め方                       |

---

### 浪人・留年の経験

#### 事実

| 項目   | 内容                                                  |
| ------ | ----------------------------------------------------- |
| 浪人   | 1回                                                   |
| 留年   | 1回（大学時代）                                       |
| 理由   | 学業以外の活動に時間を使いすぎた（主にバイトが約9割） |
| 休学   | 1回（単位取得後、学費節約のため）                     |
| 休学中 | E資格インターン、コールセンターのアルバイト           |

**Q: 浪人した理由を教えてください**

> 情報系に強い九州工業大学に行きたかったのですが、現役では不合格でした。諦めきれず、1年浪人して再受験し、合格しました。九工大を選んだのは、国立で唯一の情報工学専門学部であること、学費の負担が少ないこと、情報工学に特化したカリキュラムや就職実績を重視したからです。

**Q: 留年した理由を教えてください**

> 正直に申し上げると、大学1〜2年の頃は学業よりバイトに時間を取られすぎていました。振り返って分析すると、卒業に必要な単位を「いつ・どの学期に取るか」と逆算して履修計画を立てていなかったこと、バイトと学業のどちらを優先するかの線引きが曖昧だったことが原因でした。この経験から「目標から逆算して優先順位をつける」ことの重要性を痛感し、以降は計画的に行動するようになりました。休学期間中はAIのインターンや営業のアルバイトに取り組み、結果的にE資格のカリキュラム完走や、テレアポで常に1位という成果に繋げることができました。

---

## Appendix A: コードベース Q&A

> PROJECT_STRUCTURE_AND_CODEBASE_GUIDE.md より。各回答には技術者向けと噛み砕いた説明の両方を用意。

### Q1: 「このプロジェクトのフォルダ構成を教えてください」

**回答例**:

> pnpm モノレポで、`apps/`（3 アプリ）と `packages/`（9 パッケージ）に分離しています。`apps/` が実行可能なアプリケーション（slack-bot, dashboard, orchestrator）で、`packages/` が共有ライブラリ（agent-core, db, knowledge 等）です。依存は常に `apps/ → packages/` の一方向で、パッケージ間の依存は最小限です。

**噛み砕いた説明**: 会社のフロアを想像してほしい。`apps/` は各部署のオフィス、`packages/` は全社共有の会議室や倉庫。各部署は共有設備を使うが、部署同士が直接干渉しない設計。

---

### Q2: 「agent-core パッケージの設計思想を説明してください」

**回答例**:

> agent-core は Claude Agent SDK のラッパーで、本番依存は SDK の 1 つだけという極めてスリムな設計です。DB への直接依存を避け、`SessionStore` や `ObservationDB` 等のインターフェースを定義して消費側に実装を注入する DI パターンを採用しています。これにより、テストが容易で、異なる永続化先への差し替えが可能です。

**噛み砕いた説明**: agent-core は「充電器の規格」のようなもの。本体（エージェント）とプラグ（データベースなど）を分離しておくことで、プラグを交換しても本体は変わらない。

---

### Q3: 「エラーハンドリングの設計方針を教えてください」

**回答例**:

> プロジェクト全体で `success: boolean` フラグパターンを統一しています。例外を throw するのではなく、`{ success: false, error: "..." }` のような結果オブジェクトを返します。これにより、呼び出し側が try-catch を忘れてクラッシュするリスクを排除し、型システムでエラーケースの処理を強制できます。

**噛み砕いた説明**: エラーが起きても「プログラム全体が止まる」のではなく、「この処理は失敗しました」という報告書を返す方式。ブレーカーが落ちて家中停電するのではなく、問題のある部屋だけ赤ランプが点く仕組み。

---

### Q4: 「Inbox パイプラインの設計を説明してください」

**回答例**:

> 4 段階のパイプラインです。(1) classifier で AI（Haiku）またはキーワードベースでメッセージを分類、(2) タスクキューに投入（同時実行制限 3、アトミックなステータス更新で二重実行防止）、(3) executor で Agent SDK を実行（intent 別タイムアウト付き）、(4) reporter で Block Kit レポートを生成。起動時リカバリ機能もあり、クラッシュで `running` のまま取り残されたタスクを自動復元します。

**噛み砕いた説明**: 届いたメッセージを「仕分け → 列に並べる → 処理する → 報告する」の 4 段階で処理する郵便局のような仕組み。同時に処理できる数に上限を設け、途中でシステムが落ちても未完了の仕事を自動で再開する。

---

### Q5: 「テスト戦略について教えてください」

**回答例**:

> Vitest 4 でソースと同ディレクトリにテストをコロケーション配置しています。DB 接続はせず、`vi.mock()` で Drizzle のチェーンメソッドをモックします。Dashboard では jsdom + Testing Library で Server Component のテストも行っています。

**噛み砕いた説明**: 各ソースファイルのすぐ隣にテストファイルを置く「コロケーション」方式。本物のデータベースや AI を使わず、「ダミー」に差し替えてテストするので、速く・安く・確実に品質を確認できる。

---

### Q6: 「MCP サーバーの実装パターンを説明してください」

**回答例**:

> `McpBaseServer` という抽象基底クラスを `agent-core` パッケージに用意し、全 4 つの MCP サーバーがこれを継承しています。サブクラスは `getTools()` と `handleToolCall()` の 2 メソッドだけ実装すれば MCP サーバーとして動作します。

**噛み砕いた説明**: AI に「道具」を持たせるための統一テンプレートを用意し、各サーバーは「どんな道具があるか」と「道具の使い方」だけを定義すればよい。

---

### Q7: 「Code Patrol の仕組みを教えてください」

**回答例**:

> 週次（土曜 3:00 JST）で自動実行される 12 ステップのパイプラインです。まず pnpm audit・シークレット検出・tsc を並列スキャンし、問題があれば Claude に修正を依頼します。修正前に git stash で安全ネットを張り、修正後は pnpm build && pnpm test で検証。検証失敗時は git checkout でロールバックし、成功時は Block Kit レポートを Slack に投稿します。

**噛み砕いた説明**: 毎週土曜の深夜に「夜間警備員」が自動でコードの健康診断を行う仕組み。問題を見つけたら AI に修正を依頼し、修正が正しいか検証してから適用する。失敗したら元に戻すので安全。

---

### Q8: 「SNS 投稿管理システムの設計を教えてください」

**回答例**:

> 10 プラットフォームに対応した自動投稿システムです。核心は `PhasedGenerator` という段階的パイプライン実行エンジンで、各プラットフォームのコンテンツ生成をフェーズ分割して順次実行します。長文コンテンツは 4 フェーズ（research → structure → content → optimize）、短文コンテンツは 2 フェーズ構成です。

**噛み砕いた説明**: 毎朝 4 時に AI が 10 個の SNS の投稿案を自動で作成する仕組み。記事は「調査→構成→執筆→校正」の 4 工程に分けて品質を確保する。

---

### Q9: 「McpBaseServer を導入した理由を教えてください」

**回答例**:

> 4 つの MCP サーバーで共通のボイラープレートが重複していたため、`McpBaseServer` 抽象クラスに集約しました。MCP SDK のバージョンアップ時も 1 箇所の修正で全サーバーに反映でき、新規 MCP サーバー追加のコストも大幅に削減されます。

**噛み砕いた説明**: 4 つのお店で毎回「入口の作り方」を個別に考えていたのを、「店舗テンプレート」を作って共通化した。新しいお店を出す時も、テンプレートに「メニュー」と「調理法」を追加するだけで開店できる。

---

## Appendix B: 技術スタック Q&A

> TECH_STACK_AND_ARCHITECTURE.md より。各回答には技術者向けと噛み砕いた説明の両方を用意。

<details>
<summary>Q1: 「なぜ MongoDB ではなく PostgreSQL を選んだのですか？」</summary>

**回答例**:

> データモデルがリレーショナルだったからです。セッション、メッセージ、ツール実行記録が外部キーで紐付いており、JOIN が頻繁に発生します。また、Inbox Agent のタスクキューでは `FOR UPDATE SKIP LOCKED` を使った排他制御が必要で、PostgreSQL の ACID トランザクションが適していました。

**噛み砕いた説明**: データ同士が「親子関係」で繋がっているので、そういう関係を扱うのが得意な PostgreSQL を選んだ。

</details>

<details>
<summary>Q2: 「Prisma ではなく Drizzle を選んだ理由は？」</summary>

**回答例**:

> 3つの理由があります。第一に、プロジェクトが完全 ESM で、Prisma は歴史的に CJS 前提のため ESM 環境でトラブルが起きやすかった。第二に、Docker の alpine イメージで Prisma の Rust バイナリの互換性問題を避けたかった。第三に、Drizzle は TypeScript の型推論をそのまま活用するので、コード生成ステップが不要です。

**噛み砕いた説明**: どちらも「プログラムからデータベースを操作する翻訳ツール」だが、Drizzle は軽量で、プロジェクトの技術方針（ESM）との相性が良かった。

</details>

<details>
<summary>Q3: 「Claude Agent SDK と Anthropic SDK の違いは？使い分けは？」</summary>

**回答例**:

> Anthropic SDK は API 呼び出し 1 回分の低レベルクライアントです。Agent SDK は Claude Code のエンジンそのもので、エージェントループ全体を提供します。Argus では Agent SDK を採用し、`query()` の AsyncGenerator をストリーム消費する薄いラッパーを書いています。

**噛み砕いた説明**: Anthropic SDK は「1回質問して1回答えをもらう電話」。Agent SDK は「AI に目標を伝えると、自分で調べて結果を報告してくれる秘書」。Argus は秘書型を採用した。

</details>

<details>
<summary>Q4: 「なぜ REST API ではなく MCP でツールを実装したのですか？」</summary>

**回答例**:

> Agent SDK が MCP を標準サポートしているためです。MCP なら `server.tool()` で宣言するだけで、SDK が自動的にツールとして認識します。さらに MCP サーバーは Claude Desktop など他のクライアントからも再利用できます。

**噛み砕いた説明**: USB のように「繋げば使える」標準規格を使った。

</details>

<details>
<summary>Q5: 「Vercel ではなく Railway を選んだ理由は？」</summary>

**回答例**:

> Slack Bot の Socket Mode が常時 WebSocket 接続を維持する常駐プロセスで、Vercel のサーバーレスモデルでは動かせません。Railway は Docker をそのままデプロイでき、PM2 で 3 プロセスを管理できます。月額 $5 程度で全てをカバーできます。

**噛み砕いた説明**: Vercel は「使った瞬間だけ電源が入るマシン」なので、24 時間稼働が必要な Slack Bot には使えない。Railway は「常時稼働サーバー」を安く借りられるサービス。

</details>

<details>
<summary>Q6: 「テストで Agent SDK をどうモックしていますか？」</summary>

**回答例**:

> SDK の `query()` は `AsyncGenerator<SDKMessage>` を返すので、`fakeStream()` というヘルパーで SDKMessage の配列を AsyncGenerator に変換してモックしています。全メッセージの `session_id` を一致させることが重要です。

**噛み砕いた説明**: テスト時に本物の AI を呼ぶとお金も時間もかかるので、「AI のフリをするダミー」を使う。

</details>

<details>
<summary>Q7: 「このアーキテクチャのスケーラビリティの限界は？」</summary>

**回答例**:

> 現在の構成は単一 VPS + 単一 DB なので、同時接続数が数百を超えるとボトルネックになります。ただし、現在の用途（個人/インハウス）では YAGNI の原則に従い、過剰な最適化はしていません。

**噛み砕いた説明**: 今は「1台のサーバー」で動いている。数百人が同時に使うならサーバーを増やす必要がある。「今必要ないものは作らない」原則に従っている。

</details>

<details>
<summary>Q8: 「例外を throw せず success フラグで返す設計の理由は？」</summary>

**回答例**:

> Slack Bot のメッセージハンドラで未捕捉例外が発生すると、Socket Mode の WebSocket 接続が切れてボット全体が停止します。全ての公開関数が `{ success: boolean, ... }` パターンで結果を返す規約にしています。Go 言語の `(result, error)` パターンに近い思想です。

**噛み砕いた説明**: エラーが起きた時に「プログラム全体がクラッシュする」のではなく「エラーフラグを返す」方式。

</details>

<details>
<summary>Q9: 「pnpm の幽霊依存防止はどう役立っていますか？」</summary>

**回答例**:

> 12 パッケージのモノレポで、npm だとホイスティングにより幽霊依存が発生します。pnpm はシンボリックリンクで厳密に分離するため、`package.json` にない依存は import 時にエラーになります。

**噛み砕いた説明**: 「隣の部屋の道具を勝手に借りて使っていた」状態を防ぐ仕組み。

</details>

<details>
<summary>Q10: 「Max Plan と API キーの自動切り替えはどう実装していますか？」</summary>

**回答例**:

> `isMaxPlanAvailable()` 関数で、macOS かつ Claude CLI のバイナリが既知パスに存在するかを `fs.existsSync()` でチェックしています。Max Plan 利用時は環境変数から `ANTHROPIC_API_KEY` を除外して、SDK がローカルの Claude Code 経由で動作するよう強制します。

**噛み砕いた説明**: Mac では月額プラン（Max Plan）をそのまま使い、サーバーでは従量課金の API キーを使う。環境を自動判別し、最適な設定に切り替える。

</details>

---

## Appendix C: FAQ

> argus-interview-guide.md の FAQ セクションより。面接でよくある質問への端的な回答集。

### Q: このプロジェクトで一番難しかったことは？

A: 「Claude Agent SDK への移行判断と実行」です。既に CLI ラッパーで動いていたので「動いているものを変える」リスクがあった。しかし CLI の出力パーサーが壊れやすく、hooks も使えなかった。SDK の AsyncGenerator API を理解し、既存の公開 API（AgentResult 型）を変えずに内部実装だけ差し替える設計にしたことで、消費側のコードを一切変更せずに移行できました。

### Q: チーム開発を意識した設計はありますか？

A: はい、3つあります：

1. **monorepo + 型安全**: パッケージ間の依存を TypeScript の型で保証
2. **権限分離**: Collector/Executor パターンで最小権限を実現
3. **ADR**: 5つの Architecture Decision Records で設計判断の経緯を文書化

### Q: セキュリティはどう考えていますか？

A: 3つのレイヤーで対策しています：

1. **アプリケーション**: `.claude/settings.json` で deny-first の権限設定
2. **インフラ**: Cloudflare Access でメール認証
3. **データ**: API キーやトークンは環境変数で管理

### Q: パフォーマンスの工夫は？

A: 3つあります：

1. **Playwright MCP の動的追加**: 必要なキーワード検出時のみ起動（約 7,000 トークン節約）
2. **進捗通知のスロットル**: Slack への進捗メッセージを 5秒/8秒 スロットルで送信
3. **DB クライアントの遅延初期化**: Proxy パターンで初回アクセス時のみ接続

### Q: AI でコード書いてるだけじゃないの？

A: Claude Code を活用して開発していますが、**設計判断は全て自分で行っています**。例えば：

- CLI → SDK 移行の判断は、CLI パーサーが壊れた経験から自分で決断した
- MCP による疎結合設計は、直接統合で依存が絡まった経験からの学び
- 権限分離（Collector/Executor）は、エージェントがナレッジを誤って上書きした事故から設計した

AI はコードの実装を高速化するツールであり、**何を作るか・なぜそう設計するかは人間が決める**。CLAUDE.md や skills/ の設計パターンは「AI に何をさせるか」のコンテキストエンジニアリングであり、これ自体がスキル。

### Q: なぜ個人開発なのにこんなに規模が大きいのか？

A: Claude Code を使って開発しているからです。ただし「AI に全部書かせた」のではなく、**AI の生産性を最大化する仕組み自体を設計した**のがポイントです：

- `CLAUDE.md` にプロジェクトの全体像とコーディング規約を集約
- `.claude/rules/` でアーキテクチャルールを文書化
- `.claude/skills/` でタスクのテンプレートを定義
- hooks で段階的開示

これは「AI 駆動開発のワークフロー設計」であり、単にコードを書く以上のスキル。

### Q: Firebase から Supabase に移行した理由は？

A: 3つの理由：

1. **データモデルの不一致**: Firestore は NoSQL で、リレーショナルな構造を扱うのが不自然
2. **型安全性**: Drizzle ORM + PostgreSQL なら、スキーマ定義がそのまま TypeScript の型になる
3. **SQL の表現力**: 集計クエリが SQL なら簡潔に書ける

---

## Appendix D: 改善ポイント

> interview-episodes-review.md より、重要な改善提案を要約。面接回答をブラッシュアップする際の参考。

### 志望動機の改善

| 質問             | 改善ポイント                                                                                                           |
| ---------------- | ---------------------------------------------------------------------------------------------------------------------- |
| なぜエンジニアか | 「効率化が好き」だけでは他職種でも当てはまる。「コードを書いて形にする」「動かす」というエンジニア固有の魅力を一文足す |
| AI駆動の根拠     | 根拠の説明の最後に「自分は何にフォーカスしたいか」（要件整理・設計・優先順位の判断）を添える                           |
| フルリモート     | 自分都合だけでなく「成果につながる」視点を先に置く。「スプリント内で確実に成果を出しやすい」等                         |
| リモートの工夫   | 技術的理由の説明が長い。「目線をカメラに向ける」「構成を考えて話す」等、実践内容を簡潔に                               |

### エピソードの改善

| 質問                     | 改善ポイント                                                                                         |
| ------------------------ | ---------------------------------------------------------------------------------------------------- |
| テレアポのバイト選定理由 | 時給を先に出さず「コミュニケーション力を伸ばしたかった」を先に。金銭は「条件の一つ」として軽く触れる |
| E資格を取らなかった理由  | 「費用が高い」が先に立つとコスト避けの印象。「知識と実装力を大事にしたかった」を先に置く             |
| 卒研のテーマ選定         | 「スキルが活かせるから」だけだと受け身。「テーマへの興味」を前半に置く                               |
| 趣味（アニメと個人開発） | 並列だと仕事の延長に聞こえる。両方の役割（リフレッシュ / ものづくり）を説明する                      |

### パーソナル質問の改善

| 質問                 | 改善ポイント                                                                             |
| -------------------- | ---------------------------------------------------------------------------------------- |
| ストレスを感じるとき | 原因を相手に寄せすぎない。「自分が理解できない状態が続くとき」を主語にする               |
| 苦手なタイプの人     | 「話が長い人」だけだと刺々しい。「要点が掴みづらい方が苦手」に言い換え、対処法を柔らかく |
| 弱み                 | 「一旦完成させて直す」を強調しすぎない。「今は実装前に認識合わせをする」を主軸に         |
| 浪人理由             | 九工大の魅力の説明が長すぎる。浪人の決断理由を先に、大学の詳細は聞かれたときに           |

### 転職・キャリアの改善

| 質問          | 改善ポイント                                                                             |
| ------------- | ---------------------------------------------------------------------------------------- |
| 入社理由      | 「給与が高い」を前面に出さず「待遇」として概括。「市場価値を意識しつつ成長環境を選んだ」 |
| 他社状況      | 企業名を並べない。「AI駆動開発とフルリモートを軸に受けています」と業態・条件で答える     |
| 10年後        | 独立・稼ぎを前面に出しすぎない。「まずは御社で経験を積む」を最優先に                     |
| 簿記2級の理由 | 「投資活動」を前面に出さず「企業理解・プロダクトの採算」に繋げる                         |

### 全般的な原則

1. **結論→理由→具体例** の順で話す（結論が後回しにならないように）
2. **ネガティブな理由を先に出さない**（ポジティブな動機を先、ネガティブは補足）
3. **相手を責めない表現**（「説明が曖昧」→「自分が理解できない状態」）
4. **企業別に具体化する**（[具体的なツール名]のままにしない）
5. **「完成している部分」と「今後の予定」を分けて話す**（事実と違う説明を避ける）

---

_統合日: 2026年2月17日_
_ソース: interview-prep.md, argus-interview-guide.md, interview_episodes.md, interview-episodes-review.md, PROJECT_STRUCTURE_AND_CODEBASE_GUIDE.md, TECH_STACK_AND_ARCHITECTURE.md_
