# 転職活動 完全ガイド

> **作成日**: 2026年2月17日
> **プロフィール**: 九工大情報工学卒(2025.3)、実務1年、TypeScript/Next.js/React/Node.js/Claude Code/Firebase
> **絶対条件**: フルリモート、正社員、SES除外
> **最大の武器**: Argus（12パッケージ monorepo、1,165+テスト、Claude Agent SDK統合、MCPサーバー設計）
> **目標年収**: 450万〜550万円（AI駆動開発プレミアム込み）

---

## 本ガイドの構成

| Part | 内容 | 概要 |
|------|------|------|
| **Part 1** | [ロードマップ（10週間計画）](#part-1-転職活動-完全ロードマップ-v2) | 全体タイムライン、Phase別タスク、リスク管理 |
| **Part 2** | [企業ランキング（27社）](#part-2-企業ランキング27社) | Tier 1/2/3 の志望企業リスト、年収・技術スタック比較 |
| **Part 3** | [面接対策 — 個人エピソード](#part-3-面接対策--個人エピソード) | 志望動機、自己PR、強み弱み、ストレス対処 |
| **Part 4** | [面接対策 — エピソード添削メモ](#part-4-面接対策--エピソード添削メモ) | 各エピソードの改善点と修正版 |
| **Part 5** | [面接対策 — Argus技術Q&A](#part-5-面接対策--argus技術qa) | 38問の技術面接想定Q&A |
| **Part 6** | [面接対策 — Argus完全ガイド](#part-6-面接対策--argus完全ガイド) | エレベーターピッチ、アーキテクチャ説明、企業別対策 |
| **Part 7** | [Argus コードベースガイド](#part-7-argus-コードベースガイド) | 12パッケージ構成、コード解説、設計パターン |
| **Part 8** | [Argus 技術スタック＆アーキテクチャ](#part-8-argus-技術スタックアーキテクチャ) | ADR形式の技術選定ガイド、15章構成 |
| **Appendix A** | [ポートフォリオ戦略](#appendix-a-ポートフォリオ戦略) | Argus中心のポートフォリオ構成、企業別刺さりポイント |
| **Appendix B** | [ベストプラクティス レポート](#appendix-b-ベストプラクティス-レポート) | エージェント比較、プラットフォーム、年収交渉 |

---


---

# Part 1: 転職活動 完全ロードマップ v2


> **プロフィール**: 九工大情報工学卒(2025.3)、実務1年、TypeScript/Next.js/React/Node.js/Claude Code/Firebase
> **絶対条件**: フルリモート、正社員、SES除外
> **最大の武器**: Argus（12パッケージ monorepo、1,165+テスト、Claude Agent SDK統合、MCPサーバー設計）
> **目標年収**: 450万〜550万円（AI駆動開発プレミアム込み）

---

## 既存ロードマップからの改善点

| 旧版の課題                              | v2 での改善                                                  |
| --------------------------------------- | ------------------------------------------------------------ |
| 準備に4ヶ月は長すぎる。市場は動いている | **10週間に短縮**。準備と応募を並行実施                       |
| AWSサブプロジェクトに2-3週間            | **1週間のミニマム実装**に圧縮。ラッコ以外はAWS不要           |
| Zenn 5本を全部書いてから応募            | **2本書いたら即応募開始**。残りは並行執筆                    |
| 英語面接対策が Month 3 に後回し         | **Day 1 から英語環境に慣れる**（Tech Podcast, README英語化） |
| ポートフォリオサイト構築が含まれる      | **不要。GitHub + Zenn + Findy で十分**                       |
| スカウト型サービスの登録が遅い          | **Week 1 で即登録**。スカウトは時間がかかるので早く撒く      |
| 面接練習が計画に入っていない            | **Week 4 からカジュアル面談で実戦練習**                      |
| 内定タイミングの調整戦略が薄い          | **選考ステージ同期の具体的手法**を追加                       |

---

## 全体タイムライン（10週間）

```
Week 1-2  ━━ 基盤整備（GitHub, Findy, LAPRAS, 職務経歴書, Zenn記事 #1）
Week 3-4  ━━ 攻撃準備（AWS mini, Zenn記事 #2, カジュアル面談開始）
Week 5-6  ━━ 第1波応募（Tier 1 企業 5-7社, 面接練習, LeetCode）
Week 7-8  ━━ 第2波応募（Tier 2 企業 5-8社, 面接本番）
Week 9-10 ━━ 内定交渉（オファー比較, 年収交渉, 最終決定）
```

**並行して常時実行するもの:**

- LeetCode（1日1問、朝30分）
- 英語リスニング（通勤・家事中に Tech Podcast）
- 面接振り返りメモ（各面談・面接後24時間以内）

---

## Phase 1: 基盤整備（Week 1-2）

### Week 1: 即行動タスク

> 目的: スカウトの種を撒き、職務経歴書を仕上げる

#### Day 1-2: プラットフォーム登録

| サービス         | 優先度 | 登録時のポイント                                                            |
| ---------------- | ------ | --------------------------------------------------------------------------- |
| **Findy**        | ★★★★★  | GitHub連携必須。Argusの1,165+テスト・12パッケージがスキル偏差値に反映される |
| **LAPRAS**       | ★★★★★  | GitHub + Zenn連携。技術アウトプットが自動ポートフォリオ化                   |
| **転職ドラフト** | ★★★★☆  | レジュメ審査後に企業から年収提示。市場価値の客観指標になる                  |
| **Green**        | ★★★★☆  | IT業界最大級。フルリモート検索しやすい。「気になる」ボタンでカジュアル面談  |
| **Forkwell**     | ★★★☆☆  | フルリモート求人充実。ポートフォリオ機能あり                                |

**注意**: 全サービスに同じプロフィール文を使い回さない。各プラットフォームの特性に合わせて微調整する。

#### Day 2-3: 職務経歴書の作成

```markdown
■ 職務要約（5行以内）
九州工業大学情報工学卒。〇〇にてTypeScript/Next.js/React/Firebaseを用いた
Webアプリケーション開発に従事。並行して個人プロジェクト「Argus」を開発し、
Claude Agent SDK統合・MCPサーバー設計・1,165+テストを含む12パッケージ
monorepoを構築。AI駆動開発で開発生産性を最大化する実践者。

■ 技術スキル
【言語】 TypeScript, JavaScript
【フロントエンド】React 19, Next.js 16
【バックエンド】 Node.js, Hono
【DB/ORM】 PostgreSQL, Drizzle ORM, Firebase/Firestore
【AI/LLM】 Claude Code, Claude Agent SDK, MCP (Model Context Protocol)
【テスト】 Vitest（1,165+テスト実績, TDD）
【インフラ】 Railway, Cloudflare Tunnel, Docker, PM2
【その他】 pnpm monorepo, Git/GitHub, GitHub Actions

■ 職務経歴
[現職] 20XX年X月〜現在

- Situation: [チーム構成・プロジェクト概要]
- Task: [自分の担当範囲]
- Action: [具体的にやったこと 3点]
- Result: [定量的な成果]

■ 個人プロジェクト: Argus
概要: Claude Agent SDKを中核としたマルチエージェントシステム
規模: 12パッケージ pnpm monorepo, 1,165+テスト, 18 DBテーブル
技術: TypeScript, Next.js, React, Drizzle ORM, Supabase, Claude Agent SDK, MCP
特徴:

- Observation-First Architecture（Hook ベースのリアルタイム観測）
- 4つのMCPサーバー（Knowledge, Personal, Gmail, Calendar）
- Session-per-Thread モデルによる並行タスク管理
- Episodic Memory による自己改善機構
  GitHub: [URL]

■ 自己PR
「AIを使って開発する」ではなく「AI駆動の開発ワークフローを設計できる」エンジニア。
Claude Code のスキル・フック・MCPサーバーを設計し、個人で12パッケージ・1,165テストの
規模を実現。AI時代の開発生産性を組織に展開できる。
```

**職務経歴書チェックリスト:**

- [ ] 数値が入っているか（テスト数、パッケージ数、チーム規模、成果）
- [ ] 「なぜ」が語られているか（技術選定理由、設計判断）
- [ ] 募集要件とのマッチングが明確か
- [ ] A4で2-3枚に収まっているか
- [ ] レバテックキャリアのエージェントに添削依頼する

#### Day 3-5: Argus README.md 整備

**README.md の必須セクション:**

```markdown
# Argus 🔭

AI エージェントの運用を自動化するマルチエージェントシステム

## Why I Built This

[課題] AIエージェントの「動くデモ」はたくさんあるが、本番運用に耐えるシステムは少ない
[解決] 観測可能性・障害復旧・コスト管理を体系的に解決するシステムを構築

## Architecture

[Mermaid図: 3層構造]

- Application Layer: Slack Bot, Agent Orchestrator, Dashboard
- Core Layer: Agent Core (Claude Agent SDK), DB (Drizzle ORM)
- Integration Layer: 4 MCP Servers

## Key Design Decisions

| 判断            | 選択               | 理由                                       |
| --------------- | ------------------ | ------------------------------------------ |
| エージェントSDK | Claude Agent SDK   | CLI→SDK移行で型安全+Hook観測を獲得         |
| DB/ORM          | Drizzle + Supabase | Firebase→PostgreSQLで関係データモデリング  |
| ツール統合      | MCP                | ネイティブツール統合+権限分離+プロセス分離 |
| 観測            | Hook-based         | リアルタイム観測+ログ解析不要              |

## Tech Stack

TypeScript / Next.js 16 / React 19 / Node.js / Drizzle ORM / PostgreSQL
Claude Agent SDK / MCP / Vitest / pnpm / Docker / Railway / PM2

## Testing

1,165+ tests across 12 packages

- Unit Tests: コロケーション方式（.ts と .test.ts を同ディレクトリに配置）
- SDK Mock: fakeStream() で AsyncGenerator をモック
- MCP Tests: ロールベース権限（Collector/Executor）の検証

## Screenshots / Demo

[ダッシュボード画面] [Slack Bot 動作画面] [デモ動画リンク]
```

**README 整備チェックリスト:**

- [ ] Mermaid アーキテクチャ図を作成
- [ ] テストバッジ（CI passing, カバレッジ）を追加
- [ ] スクリーンショット 3-5枚を撮影
- [ ] 1-2分のデモ動画を撮影（Loom or YouTube）
- [ ] .env.example を作成
- [ ] git log で機密情報の痕跡をチェック

#### Day 5-7: Zenn 記事 #1 執筆

**テーマ: 「Claude Agent SDKでマルチエージェントシステムを構築した全記録」**

構成:

1. なぜ作ったか（200字）
2. アーキテクチャ概要（図付き）
3. CLI→SDK移行の判断と実装（Before/After コード付き）
4. Hook ベース観測の設計（なぜログ解析ではダメか）
5. MCP サーバーの権限分離設計
6. 失敗と学び（Slack Socket Mode 多重起動問題 etc.）
7. まとめ

**目標: 5,000-8,000字、コード例は全体の30%以下**

#### Day 5-7: エージェント登録

| エージェント           | 登録理由                                              |
| ---------------------- | ----------------------------------------------------- |
| **レバテックキャリア** | IT特化最大手。年収交渉力が強い。フルスタック求人豊富  |
| **Geekly**             | Web/IT特化。独占求人あり。内定まで平均1ヶ月のスピード |

**初回面談で聞くこと:**

- 自分のスキルセットでの市場価値（想定年収レンジ）
- AI駆動開発経験の評価度合い
- 職務経歴書のフィードバック
- フルリモート × 実務1年の求人状況

---

### Week 2: 基盤完成

#### Day 8-10: GitHub Profile 整備

`otsukiryusuke/otsukiryusuke` リポジトリに README.md を作成:

- 1行自己紹介
- 技術スタックバッジ（TypeScript, React, Next.js, Node.js, Claude等）
- Argus の概要 + リンク
- Zenn 記事の最新一覧
- GitHub Stats カード

**ピン留めリポジトリ:**

1. Argus（メイン）
2. argus-aws（Phase 2 で作成後に追加）

#### Day 8-10: 機密情報サニタイズ

```bash
# API キー・トークンの痕跡チェック
git log -p | grep -iE "secret|token|key|password|apikey" | head -50

# .env の確認
cat .gitignore  # .env が含まれているか

# Slack チャンネル ID、メールアドレスのハードコード確認
grep -rn "C0[A-Z0-9]\{8\}" src/  # Slack channel ID パターン
grep -rn "@.*\.com" src/           # メールアドレス
```

#### Day 11-14: Zenn 記事 #1 公開 + 記事 #2 着手

記事 #2 テーマ候補（優先順）:

1. 「12パッケージ pnpm monorepo の設計判断」
2. 「CLAUDE.md 設計パターン — AI駆動開発のコンテキストエンジニアリング」
3. 「MCPサーバーの設計と実装パターン」

#### Day 11-14: LeetCode 開始

**初週のルーティン:**

- 朝30分、LeetCode Easy を1日1問
- Week 2 の目標: Easy 7問完了
- 使用言語: TypeScript
- 対象パターン: Array, String, HashMap

**推奨問題（最初の7問）:**

1. Two Sum
2. Valid Parentheses
3. Merge Two Sorted Lists
4. Best Time to Buy and Sell Stock
5. Valid Palindrome
6. Linked List Cycle
7. Maximum Subarray

---

## Phase 2: 攻撃準備（Week 3-4）

### Week 3: AWS Mini + カジュアル面談開始

#### AWS ミニマム実装（5日間で完了）

> 目的: ラッコの「AWS を用いた Web アプリ開発経験」要件を最低限クリア

```
argus-aws/
├── infrastructure/
│   └── cdk/                 # AWS CDK (TypeScript)
├── functions/
│   ├── create-knowledge/    # Lambda: ナレッジ作成
│   ├── search-knowledge/    # Lambda: ナレッジ検索
│   └── list-knowledge/      # Lambda: ナレッジ一覧
├── README.md                # アーキテクチャ図 + 技術選定理由
└── package.json
```

| AWS サービス | 用途                | Free Tier                   |
| ------------ | ------------------- | --------------------------- |
| Lambda       | API 処理            | 月100万リクエスト無料       |
| API Gateway  | REST エンドポイント | 月100万コール無料（12ヶ月） |
| DynamoDB     | データ保存          | 25GB 永久無料               |
| CDK          | インフラ定義        | 無料                        |

**5日間スケジュール:**

- Day 1: AWS アカウント作成 + CDK セットアップ
- Day 2: Lambda + API Gateway 実装
- Day 3: DynamoDB 統合
- Day 4: デプロイ + テスト
- Day 5: README 作成 + GitHub 公開

#### カジュアル面談開始（Week 3-4 で 5-8社）

**最初の面談は「練習」と割り切る。**

| 順番    | 企業タイプ   | 目的                             |
| ------- | ------------ | -------------------------------- |
| 1-3社目 | 志望度 低-中 | 面談スキル向上、質問の練度向上   |
| 4-5社目 | 志望度 中    | 企業理解を深め、本命面接に備える |
| 6-8社目 | 志望度 高    | 本命企業のカジュアル面談         |

**面談前の準備（各社15分）:**

1. 事業内容・プロダクトを理解
2. 技術ブログ・エンジニア採用ページを読む
3. 質問を3つ用意（技術・働き方・成長環境）
4. Argus の URL を事前に共有

**面談中に確認するチェックリスト:**

- [ ] フルリモートの実態（出社頻度、コミュニケーション手段）
- [ ] 技術スタックと選定プロセス
- [ ] AI コーディングツールの導入状況
- [ ] テスト文化・CI/CD 運用
- [ ] オンボーディングプロセス
- [ ] エンジニアの成長支援（1on1, 勉強会, 書籍補助等）
- [ ] 入社1年後の期待値

**面談後（24時間以内）:**

- お礼メッセージを送信
- 振り返りメモを記録（良かった点、改善点、企業の印象）

### Week 4: Zenn 記事 #2 + 面接対策

#### Zenn 記事 #2 公開

#### 面接対策（自己紹介・Argus 説明の練習）

**2分バージョン（カジュアル面談用）:**

> 九州工業大学情報工学卒で、現在 Web エンジニアとして実務1年の経験があります。
> TypeScript/Next.js/React で開発しています。
>
> 並行して「Argus」という個人プロジェクトを開発しています。
> これは Claude Agent SDK を使ったマルチエージェントシステムで、
> Slack から自然言語でタスク実行・リサーチ・SNS投稿までを自動化します。
>
> 特にこだわったのは「AIの行動を信頼するのではなく検証可能にする」設計思想です。
> Hook ベースで全ツール実行をリアルタイムに記録し、
> MCP サーバーで権限分離を実現しています。
> 12パッケージの monorepo で 1,165 以上のテストがあります。
>
> 転職ではAI駆動開発を組織として推進している環境で、
> この経験を活かしてチームの生産性向上に貢献したいと考えています。

**5分バージョン（技術面接用）:**

- 上記 + アーキテクチャの3層構造説明
- CLI→SDK 移行の判断理由
- MCP 採用の理由（3点）
- 失敗と学び（1つ）

**練習方法:**

- 録音して聞き返す（1日1回、5分）
- 時間を計る（2分/5分に収まるか）
- 想定質問への回答を3往復分用意

---

## Phase 3: 第1波応募（Week 5-6）

### 応募企業（Tier 1: 確実に応募可能）

| #   | 企業                | 応募方法   | 志望度 | 特記事項                            |
| --- | ------------------- | ---------- | ------ | ----------------------------------- |
| 1   | **ラッコ**          | HERP直接   | ★★★★★  | AWS経験必須→argus-aws完成後に応募   |
| 2   | **アシアル**        | HERP/Green | ★★★★☆  | 第二新卒歓迎。技術スタック完全一致  |
| 3   | **Sales Marker**    | Japan Dev  | ★★★★☆  | 1年OK。Next.js/React。日本語不要    |
| 4   | **HENNGE**          | TokyoDev   | ★★★★☆  | TypeScript 1年OK。高年収650-900万   |
| 5   | **Helpfeel**        | HERP       | ★★★★☆  | React/Node.js 1年。完全フルリモート |
| 6   | **SO Technologies** | paiza      | ★★★☆☆  | React/Node.js 1年明記               |
| 7   | **CaSy**            | paiza      | ★★★☆☆  | 経験1年明記。上場企業。練習も兼ねて |

### 応募順序の戦略

```
Week 5 前半: CaSy, SO Technologies, アシアル（練習 + 確保）
Week 5 後半: Sales Marker, HENNGE（外資系に挑戦）
Week 6 前半: Helpfeel, ラッコ（本命）
```

**なぜこの順番か:**

1. 志望度低めの企業で面接のリズムを作る
2. 外資系で英語面接の経験値を積む
3. 本命は面接スキルが最も高まった Week 6 に

### 選考ステージ同期の戦略

**目標: Week 8-9 で複数社の最終面接が重なるようにする**

| テクニック           | やり方                                                      |
| -------------------- | ----------------------------------------------------------- |
| 応募タイミング調整   | 本命は少し遅らせて応募                                      |
| 選考速度の調整       | 「他社の選考も進めており、〇月〇日頃に判断したい」と伝える  |
| エージェント活用     | レバテック/Geekly経由の企業はエージェントがスケジュール調整 |
| カジュアル面談の活用 | 本命企業はカジュアル面談→本選考で時間を稼ぐ                 |

### 面接対策（並行実施）

#### コーディングテスト対策

**Week 5-6 の目標: LeetCode Easy 30問完了 + Medium 10問開始**

| 週     | 目標                    | パターン                      |
| ------ | ----------------------- | ----------------------------- |
| Week 5 | Easy 残り + Medium 開始 | Binary Search, Sliding Window |
| Week 6 | Medium 10問             | BFS/DFS, Stack/Queue          |

**paiza 対策（エックスポイントワン向け）:**

- paiza のスキルチェックで B ランク以上を目指す
- TypeScript で受験

#### 行動面接（STAR法）対策

5つのエピソードを完璧に仕上げる:

| #   | テーマ                     | STAR                                                 |
| --- | -------------------------- | ---------------------------------------------------- |
| 1   | 技術的に最も困難だった問題 | Slack Socket Mode 多重起動問題                       |
| 2   | 設計判断で迷ったこと       | CLI→SDK 移行の判断                                   |
| 3   | 失敗から学んだこと         | detectTaskFailure() の必要性に気づくまで             |
| 4   | 生産性を上げた経験         | Claude Code のスキル・フックで開発ワークフロー自動化 |
| 5   | チームに貢献した経験       | テレアポのスクリプト共有でチーム成果1.3倍            |

---

## Phase 4: 第2波応募（Week 7-8）

### 応募企業（Tier 2 + 挑戦枠）

| #   | 企業                 | 応募方法   | 志望度 | 特記事項                                      |
| --- | -------------------- | ---------- | ------ | --------------------------------------------- |
| 8   | **テックタッチ**     | HERP       | ★★★★★  | AI Agent事業=Claude Agent SDK経験が直接活きる |
| 9   | **ちょっと株式会社** | HERP       | ★★★★☆  | Vercelエキスパート。Next.js特化               |
| 10  | **GitLab**           | Greenhouse | ★★★★☆  | スキルベース評価。AI Editor Extensions        |
| 11  | **HERP**             | HERP       | ★★★☆☆  | TypeScript/React + Haskell。少数精鋭          |
| 12  | **カミナシ**         | HERP       | ★★★☆☆  | TypeScript/React/Go。IVS LAUNCHPAD優勝        |
| 13  | **note**             | Talentio   | ★★★★★  | 経験3年目安だがAI活用要件で差別化             |
| 14  | **GameWith**         | Green      | ★★★☆☆  | 数字で成果を語る面接文化                      |
| 15  | **Automattic**       | 公式サイト | ★★★☆☆  | コードテスト評価。100%リモート                |

### 並行管理

**スプレッドシートで管理する項目:**

| 企業名 | 応募日 | 応募経路 | 選考状況 | 次のアクション | 期限 | 志望度 | 年収提示 | メモ |
| ------ | ------ | -------- | -------- | -------------- | ---- | ------ | -------- | ---- |

### Zenn 記事の追加執筆（並行）

Week 7-8 で記事 #3 を公開:

- 「MCPサーバーの設計と実装 — エージェントのツール拡張を疎結合に」
- または「実務1年エンジニアが1,165テストを書いた理由とテスト戦略」

---

## Phase 5: 内定交渉（Week 9-10）

### 内定が出たら

#### Step 1: 冷静に情報を整理

| 評価項目                   | Weight | A社 | B社 | C社 |
| -------------------------- | ------ | --- | --- | --- |
| 年収                       | 25%    |     |     |     |
| 技術スタック一致度         | 20%    |     |     |     |
| フルリモート実態           | 15%    |     |     |     |
| AI駆動開発の推進度         | 15%    |     |     |     |
| 成長環境（メンター、1on1） | 10%    |     |     |     |
| 事業の将来性               | 10%    |     |     |     |
| 企業カルチャー             | 5%     |     |     |     |

#### Step 2: 年収交渉

**交渉の5原則:**

1. **複数オファーを持つ**: 最低2社のオファーがある状態で交渉
2. **第一志望を明確にしつつ条件提示**: 「御社が第一志望だが、他社から〇〇万円のオファーもある」
3. **嘘はつかない**: 数字の水増しは絶対にNG
4. **年収以外も交渉材料に**: リモート手当、書籍補助、学習時間、技術選定の裁量
5. **エージェント経由が有利**: 自分で直接より心理的負担が少なく、相場感もサポート

**交渉のセリフ例:**

> 「他社からも内定をいただいており、年収〇〇万円の提示を受けています。
> 御社が第一志望ですので、同水準でご検討いただけないでしょうか。
> 年収に限らず、技術選定の裁量やリモートワーク環境など、
> 総合的に判断して決めたいと考えています。」

#### Step 3: 最終決定

**内定承諾前の最終チェックリスト:**

- [ ] 年収（基本給+賞与+手当）の確認
- [ ] フルリモートの具体的運用（出社頻度、コミュニケーションツール）
- [ ] 試用期間の条件
- [ ] 技術スタック・プロジェクトの確認
- [ ] チーム構成（直属の上長、チームメンバー）
- [ ] オンボーディングプロセス
- [ ] 退職交渉のスケジュール（現職に最低1ヶ月前、できれば2ヶ月前に通知）

---

## 週次チェックリスト

### Week 1

- [ ] Findy 登録 + GitHub 連携
- [ ] LAPRAS 登録 + GitHub/Zenn 連携
- [ ] 転職ドラフト登録 + レジュメ作成
- [ ] Green 登録
- [ ] 職務経歴書 初版作成
- [ ] Argus README.md 整備開始（Mermaid 図、スクリーンショット）
- [ ] レバテックキャリア登録 + 初回面談予約
- [ ] LeetCode アカウント作成 + Easy 3問

### Week 2

- [ ] Argus README.md 完成 + 機密情報チェック
- [ ] GitHub Profile README 作成
- [ ] デモ素材作成（スクリーンショット 3-5枚、動画 1-2分）
- [ ] Zenn 記事 #1 執筆・公開
- [ ] Geekly 登録 + 初回面談
- [ ] 職務経歴書をエージェントに添削依頼
- [ ] LeetCode Easy +4問（累計7問）

### Week 3

- [ ] AWS アカウント準備 + CDK セットアップ
- [ ] argus-aws 実装（Lambda + API Gateway + DynamoDB）
- [ ] argus-aws README 作成 + GitHub 公開
- [ ] Zenn 記事 #2 着手
- [ ] カジュアル面談 2-3社（練習）
- [ ] LeetCode Easy +7問（累計14問）

### Week 4

- [ ] Zenn 記事 #2 公開
- [ ] カジュアル面談 3-5社（本命含む）
- [ ] 面接対策：2分自己紹介を録音・改善
- [ ] 面接対策：STAR エピソード 5つを仕上げ
- [ ] LeetCode Easy +7問（累計21問）+ Medium 開始

### Week 5

- [ ] Tier 1 企業に応募開始（CaSy, SO Technologies, アシアル）
- [ ] Tier 1 企業に応募（Sales Marker, HENNGE）
- [ ] 面接（1次面接が入り始める）
- [ ] LeetCode Easy 完了（30問）+ Medium 5問

### Week 6

- [ ] Tier 1 企業に応募（Helpfeel, ラッコ）
- [ ] 面接（1次〜2次）
- [ ] 面接振り返りメモを毎回記録
- [ ] Zenn 記事 #3 着手
- [ ] LeetCode Medium +5問（累計10問）

### Week 7

- [ ] Tier 2 企業に応募開始（テックタッチ, ちょっと, GitLab等）
- [ ] 挑戦枠応募（note, Automattic）
- [ ] 面接（2次〜最終に近づく企業あり）
- [ ] Zenn 記事 #3 公開

### Week 8

- [ ] 面接（最終面接が集中するように調整）
- [ ] 選考ステージの同期確認
- [ ] 内定が出始めたら比較表作成

### Week 9

- [ ] 内定交渉（年収、条件）
- [ ] 複数オファーの比較検討
- [ ] 最終決定

### Week 10

- [ ] 内定承諾
- [ ] 現職への退職交渉
- [ ] 入社準備

---

## 各企業別の志望動機テンプレート

### ラッコ（最有力候補）

> AI活用を積極推進されている御社の姿勢に強く共感します。私はArgusでClaude Agent SDKとMCPサーバーを統合し、AI駆動開発の生産性を実証してきました。「人間ならではの判断と設計に集中する」という御社の方針は、私がArgusで実践してきた「AIの行動を検証可能にする」設計思想と一致しています。AWS経験としてはCDKでのインフラ定義とLambda/DynamoDB/API Gatewayでの実装経験があります。

### テックタッチ（AI Agent事業）

> AI Agent事業をゼロから立ち上げるという御社のフェーズに、私のClaude Agent SDK統合経験が直接貢献できると考えます。Argusで培ったMCPサーバーの権限分離、Hook ベースの観測、Episodic Memoryによる自己改善の設計パターンは、企業向けAI Agentの品質・安全性設計にそのまま応用できます。

### note（挑戦枠）

> 「生成AIツールやAIコーディングエディタを日常的に活用」という御社の必須要件は、私の最大の強みそのものです。Claude Codeのスキル・フック・MCPサーバーを設計し、開発ワークフロー自体をAI化する取り組みは、AI活用のレベル4（ワークフロー設計）に該当すると自負しています。経験年数は足りませんが、AI活用の深度と実装力でカバーできると考えています。

### GitLab（外資系挑戦枠）

> AI Editor Extensions チームのポジションに強い関心があります。ArgusでClaude Agent SDKのHookシステムをブリッジする `buildSDKHooks()` を実装した経験は、エディタ拡張のツール統合設計に直接活かせます。MCPプロトコルによるツール拡張の実装経験も、GitLab Duoの機能拡張に貢献できると考えています。

---

## リスク管理

### リスク1: 全滅した場合

**対策**: Week 6 の時点で書類選考の通過率を確認。通過率 30%以下なら:

- 職務経歴書の再添削
- 応募企業のレンジを広げる（Tier 3 を前倒し）
- Wantedly でカジュアル面談を増やす

### リスク2: 内定が1社だけの場合

**対策**: 交渉力が弱くなるので:

- 承諾期限の延長を依頼（1-2週間）
- 追加で 3-5社に急ぎ応募
- エージェントに「急ぎ応募可能な企業」を紹介してもらう

### リスク3: 年収が希望に届かない場合

**対策**:

- 年収以外の条件（リモート手当、書籍補助、SO等）を含めた総報酬で判断
- 「入社後6ヶ月の成果をもとに年収を見直す条件」を提案
- 1-2年後の年収テーブルを確認

### リスク4: 現職の退職交渉が難航する場合

**対策**:

- 退職届は最低1ヶ月前、できれば2ヶ月前に提出
- 引き継ぎ計画を事前に作成
- 法的には退職届提出から2週間で退職可能（民法627条）

---

## 成功指標

| 指標             | 目標値                  |
| ---------------- | ----------------------- |
| カジュアル面談数 | 10社以上                |
| 本応募数         | 10-15社                 |
| 書類通過率       | 40%以上                 |
| 1次面接通過率    | 50%以上                 |
| 内定数           | 2-3社                   |
| 最終年収         | 450万円以上             |
| 活動期間         | 10週間以内              |
| Zenn 記事数      | 3本以上                 |
| LeetCode         | Easy 30問 + Medium 15問 |

---

## 参考ドキュメント（同ディレクトリ内）

| ファイル                        | 内容                                               |
| ------------------------------- | -------------------------------------------------- |
| `final-ranking.md`              | 企業ランキング 27社の詳細                          |
| `interview-prep.md`             | Argus ベースの想定質問と回答集 38問                |
| `interview_episodes.md`         | 面接エピソード集（志望動機、ガクチカ、転職理由等） |
| `interview-episodes-review.md`  | エピソード集の添削メモ                             |
| `argus-interview-guide.md`      | Argus 面接対策完全ガイド                           |
| `portfolio-strategy.md`         | ポートフォリオ戦略                                 |
| `job-hunting-best-practices.md` | 転職活動ベストプラクティス                         |
| `action-plan.md`                | 旧版アクションプラン（v1）                         |

---

## 情報源

- [2026年 ITエンジニア転職市場予測 - エンジニアtype](https://type.jp/et/feature/29295/)
- [IT転職エージェントおすすめ比較 - Qiita Job Change](https://jobs.qiita.com/best-agent-it/)
- [転職で差がつくGitHub 7つのポイント - RUNTEQ](https://runteq.jp/blog/portfolio/29737/)
- [コーディング面接対策 LeetCode 60問](https://1kohei1.com/leetcode/)
- [SE職務経歴書テンプレート - doda](https://doda.jp/guide/syokureki/resume/it01.html)
- [エンジニア採用のカジュアル面談 - back check](https://site.backcheck.jp/knowledge/engineer-casual-interview)

---

_作成日: 2026年2月17日_
_旧版: action-plan.md (2026年2月14日) を全面改訂_

---

# Part 2: 企業ランキング（27社）


**候補者プロフィール**: 九工大情報工学卒(2025.3)、実務経験約1年、TypeScript/Next.js/React/Node.js/Claude Code/Firebase
**絶対条件**: フルリモート、正社員、SES除外
**強み**: Argus（11パッケージ pnpm monorepo、899+テスト、Claude Agent SDK統合、MCPサーバー設計）

---

## Tier 1: 確実に応募可能（経験1年が明記 or 第二新卒歓迎）

### 1. ラッコ株式会社
- **事業**: ラッコキーワード、中古ドメイン等のWebツール群
- **ポジション**: フルスタックエンジニア
- **必須経験**: 1年以上（明記）
- **年収**: 450万〜700万円
- **リモート**: フルリモート
- **技術スタック**: TypeScript, React, Next.js, AWS, Docker
- **特徴**: AI活用を積極推進、テキストコミュニケーション文化
- **注意**: **AWS経験が必須**（AWS補強プロジェクトが必要）
- **応募URL**: https://herp.careers/v1/rakko

### 2. アシアル株式会社
- **事業**: Monaca/Onsen UI（モバイルアプリ開発環境）、受託開発
- **ポジション**: 新卒/第二新卒エンジニア
- **必須経験**: 第二新卒歓迎（年数要件なし）
- **年収**: 460万〜600万円
- **リモート**: フルリモート（研修1-2ヶ月のみ週2-3出社の場合あり）
- **技術スタック**: TypeScript, React, Vue.js, Node.js, Next.js, Jest, AWS, Firebase, Vercel
- **特徴**: グローバルチーム（多国籍）、AI活用（Copilot, ChatGPT）に積極的、メンター制度あり
- **応募URL**: https://herp.careers/v1/asial/KZo_FKHY2qVp / https://www.green-japan.com/company/3072/job/237984

### 3. 株式会社CaSy
- **事業**: 家事代行マッチングプラットフォーム（東証グロース上場）
- **ポジション**: Web開発エンジニア
- **必須経験**: 1年以上（言語不問、明記）
- **年収**: 推定400万〜600万円
- **リモート**: フルリモート・フルフレックス（コアタイムなし）
- **技術スタック**: TypeScript, React.js, Redux, Ruby on Rails, Python, Docker, MySQL
- **特徴**: 第二新卒・スキルチェンジ歓迎と明記、上場企業
- **応募URL**: https://paiza.jp/career/job_offers/22097

### 4. SO Technologies株式会社
- **事業**: 中小企業向けデジタルマーケティング支援SaaS
- **ポジション**: 自社プロダクト開発エンジニア
- **必須経験**: React/Node.js実務1年以上（明記）
- **年収**: 800万〜1,200万円（paiza掲載レンジ、実際は要確認）
- **リモート**: フルリモート（リモート勤務手当あり）
- **技術スタック**: React.js, Node.js, Go, Python, AWS
- **特徴**: フラットな組織、自社プロダクト開発
- **応募URL**: https://paiza.jp/career/job_offers/9012

### 5. Sales Marker（外資系）
- **事業**: Intent Sales プラットフォーム（日本No.1）
- **ポジション**: Front-End Engineer
- **必須経験**: 1年以上（明記）
- **年収**: 500万〜700万円
- **リモート**: フルリモート（日本在住必須）
- **技術スタック**: Next.js, React, TypeScript, Node.js
- **特徴**: 日本語不要、16カ国以上のグローバルチーム、Google/Microsoft/Mercari出身メンバー
- **応募URL**: https://japan-dev.com/jobs/sales-marker/sales-marker-front-end-engineer-2u8l5d

### 6. HENNGE（外資系 / 東証グロース上場）
- **事業**: クラウドセキュリティ（SaaS認証基盤）
- **ポジション A**: Junior Full Stack Developer (TypeScript) — 1年以上
- **ポジション B**: Junior Front-end Engineer (Vue) — Vue 3実務1年以上
- **年収**: 650万〜900万円
- **リモート**: フルリモート（日本在住必須）
- **技術スタック**: TypeScript, Vue 3, Composition API
- **特徴**: 日本語不要、英語が社内公用語
- **応募URL**: https://www.tokyodev.com/companies/hennge/

### 7. Helpfeel（旧Nota）
- **事業**: FAQ SaaS「Helpfeel」、Gyazo、Cosense（旧Scrapbox）
- **ポジション**: プロダクトエンジニア
- **必須経験**: React/Node.js実務1年以上
- **年収**: 推定500万〜750万円
- **リモート**: フルリモート・フルフレックス（2007年創業時から）
- **技術スタック**: React, TypeScript, Node.js, Express, MongoDB, GCP
- **特徴**: 創業時からフルリモート、実力・アウトプット重視、開発者向けプロダクト
- **応募URL**: https://herp.careers/v1/notainc/Nn_MkDbWHh02

---

## Tier 2: 応募可能性が高い（経験年数が柔軟 or スキルベース評価）

### 8. エックスポイントワン
- **事業**: DX推進コンサルティング + SaaS開発
- **ポジション**: エンジニア
- **必須経験**: 柔軟（年数不明確）
- **年収**: 400万〜700万円
- **リモート**: フルリモート
- **技術スタック**: TypeScript, React, Node.js
- **注意**: paizaコーディングテストあり（アルゴリズム対策必要）
- **応募URL**: https://paiza.jp/career/

### 9. GitLab（外資系 / 100%リモート企業）
- **事業**: DevSecOpsプラットフォーム（世界最大のオールリモート企業）
- **ポジション**: Intermediate Fullstack Engineer (TypeScript), AI Editor Extensions
- **必須経験**: 年数明記なし（スキルベース。「many successful candidates do not meet every single requirement」と明記）
- **年収**: 推定600万〜1,000万円（日本、ロケーションファクター調整後）
- **リモート**: 100%リモート（「Remote, Japan」明記、65カ国以上にメンバー）
- **技術スタック**: TypeScript, Node.js, Vue.js, CSS, Git
- **特徴**: AI関連（GitLab Duo）のエディタ拡張開発。候補者のClaude Agent SDK/MCP経験が活きる
- **英語要件**: ビジネスレベル（非同期・文書ベース）
- **応募URL**: https://job-boards.greenhouse.io/gitlab/jobs/8315155002

### 10. Automattic（外資系 / WordPress.com, Tumblr等）
- **事業**: WordPress.com, WooCommerce, Tumblr等
- **ポジション**: Experienced Software Engineer (JavaScript)
- **必須経験**: 年数明記なし（コードテスト+ペイドトライアルで実力評価）
- **年収**: $70,000〜$170,000 USD（グローバル共通、現地通貨払い）
- **リモート**: 100%リモート（92カ国1,730名以上）
- **技術スタック**: JavaScript (React), PHP, WordPress
- **特徴**: 年3-4週間のチームミートアップ旅行、無制限休暇、ホームオフィス補助
- **英語要件**: ビジネスレベル
- **注意**: PHP学習が必要
- **応募URL**: https://automattic.com/work-with-us/job/experienced-software-engineer/

### 11. ちょっと株式会社
- **事業**: 日本初のVercelエキスパートパートナー、Next.js/Vercel特化開発
- **ポジション**: フロントエンドエンジニア
- **必須経験**: 要確認
- **年収**: 450万〜1,000万円
- **リモート**: フルリモート・フルフレックス（約半数が東京以外から勤務）
- **技術スタック**: Next.js, React, TypeScript, Vercel, AWS
- **特徴**: Next.js特化、エンジニア比率60%以上
- **応募URL**: https://herp.careers/v1/chot/5y3cHQkAMhRM

### 12. カイテク株式会社
- **事業**: 介護・看護ワークシェアリングサービス
- **ポジション**: 開発エンジニア（フルスタック志向歓迎）
- **必須経験**: 要確認
- **年収**: 500万〜1,000万円
- **リモート**: フルリモート
- **技術スタック**: TypeScript, React, Python, Go, Firebase, AWS
- **特徴**: 少人数スタートアップ（正社員17名）、裁量大、社会的意義のある事業
- **応募URL**: https://www.green-japan.com/company/9477/job/201009

### 13. 株式会社HERP
- **事業**: 採用管理SaaS「HERP Hire」
- **ポジション**: 開発エンジニア
- **必須経験**: 要確認
- **年収**: 推定500万〜800万円
- **リモート**: フルリモート・フルフレックス
- **技術スタック**: TypeScript, React, Next.js, Haskell, PostgreSQL
- **特徴**: ストックオプション全社員対象、少数精鋭
- **応募URL**: https://herp.careers/v1/herpinc

### 14. 株式会社SalesNow
- **事業**: AI企業データクラウド（540万社データベース）
- **ポジション**: Webエンジニア
- **必須経験**: 要確認
- **年収**: 要確認
- **リモート**: フルリモート・フルフレックス
- **技術スタック**: TypeScript (Next.js), Python (FastAPI), PostgreSQL, AWS, GCP
- **特徴**: AI・データ領域で急成長中（累計6.5億円調達）
- **応募URL**: https://www.green-japan.com/company/10396

### 15. テックタッチ株式会社
- **事業**: デジタルアダプションプラットフォーム（国内シェアNo.1）
- **ポジション**: AI Agent事業エンジニア
- **必須経験**: 要確認
- **年収**: 500万〜
- **リモート**: フルリモート・フレックス
- **技術スタック**: TypeScript, React等
- **特徴**: **AI Agent事業をゼロから立ち上げ** — 候補者のClaude Agent SDK経験が直接活きる
- **応募URL**: https://herp.careers/v1/techtouch

### 16. 株式会社ROUTE06
- **事業**: 大手企業DX支援、ビジネスAPIプラットフォーム「Plain」
- **ポジション**: ソフトウェアエンジニア
- **必須経験**: 要確認
- **年収**: 要確認
- **リモート**: フルリモート（地方在住OK）、フルフレックス
- **技術スタック**: TypeScript, React, Next.js
- **特徴**: ストックオプション制度あり
- **応募URL**: https://jobs.route06.co.jp/

### 17. 株式会社カミナシ
- **事業**: 現場DX SaaS「カミナシ」（ノンデスクワーカー向け）
- **ポジション**: アプリケーションエンジニア
- **必須経験**: 要確認
- **年収**: 要確認
- **リモート**: リモートワーク主体（定期出社なし、年2回オフライン全社MTGのみ）
- **技術スタック**: TypeScript, React, Go, AWS
- **特徴**: IVS LAUNCHPAD優勝、フルスタックで業務範囲制限なし
- **応募URL**: https://herp.careers/v1/kaminashi

### 18. 株式会社トドケール
- **事業**: 郵便・配達物管理SaaS
- **ポジション**: フロントエンジニア
- **必須経験**: SIer出身歓迎（経験の浅い方にも門戸あり）
- **年収**: 500万〜900万円
- **リモート**: フルリモート可
- **技術スタック**: TypeScript, React, React Native, Python, Terraform
- **応募URL**: https://jobs.forkwell.com/todoker/jobs/10096

### 19. 株式会社コドモン
- **事業**: 保育・教育施設向け業務支援SaaS（24,000施設以上導入）
- **ポジション**: ソフトウェアエンジニア
- **必須経験**: 要確認
- **年収**: 要確認
- **リモート**: フルリモート（出社率20%程度）
- **技術スタック**: Nuxt.js, TypeScript, Kotlin, PHP
- **特徴**: 「0.5投資制度」（週0.5日を自己研鑽に使える）
- **注意**: フロントはVue.js系が中心
- **応募URL**: https://herp.careers/v1/codmon

---

## Tier 3: 挑戦枠（ダメ元 or 経験年数要件がやや高い）

### 20. GameWith
- **事業**: ゲーム情報メディア + NFTゲーム
- **ポジション**: フロントエンドエンジニア
- **必須経験**: 年数不明確
- **年収**: 450万〜700万円
- **リモート**: フルリモート
- **技術スタック**: TypeScript, React, Next.js
- **注意**: 「数字を持って成果を説明する」面接文化
- **応募URL**: https://www.green-japan.com/company/5609

### 21. note株式会社
- **事業**: クリエイター向けメディアプラットフォーム
- **ポジション**: Webエンジニア
- **必須経験**: 実務3年（目安）
- **年収**: 600万〜900万円
- **リモート**: フルリモート
- **技術スタック**: TypeScript, React, Next.js, Ruby
- **特徴**: **AI活用が必須要件**（希少）— 候補者の最大の強み
- **所感**: 経験年数は足りないが、AI活用要件で差別化できる可能性
- **応募URL**: https://open.talentio.com/r/1/c/note-corp/

### 22. Supabase（外資系 / オープンソースBaaS）
- **事業**: Firebase代替のオープンソースBaaS
- **ポジション**: Frontend Engineer (Dashboard)
- **必須経験**: 「deep experience」（年数明記なし、実質2-3年以上の可能性）
- **年収**: 非公開（米国スタートアップ水準 + ESOP）
- **リモート**: 100%ワールドワイドリモート（35カ国180名以上）
- **技術スタック**: React, TypeScript, Next.js, Postgres
- **特徴**: 候補者のSupabase/Firebase経験がプラス。monorepo/899テストの実績アピール可能
- **応募URL**: https://supabase.com/careers

### 23. 株式会社estie
- **事業**: 商業用不動産テック
- **ポジション**: フロントエンドエンジニア (React/TypeScript)
- **必須経験**: 要確認
- **年収**: 要確認
- **リモート**: リモート可（フルリモートかは要確認）
- **技術スタック**: React, TypeScript
- **応募URL**: https://hrmos.co/pages/estie/jobs/10000024

### 24. 株式会社IVRy
- **事業**: AI対話型音声SaaS
- **ポジション**: エンジニア
- **必須経験**: 要確認
- **年収**: 要確認
- **リモート**: 要確認
- **技術スタック**: TypeScript, React, Ruby on Rails, Python, AWS
- **特徴**: AI音声サービスという先端領域、急成長
- **応募URL**: https://herp.careers/v1/ivry

### 25. justInCaseTechnologies
- **事業**: InsurTech、保険基幹システム「joinsure」
- **ポジション**: TypeScriptエンジニア
- **必須経験**: TypeScript実装 + 設計リード経験（経験1年だとやや厳しい）
- **年収**: 要確認
- **リモート**: フルリモート（社員の3-4割が国内外からリモート）
- **技術スタック**: Next.js, TypeScript, NestJS, Vercel, ECS
- **応募URL**: https://herp.careers/v1/justincase/4pDDVWowHK4J

### 26. 株式会社COMPASS
- **事業**: AI型教材「Qubena」（2,300校以上導入）
- **ポジション**: Webフロントエンジニア (React/TypeScript)
- **必須経験**: 要確認（「ミドル」ポジションの記載あり）
- **年収**: 605万〜960万円
- **リモート**: フルリモート
- **技術スタック**: React, TypeScript, AI/ML
- **応募URL**: https://hrmos.co/pages/qubena/jobs/4_1_15

### 27. 株式会社immedio
- **事業**: 商談獲得自動化SaaS
- **ポジション**: フルスタックエンジニア
- **必須経験**: 要確認
- **年収**: 要確認（3.5億円調達済み）
- **リモート**: リモートワーク可（フルリモートかは要確認）
- **技術スタック**: Go, TypeScript, React, Next.js
- **応募URL**: https://herp.careers/v1/immedio/Ct_xZX8cLzsm

---

## 将来的に注目（現時点では要件不足）

| 企業 | 理由 | 再挑戦目安 |
|------|------|------------|
| **Vercel** | 3年以上必須（Next.js開発元で最適合だが） | 2年後 |
| **Grafana Labs** | Senior中心だがジュニア採用実績あり。ポジション開いたら応募 | 随時チェック |
| **LayerX** | 年収600万〜のレンジ、中堅以上想定 | 1-2年後 |
| **マネーフォワード** | 即戦力志向、ポテンシャル層は不利 | 1-2年後 |
| **SmartHR** | HTML/CSS/JS 3年 + React 2年必須 | 2年後 |
| **ちゅらデータ** | 3年 + リード経験必須 | 3年後 |
| **ミラティブ** | 2年以上目安 | 1年後 |
| **PayPay** | 4年以上必須 | 3年後 |
| **Mercari** | 週2出社ハイブリッド（フルリモート不可） | - |
| **Stripe** | New Grad枠あるがオフィス勤務の可能性大 | 要確認 |
| **Linear** | NA/Europeタイムゾーン限定（日本対象外） | - |
| **Anthropic** | 大半がオフィス勤務 | - |
| **OpenAI** | ほぼオフィス勤務 | - |

---

## 推奨応募順序

### 最優先（今すぐ応募）
1. **ラッコ** — AI活用推進 + フルリモート + 1年OK（AWS補強が先に必要）
2. **アシアル** — 第二新卒歓迎 + フルリモート + 技術スタック完全一致
3. **CaSy** — 経験1年明記 + フルリモート + 上場企業
4. **SO Technologies** — 実務1年OK + React/Node.js + フルリモート
5. **Sales Marker** — 1年OK + Next.js/React + グローバル環境

### 準優先（カジュアル面談から）
6. **HENNGE** — TypeScript 1年OK + フルリモート + 高年収
7. **Helpfeel** — React/Node.js 1年 + 完全フルリモート
8. **ちょっと株式会社** — Next.js/Vercel特化 + フルリモート
9. **テックタッチ** — AI Agent事業 = Claude Agent SDK経験が直接活きる
10. **GitLab** — スキルベース評価 + AI Editor Extensions

### 挑戦枠
11. **Automattic** — コードテスト評価 + 100%リモート
12. **note** — 経験3年目安だがAI活用要件で差別化
13. **Supabase** — OSS文化 + monorepo実績でアピール

---

## 定期チェック推奨サイト

| サイト | URL | 特徴 |
|--------|-----|------|
| **Green** | https://www.green-japan.com/search/area/98/skill/TypeScript | フルリモート + TypeScript |
| **Forkwell Jobs** | https://jobs.forkwell.com/select/full-time-remote-work-is-available | フルリモート可の厳選求人 |
| **paiza転職** | https://paiza.jp/career/job_offers/topics/full_remote | フルリモート特集 |
| **Findy** | https://findy-code.io/ | GitHub偏差値で評価（899+テストが高評価） |
| **HERP Careers** | https://herp.careers/careers/jobs?remote-work-type-ids=FULL_REMOTEWORK | スタートアップのフルリモート |
| **Japan Dev** | https://japan-dev.com/junior-jobs-in-japan | ジュニア向け外資系 |
| **TokyoDev** | https://www.tokyodev.com/jobs/fully-remote | フルリモート（英語環境） |
| **リラシク** | https://relasic.jp/ | フルリモート特化 |

---

## 候補者の最大のアピールポイント

1. **AI駆動開発のレベル4**: Claude Agent SDK統合、MCPサーバー設計 → 「AIワークフローを設計してチーム生産性を向上」
2. **テストカルチャー**: 899+テストは実務1年としては異例
3. **アーキテクチャ設計力**: 11パッケージ pnpm monorepo → 依存関係管理の実践知
4. **技術選定の判断力**: CLI → SDK移行、Firebase → Supabase + Drizzle移行

---

*調査日: 2026年2月13-14日*
*情報源: 各社採用ページ、Green、Forkwell、paiza、Findy、HERP Careers、Wantedly、Japan Dev、TokyoDev、Indeed、OpenWork、Glassdoor、Levels.fyi等*
*注意: 求人情報は随時変更されるため、応募前に必ず最新情報を確認してください*

---

# Part 3: 面接対策 — 個人エピソード


※各問いへの添削メモ（ここがダメ・なぜダメ・どう改善）は `interview_episodes_review.md` にまとめています。本ファイルは添削に基づいて回答を修正済みです。

## 基本情報

| 項目       | 内容                                     |
| ---------- | ---------------------------------------- |
| 大学       | 九州工業大学 情報工学部                  |
| 現在の状況 | 新卒1年目（転職活動中）                  |
| 学歴備考   | 浪人1回、留年1回、休学1回                |
| 志望職種   | フルスタックエンジニア（プロダクト開発） |
| 志望条件   | AI駆動開発、フルリモート                 |
| 資格       | 基本情報技術者試験、簿記2級、TOEIC 680   |

---

## 志望動機

### なぜエンジニアか

**なぜエンジニアか？**

> 効率化が好きで、それをソフトウェアの力で実現できる仕事に魅力を感じたからです。

※面接ではこの一文で答え、質問されたら下のQ&Aで深掘りする。下のQ&Aは**時系列**（高校→浪人・留年→大学）に沿って並べている。

---

#### 時系列の整理

| 時期 | 経験                                   | 得たこと・気づき                                                                                                                          |
| ---- | -------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------- |
| 高校 | 進路を考えていた                       | ものづくり・仕組みで課題を解決することに興味があると気づいた → **情報系（九工大）を志した**（プログラミングを本格的に始めたのは大学から） |
| 浪人 | 九工大不合格→浪人→合格                 | 「時間の使い方と計画の立て方が結果を左右する」→ 時間を大切に思う**きっかけの一つ**                                                        |
| 大学 | 留年、バイトと学業の両立               | 「時間の使い方が結果を左右する」→ 時間を大切に思う**きっかけの一つ**                                                                      |
| 大学 | 授業でコード、ドットインストールで学習 | プログラミングを**本格的に**始めた。コードが動く楽しさ、形にしていく面白さ → **エンジニアを志す**                                         |

---

#### Q&A（時系列に沿って、一問一答）

**Q: 情報系を志したきっかけは何ですか？**（高校）

> 高校で進路を考えていたとき、自分はものごとを形にしたり、仕組みで課題を解決したりすることに興味があると気づきました。情報工学を専門に学べる大学を調べるなかで九州工業大学を知り、そこで学びたいと思って情報系を志しました。プログラミングを本格的に始めたのは大学からです。

**Q: どういうエピソードからそういうふうに気づいたんですか？**（高校・深掘り）

> 大きな一つのエピソードというより、高校の授業や普段の生活のなかで、いくつか重なった感覚です。数学では、公式を覚えるより「なぜそうなるか」や「どういう手順で解くか」を追う方が好きでした。あとは、何か面倒だと思っていたことを「こうしたら楽になるのでは」と考えてやり方を変えてみたり、ものごとを手順やルールで整理したりすることが、わりと苦にならなかったんです。進路を考えていたときに、それが「仕組みで課題を解決することに興味がある」ということだと、自分なりに言語化できました。

**Q: なぜ時間をそこまで大切だと思うようになったんですか？**（浪人・大学）

> 浪人や留年、バイトと学業の両立など、高校を卒業してからのいくつかの経験を通じて、「時間の使い方が、結果を左右する」と実感しました。そこから、時間は取り戻せない資産だと強く意識するようになっています。

**Q: なぜ効率化にこだわるんですか？**（今の理由）

> 時間を大切にしているからです。上で話したような経験から時間の有限さを意識しているので、効率化によって、自分や周りの人が「本当にやりたいこと」に使える時間を増やしたいと考えています。

**Q: プログラミングに触れたのはいつ・どうやってですか？**（大学）

> 本格的に触れ始めたのは大学生になってからです。高校で情報系を志したあと、大学の授業でコードを書き、そこからドットインストールでHTML・CSS・JavaScriptなどを学びました。自分で書いたコードが動く楽しさと、形にしていく面白さを感じ、エンジニアを志すようになりました。

**Q: 仕組みで課題を解決する、と言ってもコンサルや経営などいろいろあると思うんですが、なぜエンジニアなんですか？**

> 確かにいろいろあります。理由は2つです。1つは、コンサルは「こうしたらいい」と提案するところが主で、エンジニアは実際にものを作るところまでやる、という違いがあること。もう1つは、自分は提案で終わらず形にして動かすところまでやりたいからです。だからエンジニアを選びました。

**Q: なんでソフトウェアが直結していると思うんですか？**（深掘り）

> 効率化で時間を増やすには、人が手でやっている繰り返しの作業を自動化したり、一度つくった仕組みが動き続けるようにしたりする必要があります。ソフトウェアは、それをコードとして形にし、動かし続けられる。提案やルール変更だけだと「こうしたらいい」で終わりがちですが、ソフトなら実際に動くものが残り、その分の時間が生まれます。だから、効率化で時間を増やしたいと思うと、手段としてソフトウェアが直結していると感じました。

**Q: 趣味は何ですか？休日はどう過ごしていますか？**

> アニメと個人開発です。休日はアニメを観たり、Claude Codeで個人開発をしたりしています。個人開発では、自分が欲しい仕組みや機能を形にすることが多く、効率化やものづくりの楽しさを実感しています。

**Q: エンジニアの仕事で、特にやりがいを感じるのはどんなところですか？**

> 自分だけでなく、他の人の時間を増やせることです。業務や生活を効率化して、「人が本当にやりたいことに使える時間」を増やせる仕事に魅力を感じています。

### なぜAI駆動開発の会社か

今後のエンジニアの未来を考えたときに、AIをうまく使いこなしているエンジニアしか生き残れないと考えている。最先端のAI駆動技術を取り入れている会社で経験を積みたい。

#### なぜそう思うようになったか（実体験）

**Q: 「AIを使いこなすエンジニアしか生き残れない」と思う根拠は？**

> 実際に1年間の実務で、AIに任せられる範囲がどんどん広がっていることを実感しているからです。あわせて、新機能の追加の際の要件の叩き上げの質も、AIを使うことで上がっていると感じています。

**Q: 具体的なエピソードはありますか？**（根拠の深掘り）

> 自社アプリのスタイル調整（CSS・レイアウト・余白）と新機能の要件叩き上げについて、Opus 4.5やClaude Codeを使い始めてから、AIに任せられる範囲が広がり、要件の質も上がる手応えがありました。

**Q: 「AIに仕事を奪われる」という意見にはどう反論する？**

> 「奪われる」というより、仕事の中身が変わるという捉え方をしています。AIによって、頭を使わなくていいような単純作業、ただ手を動かすだけの作業から解放されます。その結果、人間にしかできない本当に重要なタスク——意思決定やクリエイティブな作業——に時間を割けるようになります。これは私が大切にしている「時間」の価値観とも一致しています。

### 志望軸の詳細（本音ベース）

| 優先度 | 条件         | 理由                                                                                  |
| ------ | ------------ | ------------------------------------------------------------------------------------- |
| 高     | AI駆動開発   | AIでできることが増えており、その最前線で経験を積みたい                                |
| 高     | フルリモート | 自宅のデスク環境が整っている（3画面、スタンディングデスク等）、通勤時間がもったいない |

#### なぜフルリモート希望か

**Q: フルリモートがいい理由は？**

> 集中して実装に没頭できるため、任された期間内で確実に成果を出しやすい環境だと考えています。そのために自宅に3画面やスタンディングデスクを整えています。また、通勤時間を仕事や学習に充てたいと考えています。

**Q: 出社のメリットは認識しているか？**

> はい。出社には、雰囲気や非言語の情報が伝わりやすいこと、雑談や偶発的な会話で関係が深まりやすく、曖昧なニュアンスのすり合わせがしやすいこと、その場で集まって決められる分だけ意思決定が速くなりやすいこと、といったメリットがあると思います。だからこそリモートでは、カメラの向きや書く・図にすることでの共有、そして発言の仕方や確認の入れ方で、伝わり方を補うようにしています。

**Q: リモートでのコミュニケーションの工夫は？**

> リモートならではの点として、目線をカメラに向けること、発言が被りやすいので話したいときは「話したいです」と一言入れてから話すこと、聞き手の反応が見えづらいので区切りのところで「ここまで大丈夫ですか？」と確認すること、を意識しています。あわせて、後から見返せる用件はチャットに書き、ニュアンスや相談事は音声で話すなど、チャットと口頭の使い分けも心がけています。

### キャリアビジョン（1年後・3年後・5年後・10年後）

**本音：** いずれ独立し、自分で価値を生み出せるエンジニアになりたい。その前に、AI駆動開発の実践力とビジネス感覚を身につけたい。

**面接用の考え方：** 短期では御社で成果を出し貢献する。中長期では、自分で課題を見つけて形にできる存在になりたい、と伝える。独立は「10年後には」「将来の選択肢の一つ」程度にすると、短期で辞める印象を避けやすい。

※以下はベース。**会社ごとに、御社の事業・チーム・求人に合わせて「1年後・3年後・5年後でどうなっていたいか」をより具体化して話す。**

**Q: 1年後はどうなっていたい？**

> 御社でAI駆動開発の実務をしっかり積み、チームで成果を出せるようになりたいです。CursorやClaude Codeなどを現場で使い込み、開発の質と速度の両立できるようになりたいと考えています。

**Q: 3年後は？**

> 担当範囲を広げ、設計や技術選定に関われるようになりたいです。チームの核として、後輩のサポートや横串の役割も担えるようになれればと考えています。

**Q: 5年後は？**

> 自分で課題を発見し、企画から実装まで一貫して担える人材になりたいです。御社の事業に深くコミットしつつ、AI駆動開発のノウハウを咀嚼して、次のステージに活かせる状態を目指しています。

**Q: 10年後はどうなっていたい？**

> 事業を作る側に回りたいです。AI駆動開発で培った専門性を活かし、自分で課題を見つけて形にできる存在になりたいと考えています。社内で新規事業を担うのか、別の形なのかは、そのときの自分と状況に合わせて考えたいです。今は御社で経験を積むことを最優先にしています。

---

## ガクチカ（学生時代に力を入れたこと）

### テレアポ営業（蓄電池販売）

| 項目 | 内容                               |
| ---- | ---------------------------------- |
| 期間 | 大学3年、約1年間                   |
| 業務 | 蓄電池の販売（アウトバウンド営業） |
| 規模 | 同僚15名のチーム                   |
| 成果 | **在籍期間中、常に売上1位を維持**  |

**Q: なぜ蓄電池販売のバイトを選んだ？**

> 2つ理由があります。1つ目は、当時の自分は人見知りで、知らない人と話すのが得意ではありませんでした。テレアポは初対面の相手と電話で話す仕事なので、人見知りを克服したいと思い、そのうえで相手の反応を読みながら話す経験を通じて、コミュニケーションの力も伸ばしたくて選びました。2つ目は、学生で使える時間が限られていたので、同じ時間でしっかり稼げる仕事がよいと考えていました。蓄電池販売のテレアポは時給が高く、成果に応じた報酬もあり、限られた稼働時間で効率的に収入を確保できる点が魅力でした。

#### 具体的な実績（数値）

| 指標              | 内容                                |
| ----------------- | ----------------------------------- |
| 勤務頻度          | 月8回（土日のみ）                   |
| 1回あたり勤務時間 | 約8時間                             |
| 1回あたりアポ獲得 | 約2件                               |
| 月間アポ獲得数    | 約16件                              |
| 有効アポ率        | 約50%（実際に商談につながった割合） |
| 商材単価          | 1台あたり200〜300万円               |
| 月間売上貢献      | **約1,000万円**（アポベース）       |

#### 工夫したこと

1. **観察から始める**: 最初は他の人のやり方を徹底的に観察
2. **成功パターンの分析**: 経験を積みながら「どういう話し方が刺さるか」を自分で分析
3. **スクリプトの体系化**: 顧客タイプ別にスクリプトをカスタマイズ

#### 顧客分類の軸

- **関心度（高/中/低）** … 効果が特に大きかった軸
- 反応パターン（質問が多い/即決型/慎重型）
- よくある質問への回答準備
- 年齢層による話し方の調整

#### 面接用ストーリー（STAR法）

**Situation（状況）：**
大学3年生のとき、蓄電池販売のテレアポ営業のアルバイトを始めました。15名ほどのチームで、一人ひとりが成果を競う環境でした。入ってから比較的早く売上1位に届き、在籍中は常に1位を維持していました。

**Task（課題）：**
最初は渡されたスクリプト通りに話していましたが、お客様によって反応が全く異なり、一律のアプローチでは限界があると感じました。

**Action（行動）：**
まず、成果を出している先輩のトークを徹底的に観察し、パターンを分析しました。そして、自分の経験からも「どんな話し方がどんなお客様に刺さるか」を記録し、顧客タイプ別のスクリプトを作成しました。関心度、よくある質問、年齢層などで分類し、それぞれに最適なアプローチを体系化しました。

**Result（結果）：**
この取り組みの結果、在籍した1年間を通じて常に売上1位を維持できました。自分は月8回（土日のみ）の勤務で月間約16件のアポを獲得し、有効アポ率は約50%。蓄電池は1台200〜300万円の商材で、月間約1,000万円の売上に貢献していました。作成したスクリプトをチーム内の何人かに共有したところ、チーム全体の月間アポ獲得数が約1.3倍に増加しました（例：共有前月間約120件→共有後月間約155件）。特に「関心度」で分類したアプローチが効果的でした。

#### エンジニアリングとの接続

> この経験から「観察→分析→仕組み化」のサイクルを回す力が身につきました。これはソフトウェア開発における「現状把握→設計→実装→改善」のサイクルと同じです。また、お客様のタイプ別にスクリプトを分けたことは、ユーザーペルソナを意識した設計思考にも通じると考えています。

#### 想定質問と回答

**Q: なぜ最初から1位だったのですか？**

> 「最初から」というより、他の人の良いところを素早く吸収し、自分なりに改善したからです。新しい環境では「まず真似る、そして改善する」を徹底しています。

**Q: 大変だったことは？**

> 最初は断られることに慣れず、精神的にきつい時期もありました。しかし、断られるパターンを分析し、「断られる前に対処する」スクリプトに改善することで、成約率も上がり、精神的な負担も減りました。課題を仕組みで解決することの重要性を学びました。

**Q: チームへの貢献は？**

> 自分が作ったスクリプトを何人かのメンバーに共有し、新人の教育にも活用しました。その結果、チーム全体の月間アポ獲得数が共有前と比べて約1.3倍に増えました（例：月間約120件→約155件）。ノウハウを属人化させず、チーム全体の成果につなげる意識は、エンジニアとしてのドキュメント文化やナレッジ共有にも活かせると考えています。

---

### E資格インターン（スキルアップAI株式会社）

| 項目 | 内容                                          |
| ---- | --------------------------------------------- |
| 期間 | 約1年間                                       |
| 内容 | E資格（AIエンジニア向け資格）取得カリキュラム |
| 形式 | 2-3ヶ月ごとに動画+資料→テスト→合格者のみ次へ  |
| 結果 | カリキュラム完走（資格試験は未受験）          |

#### なぜ始めたか

AIの仕組みを根本から理解したかった。表面的にAPIを叩くだけでなく、裏で何が動いているかを知ることで、より効果的にAIを活用できると考えた。

**Q: 1年間続けられたモチベーションは？**

> 大学時代にChatGPTを使っていて、そのすごさに感銘を受けていました。「この中身の仕組みはどうなっているんだろう」という好奇心があり、それを知ることが純粋に楽しかったので続けられました。

#### 学んだこと

- 機械学習・深層学習の基礎理論
- PyTorchを使った実装
- AIモデルの評価手法

#### なぜ資格は取らなかったか

資格試験の受験費用が高額だったため、知識と実装力を得ることを優先した。資格そのものより、実際にプロダクトを作れる力が重要だと判断した。

#### 面接用表現

**Q: AIについて何を知っていますか？**

> E資格のカリキュラムを1年かけて完走し、機械学習・深層学習の基礎から実装まで学びました。今はAIを「ブラックボックス」ではなく、裏の仕組みを理解した上で活用しています。

**Q: 資格を取らなかったのはなぜ？**

> 資格そのものより、カリキュラムで得た知識と実装力を大事にしたかったためです。受験費用も高かったので、その分は別の学習や個人開発に回す選択をしました。学んだ知識は、個人開発のAIニュース要約アプリなどに活かしています。

---

### 卒業研究（AI技術を用いた化学物質の蓄積性予測）

| 項目   | 内容                                                                       |
| ------ | -------------------------------------------------------------------------- |
| テーマ | AI技術を用いた魚類における「代謝されにくさ」を決定づける化学物質の特徴探索 |
| 期間   | 大学4年（令和6年度）                                                       |
| 役割   | **AI解析パート全般を一人で担当**                                           |
| 発表   | 国内学会「ケモインフォマティクス討論会」で口頭発表（2024年12月、金沢）     |
| 連携   | 愛媛大学との共同研究（化学・生物学の知見提供）                             |

#### 自分が担当した範囲（全工程）

| 工程           | 内容                                          |
| -------------- | --------------------------------------------- |
| データ収集     | 1,332種類の化学物質データを収集・整理         |
| 分子記述子生成 | RDKitで201個の分子記述子を生成                |
| 特徴量選択     | RFE（再帰的特徴消去）で重要な記述子を絞り込み |
| モデル構築     | Random Forestで予測モデルを構築               |
| SHAP分析       | 説明可能なAIで予測根拠を可視化                |
| 学会発表       | 発表資料作成・口頭発表（2024年12月、金沢）    |

※愛媛大学からは化学・生物学の専門的知見（BCFの解釈、化学物質の特性など）を提供いただいた

**Q: なぜこのテーマを選んだ？**

> 化学・生物データをAIで扱うテーマに興味があり、かつE資格で学んだ機械学習がそのまま活かせると知って選びました。

**Q: 研究で一番楽しかったことは？**

> データを加工したり、パラメータを変えたりして精度を上げていくプロセスが楽しかったです。あわせて、動物実験の代替になりうるモデルづくりに携われたことにもやりがいを感じました。

#### 研究内容

化学物質が魚の体内にどれだけ蓄積するか（生物濃縮係数：BCF）を、機械学習で予測するモデルを構築した。

**課題：**

- 従来のBCF測定は時間・コスト・倫理的問題（動物実験）がある
- 既存のAIモデルは「なぜその予測になるか」の解釈が困難

**解決アプローチ：**

1. 1,332種類の化学物質データを収集
2. RDKitで201個の分子記述子を生成
3. 特徴量選択（RFE）で重要な記述子を絞り込み
4. Random Forestで予測モデルを構築
5. **SHAP（説明可能なAI）** で予測の根拠を可視化

**成果：**

- 4つの重要な分子記述子を特定（疎水性、分子サイズ、電荷分布など）
- 従来のEPI Suiteモデルより予測誤差が小さいモデルを構築
- 「代謝されにくい」化学物質の特徴を明らかにした

#### 使用技術

| カテゴリ   | 技術                                  |
| ---------- | ------------------------------------- |
| 言語       | Python, R                             |
| 機械学習   | scikit-learn, Random Forest, XGBoost  |
| 分子記述子 | RDKit                                 |
| 説明可能AI | SHAP (Shapley Additive exPlanations)  |
| 統計       | スピアマン相関、RFE（再帰的特徴消去） |

#### 面接用ストーリー

**Q: 研究内容を簡単に説明してください**

> 化学物質が魚の体内にどれだけ蓄積するかを、AIで予測する研究を行いました。従来の測定方法は時間とコストがかかり、動物実験の倫理的問題もあります。私はAIモデルの構築を担当し、1,300種類以上の化学物質データから、蓄積しやすさを決める重要な特徴を4つ特定しました。特に、SHAPという「説明可能なAI」の手法を使い、なぜその予測になるかを可視化したことがポイントです。2024年12月、ケモインフォマティクス討論会で口頭発表しました。

**Q: なぜ説明可能なAI（XAI）を使ったのですか？**

> 予測精度だけでなく、「なぜその予測になるか」を説明できることが、化学物質規制の現場では重要だからです。ブラックボックスのモデルでは、規制の根拠として使えません。SHAPを使うことで、各化学物質の特徴が予測にどう影響するかを定量的に示せるようになりました。

**Q: この研究で苦労したことは？**

> 201個の分子記述子から、本当に重要な4つを選び出すプロセスに苦労しました。単純に相関が高いものを選ぶだけでは多重共線性の問題があり、特徴量選択の手法を複数組み合わせて、解釈性と予測精度のバランスを取る必要がありました。

#### エンジニアリングとの接続

> この研究を通じて、AIは「使う」だけでなく「なぜそうなるか説明する」ことの重要性を学びました。これはプロダクト開発においても、ユーザーに対して透明性のある機能を提供することに通じると考えています。また、大規模なデータを扱い、仮説を立てて検証するサイクルを回した経験は、エンジニアとしてのデータ分析力にも活きています。

---

## ポートフォリオ

### 1. AIニュース音声要約アプリ

| 項目         | 内容                                                                                |
| ------------ | ----------------------------------------------------------------------------------- |
| リポジトリ   | GitHub公開済み                                                                      |
| 目的         | AI最新情報を効率的にキャッチアップするため                                          |
| 技術スタック | Firebase Functions, TypeScript, Google Cloud Text-to-Speech, Gemini API, RSS Parser |
| 利用状況     | **通勤時に毎日使用**（通勤片道約30分のうち約10分、徒歩中に聴いている）              |

#### 機能

1. AIツール関連のRSSフィードからニュースを取得
2. Gemini APIで記事を要約
3. Google Cloud Text-to-Speechで音声化
4. 毎朝聞ける形式で配信

#### なぜ作ったか

> 自分で使いたい情報を、自分で作るツールにしたかったからです。AI分野は進化が速く、通勤時間をインプット時間に変えれば効率的にキャッチアップできると考え、開発しました。「自分の課題を自分で解決する」という姿勢で取り組みました。

**Q: なぜ「音声」にしたのか？テキストではダメだった理由は？**

> 通勤は片道約30分で、そのうち徒歩の約10分はテキストを読めません。音声にすればその10分を毎日インプットに使えると考え、徒歩中に聴くようにしています。

#### 面接でのアピールポイント

- **自分で使っている**: 作って終わりではなく、実際に毎日使用
- **AI活用の実践**: 要約（Gemini）+ 音声合成（TTS）の組み合わせ
- **効率化志向**: 「時間を生み出す」という価値観を体現

---

### 2. 電子書籍→PDF変換アプリ

| 項目         | 内容                                                                              |
| ------------ | --------------------------------------------------------------------------------- |
| リポジトリ   | GitHub公開済み（Vercelデプロイ）                                                  |
| 目的         | 複数の本から共通点を抽出し、自分の成長に活かすため                                |
| 技術スタック | Next.js 16, React 19, TypeScript, Tailwind CSS, pdf-lib, Playwright, Tesseract.js |
| 利用状況     | **現在も使用中**                                                                  |

#### なぜ作ったか

> 1冊の本だけを読むと、その著者の思考に偏りがちです。複数の本から共通点を抽出し、普遍的な知見を自分に取り込みたいと考えました。そのために、電子書籍をPDF化し、AIで横断的に分析できる形にするツールを作りました。現時点ではPDF化まで完成しており、AIでの横断分析はこれから活用していく予定です。

**注意：** PDF化の機能は完成しているが、実際にAIで分析・知見抽出はまだ行っていない。面接では「これから活用予定」と伝える。

#### 技術的なポイント

- Playwrightでブラウザ自動化
- Tesseract.jsでOCR処理
- pdf-libでPDF生成

---

## チーム開発経験

| 項目     | 内容                         |
| -------- | ---------------------------- |
| 場所     | **現職（ラキール株式会社）** |
| チーム   | 6人                          |
| 内容     | 人事アプリの保守開発         |
| 役割     | メンバー（実装担当）         |
| ツール   | Git, GitHub Issues           |
| 開発手法 | Issue駆動開発                |

#### 面接用表現

> 現職で自社の人事アプリ（LaKeel HR）の保守開発に携わっています。6名のチームで、GitHubのIssueでタスクを管理し、ブランチを切って開発、PRを出してレビューを受けるという一連のフローを経験しました。自分のコードが他のメンバーに影響することを意識し、可読性やコミットメッセージの分かりやすさに気を配っています。

---

## 強み・弱み

### 強み

| 強み                   | 具体例                                                                    |
| ---------------------- | ------------------------------------------------------------------------- |
| 観察→分析→仕組み化     | テレアポでの顧客分類スクリプト作成                                        |
| 自分の課題を自分で解決 | 個人開発アプリ（AIニュース要約、電子書籍PDF変換等）はすべて自分の課題解決 |
| 継続的な学習           | E資格1年完走、毎朝のAIニュースキャッチアップ                              |
| 効率化志向             | 時間を生み出すためのツール開発                                            |

**Q: 「観察→分析→仕組み化」のテレアポ以外の具体例は？**

> 自分に必要な情報だけを、必要な形式で得たいと考えました。Audibleは便利でしたがノイズが多く、自分専用のニュースが音声で欲しかったので、アプリで仕組み化しました。これがAIニュース音声要約アプリです。

### 弱み（改善中）

| 弱み                                 | 対策                                     |
| ------------------------------------ | ---------------------------------------- |
| スピード重視で細かい確認が疎かになる | 実装前に必ず認識合わせをする習慣をつけた |

**詳細：**

> 以前はスピードを優先して「一旦出してから直す」考え方が強かったです。そのため、細かいところまで気がつかず、確認不足になることがありました。

**対策と改善：**

> 現職でIssueの前提条件を誤解して手戻りが発生した経験から、実装前に必ず認識合わせをする習慣をつけました。「自分はこう理解しましたが、合っていますか？」と確認することで、スピードを落とさずに認識齟齬を防いでいます。

**面接用表現：**

> 私の弱みは、スピードを重視するあまり細かい確認が疎かになることです。現職で、Issueの前提条件を誤解して手戻りが発生した経験があります。この経験から、実装前に認識合わせをする習慣をつけました。「自分はこう理解しましたが、合っていますか？」と確認することで、スピードを維持しながらミスを防いでいます。

---

## ストレス・挫折・対人関係

### ストレス

**Q: ストレスを感じるのはどんな時？**

> 自分が理解できない状態が続くときです。説明が曖昧だったり、前提が違うまま進んだりすると、そこを解消したくなりストレスを感じます。

**Q: ストレス解消法は？**

> ストレスを感じたら、現状を変えるために行動します。原因の仮説を立てて、それを解消するための行動を取ることで対処しています。じっと我慢するのではなく、行動で解決するタイプです。

### 挫折経験

**Q: 留年以外の挫折経験は？**

> 浪人です。現役で九州工業大学に不合格になったことが挫折でした。

**Q: どう立ち直った？**

> 浪人してから、いきなり勉強を始めるのではなく、まず「どういう勉強をしたら合格できるか」を決めるための分析から入れました。答案や模試を科目別・分野別に振り返り、どこで点を落としているか、合格最低点との差、苦手単元を特定しました。その分析をもとに戦略を立て、「いつまでに何を仕上げるか」を月単位で逆算して計画し、塾と参考書で実行しました。落ち込むより、戦略づくりのための分析と行動に時間を使うことで立ち直りました。

**面接用表現：**

> 浪人が挫折経験です。時間が足りず勉強開始が遅れた結果、九工大に現役で届かず浪人しました。浪人では、ただ勉強するだけでなく、最初に「どういう勉強をしたら合格できるか」という戦略を立てるための分析をしました。答案や模試を科目別・分野別に見直し、合格最低点との差・苦手単元・抜けている基礎を特定したうえで、「いつまでに何を終わらせるか」を逆算して計画を立て、塾と参考書で実行しました。この経験から、困難に直面したときは「まず戦略を立てるための分析をし、そのうえで行動に落とす」という姿勢が身につきました。

### 対人関係

**Q: チームでの自分の役割は？**

> 誰もやらないところをやる、という役割が多いです。明確なリーダーやサポートという分類ではなく、チームに足りない部分を補う動きをします。

**Q: 苦手なタイプの人は？どう対処する？**

> 話が長く、要点が掴みづらい方が苦手です。その場合は「いま何の話でしたっけ？」と確認して、目的に戻すようにしています。

**Q: 意見が対立したときどうする？**

> まず相手の意見を尊重して聞きます。その上で、自分の意見の方が良いと判断すれば、自分の意見を通すように動きます。相手の意見の方が良ければ、素直に折れて相手の意見に賛同します。どちらが正しいかではなく、どちらがより良い結果になるかで判断しています。

---

## 想定質問集

### 自己紹介

> 九州工業大学情報工学部を卒業した大月と申します。大学では機械学習を用いた化学物質の蓄積性予測の研究を行い、学会発表も経験しました。大学時代はテレアポ営業で常に売上1位を維持し、「観察→分析→仕組み化」のサイクルを回す力を身につけました。現在はAI駆動開発に強い関心があり、個人でAIニュース音声要約アプリなどを開発し、毎日使っています。御社のようにAI活用を積極的に進めている環境で、フルスタックエンジニアとして成長したいと考えています。

### なぜ当社か（志望企業共通の軸）

> 御社を志望する理由は3つあります。1つ目は、AI駆動開発を本格的に導入していること。[具体的なツール名]を全社的に活用されている点に魅力を感じました。2つ目は、フルリモートで成果を出せる環境があること。3つ目は、プロダクト開発を通じてユーザーに価値を届けられること。これらが私の志向と一致しています。

### 時系列の整理（過去→現在→未来）

以下は想定質問を**時系列**で並べています。志望動機の「なぜエンジニアか」と同様、過去（高校・資格）→ 現在（他社状況）→ 未来（1年後〜10年後）の順です。

#### 過去：高校時代〜エンジニアを目指したきっかけ

**Q: 高校時代からエンジニアになりたかったきっかけは？**

> 高校で進路を考えていたとき、ものごとを形にしたり、仕組みで課題を解決したりすることに興味があると気づきました。情報工学を専門に学べる九州工業大学を知り、そこで学びたいと思って情報系を志しました。プログラミングを本格的に始めたのは大学からで、大学で授業とドットインストールでコードを学び、自分で書いたコードが動く楽しさを感じて、エンジニアを志すようになりました。

#### 過去〜現在：資格について

**Q: 簿記2級を取った理由は？**

> 企業の財務や経営状況を読み解く力をつけたくて取得しました。就職活動での企業理解や、プロダクトの採算を考えるうえでも役立つと考えています。

**Q: TOEIC 680を取った理由は？英語を使う予定は？**

> 学校の機会で受験し、それ以降も技術ドキュメントや英語の技術情報を読むときに活用しています。今後は海外の技術発信やOSSに触れる際にも活かしたいです。

#### 現在：他社状況

**Q: 他にどんな会社を受けている？**

> AI駆動開発とフルリモートを軸に受けています。同様の志向の企業を複数志望しています。

**Q: 複数内定が出たらどう選ぶ？**

> 2つの軸で判断します。1つ目は、AI駆動開発の導入度合い。Claude CodeやCursorなどを全社的に使える環境かどうか。2つ目は、フルリモートで成果を出せる環境があるかどうか。これらの条件がより揃っている企業を選びます。御社は[具体的な理由]の点で、特に魅力を感じています。

#### 未来：キャリアビジョン（1年後→3年後→5年後→10年後）

※志望軸の「キャリアビジョン」と同一。会社ごとに具体化して話す。

**Q: 1年後はどうなっていたい？**

> 御社でAI駆動開発の実務をしっかり積み、チームで成果を出せるようになりたいです。CursorやClaude Codeなどを現場で使い込み、開発の質と速度の両立できるようになりたいと考えています。

**Q: 3年後は？**

> 担当範囲を広げ、設計や技術選定に関われるようになりたいです。チームの核として、後輩のサポートや横串の役割も担えるようになれればと考えています。

**Q: 5年後は？**

> 自分で課題を発見し、企画から実装まで一貫して担える人材になりたいです。御社の事業に深くコミットしつつ、AI駆動開発のノウハウを咀嚼して、次のステージに活かせる状態を目指しています。

**Q: 10年後はどうなっていたい？**

> 事業を作る側に回りたいです。AI駆動開発で培った専門性を活かし、自分で課題を見つけて形にできる存在になりたいと考えています。社内で新規事業を担うのか、別の形なのかは、そのときの自分と状況に合わせて考えたいです。今は御社で経験を積むことを最優先にしています。

### 逆質問のストック

1. AI駆動開発で使用しているツールと、その導入の経緯を教えてください
2. エンジニアの評価はどのような基準で行われていますか？
3. 入社後、最初に任される業務はどのようなものですか？
4. チーム内でのコードレビューの文化について教えてください
5. リモートワークでのコミュニケーション方法を教えてください

---

## 現職について

### ラキール株式会社

| 項目     | 内容                                                      |
| -------- | --------------------------------------------------------- |
| 会社名   | 株式会社ラキール（LaKeel）                                |
| 上場     | 東証グロース（証券コード: 4074）                          |
| 本社     | 東京都港区                                                |
| 事業     | DX支援プラットフォーム「LaKeel DX」等の自社プロダクト開発 |
| 主要製品 | LaKeel HR（人事システム）、LaKeel BI、LaKeel Data Insight |
| 顧客層   | 大企業向け                                                |
| 在籍     | 新卒1年目                                                 |

### 入社理由（なぜラキールを選んだか）

1. **自社プロダクトを持っている**: SIerではなく、自社サービスを開発・運用している企業で経験を積みたかった
2. **年収450万円**: 新卒エンジニアとしては比較的高い給与水準だった

**面接用表現：**

> ラキールを選んだ理由は2つあります。1つ目は、SIerではなく自社プロダクトを持っている企業で経験を積みたかったからです。LaKeel HRなどの自社製品の開発に携われる点に魅力を感じました。2つ目は、当時は経験を積める環境と待遇のバランスを踏まえ、自分の市場価値を意識しつつ長く成長できる環境を重視して選びました。

### 転職理由

**本音：**

1. 年収の伸びが見込めない
2. AI駆動開発をガンガンやらせてくれない環境

#### 深掘り質問への回答

**Q: 入社前にこれらの不満点は予測できなかったか？**

> AI駆動開発については、当時はまだClaude Codeのようなツールが出ていなかったこともあり、予測できませんでした。正直、私のインプット不足もありました。年収については、当時は「今が高いからいい」という考えで、将来の伸びしろまでは見据えられていませんでした。

**Q: 「またすぐ辞めるのでは？」という懸念にどう答える？**

> 新卒のときは正直、将来を十分に見据えられていませんでした。今回は、AI駆動開発の動向、会社の評価制度、将来性などをしっかり調べた上での転職活動です。同じ失敗を繰り返すつもりはありません。また、一つの会社に長く働くことで得られるものがあると考えているので、長く働くつもりです。

**Q: 現職のAI駆動開発の状況は？**

> Opus 4.5などのモデルが登場したタイミングで、自社アプリのCSSやレイアウト調整などのタスクで少しずつAIを使い始め、Claude Codeなども自分では使っています。ただ、社内ではClaude Codeや最新のAIモデルが浸透するまでまだ時間がかかると感じています。周囲にはClaude Codeや最新のAIに疎い人が多く、あまり使っていない様子が散見されるためです。利用範囲や環境の制約もまだあり、社内全体で高機能なAIツールを本格導入するには至っていません。

#### 現職で学んだこと・感謝していること

**Q: 1年間で具体的に何を身につけた？**

| カテゴリ           | 学んだこと                                                                 |
| ------------------ | -------------------------------------------------------------------------- |
| チーム開発         | GitHubを用いたスプリント管理、Issue駆動開発                                |
| コミュニケーション | レビューのタイミング、分かりやすい伝え方・説明の構成                       |
| コード品質         | 命名規則、責務分離、可読性の高いコードの書き方（レビュー指摘を通じて習得） |
| 社会人基礎         | メールの書き方、電話対応、オリエンテーションの進め方                       |

**Q: 現職に対する感謝はあるか？**

> もちろんあります。社会人1年目として、メールの送り方、電話のやり方、オリエンテーションの進め方まで手取り足取り教えていただきました。チーム開発のお作法やコードレビューを通じた成長も、現職のおかげです。

**面接用表現：**

> 現職では自社プロダクトの開発に携わり、チーム開発のお作法やコードレビューを通じてエンジニアとしての基礎を身につけることができました。現職には感謝しています。しかし、AI駆動開発をより積極的に取り入れたいと考え、社内で提案もしましたが、金銭面の理由で導入が難しい状況でした。今後のキャリアを考えたとき、AI駆動開発を本格的に導入している環境で経験を積みたいと考え、転職を決意しました。

**NG回答（言ってはいけないこと）：**

- 年収が低い
- 今の会社がダメ
- すぐ辞めるつもり

---

## 浪人・留年・休学について

### 事実

| 項目   | 内容                                                  |
| ------ | ----------------------------------------------------- |
| 浪人   | 1回                                                   |
| 留年   | 1回（大学時代）                                       |
| 理由   | 学業以外の活動に時間を使いすぎた（主にバイトが約9割） |
| 休学   | 1回（単位取得後、学費節約のため）                     |
| 休学中 | E資格インターン、コールセンターのアルバイト           |

### 面接用回答

**Q: 浪人した理由を教えてください**

> 情報系に強い九州工業大学に行きたかったのですが、現役では不合格でした。諦めきれず、1年浪人して再受験し、合格しました。九工大を選んだのは、国立で唯一の情報工学専門学部であること、学費の負担が少ないこと、情報工学に特化したカリキュラムや就職実績を重視したからです（詳細は下記補足表参照）。

**九州工業大学 情報工学部を選んだ理由（補足）：**

| 観点           | 内容                                                       |
| -------------- | ---------------------------------------------------------- |
| 専門性         | 国立大学唯一の情報工学専門学部（1986年創設、日本初）       |
| カリキュラム   | 情報技術と専門分野をバランスよく学べる体系的なカリキュラム |
| AI・データ教育 | MDASHプログラム（数理・データサイエンス・AI教育）          |
| 就職実績       | 就職率100%（令和6年度）                                    |
| 経済面         | 国立大学のため学費が私立の半額以下                         |

**Q: 留年した理由を教えてください**

> 正直に申し上げると、大学1〜2年の頃は学業よりバイトに時間を取られすぎていました。生活の約9割がバイトで、単位を落としてしまいました。振り返って分析すると、卒業に必要な単位を「いつ・どの学期に取るか」と逆算して履修計画を立てていなかったこと、バイトと学業のどちらを優先するかの線引きが曖昧だったことが原因でした。この経験から「目標から逆算して優先順位をつける」ことの重要性を痛感し、以降は計画的に行動するようになりました。休学期間中はAIのインターンや営業のアルバイトに取り組み、結果的にE資格のカリキュラム完走や、テレアポで常に1位という成果に繋げることができました。

**ポイント：**

- 「遊んでいた」とは言わない
- 反省と学びをセットで伝える
- 休学期間を有意義に使ったことをアピール

---

## スキルの学び方

### プログラミング学習歴

| 時期       | 内容                                             |
| ---------- | ------------------------------------------------ |
| 大学1-3年  | C言語、Java（授業：データ構造、アルゴリズム）    |
| 大学4年    | Python、R（卒業研究：機械学習）                  |
| インターン | 機械学習、深層学習（E資格カリキュラム）          |
| 現職       | 自社プロダクトのソースコードを読んで学習         |
| 個人開発   | Next.js、TypeScript、Firebase（Claude Code活用） |

### 学び方の特徴

1. **基礎から応用へ**: 大学で学んだfor文、if文などの基本構文を、複雑な処理に応用
2. **ソースコードリーディング**: 現職では自社製品のコードを読んで実践的なパターンを学習
3. **AI活用学習**: 分からないところはAIに聞き、Claude Codeで個人開発しながら学ぶ
4. **アウトプット駆動**: 自分で使うアプリを作り、作りながら学ぶスタイル

### 面接用表現

> プログラミングは大学の授業でCとJavaの基礎を学び、卒業研究でPythonを使った機械学習を経験しました。現職では自社製品のソースコードを読み、分からない箇所はAIに質問して理解を深めています。また、個人でもClaude Codeを使ってアプリを開発し、実際に自分で使いながら技術を身につけています。「作りながら学ぶ」スタイルを大切にしています。

---

## 失敗から学んだ経験

### エピソード：Issueの認識齟齬による手戻り

| 項目     | 内容                                                      |
| -------- | --------------------------------------------------------- |
| 場面     | 現職での開発業務                                          |
| 失敗内容 | Issueの前提条件を誤解し、意図と違う成果物を作ってしまった |
| 結果     | 手戻りが発生                                              |
| 学び     | 実装前に必ず認識合わせをする                              |

### 面接用ストーリー（STAR法）

**Situation（状況）：**
現職で開発タスクを任されたとき、Issueに書かれた内容を読み、自分なりに理解して実装を進めました。

**Task（課題）：**
実装を完了して上司に確認してもらったところ、前提条件の認識が違っており、意図していたものと異なる成果物になっていました。

**Action（行動）：**
この経験から、実装に取り掛かる前に必ず認識合わせをするようにしました。「絶対にこれだろう」と思っていても、一度確認するようにしています。具体的には、Issueの内容を自分の言葉で言い換えて上司に確認する、不明点はその場で質問する、という習慣をつけました。

**Result（結果）：**
以降は認識の齟齬による手戻りがなくなり、効率的に開発を進められるようになりました。

### 面接用表現

> 現職でIssueの前提条件を誤解し、上司が意図したものと違う成果物を作ってしまったことがあります。この経験から、実装前に必ず認識合わせをする習慣を身につけました。「自分はこう理解しましたが、合っていますか？」と確認することで、手戻りを防ぎ、効率的に開発を進められるようになりました。エンジニアとして、コードを書く前のコミュニケーションの重要性を学んだ経験です。

### ポイント

- 失敗自体は小さいが、学びが明確
- 「確認する」という具体的な行動変容がある
- チーム開発で重要なコミュニケーションに繋げられる

---

## 更新履歴

- 2025-01-25: 初版作成
  - 基本情報（資格、浪人・留年・休学）
  - 志望動機（なぜエンジニア、なぜAI駆動開発、キャリアビジョン）
  - ガクチカ（テレアポ営業、E資格インターン）
  - 卒業研究（AI×化学物質蓄積性予測、学会発表）
  - ポートフォリオ（AIニュース音声要約、電子書籍PDF変換）
  - 現職情報（ラキール株式会社、転職理由）
  - 浪人・留年・休学の説明
  - スキルの学び方
  - 失敗から学んだ経験
  - 強み・弱み
  - 想定質問集・逆質問
- 2025-01-25: 浪人理由・入社理由を追加
  - 浪人理由（九工大を選んだ理由の補足）
  - 九州工業大学情報工学部の特徴（国立大学唯一の情報工学専門学部、就職率100%など）
  - ラキール入社理由（自社プロダクト、年収450万）
- 2025-01-25: 深掘り質問への回答を追加（全24項目）
  - カテゴリ1: 価値観・動機（時間を大切にする理由、効率化の原体験、AIへの見解）
  - カテゴリ2: キャリア・志望動機（フルリモート、AI駆動開発）
  - カテゴリ3: 経験・エピソード（テレアポ、E資格、卒業研究、ポートフォリオ）
  - カテゴリ4: 転職・現職（1年で転職の理由、現職で学んだこと、AI提案の結果）
  - カテゴリ5: 性格・人間性（強み追加例、弱み修正、ストレス、挫折、対人関係）
  - カテゴリ6: その他（資格、高校時代、10年後、他社状況）

---

# Part 4: 面接対策 — エピソード添削メモ


各問いに対して「ここがダメ」「なぜダメか」「どう改善するか」を記述した添削メモです。面接官の視点で、伝わりやすさ・説得力・印象を基準にしています。

---

## 志望動機

### なぜエンジニアか

#### Q: なぜエンジニアか？

**ここがダメ：** 「効率化が好きで、それを動く仕組みとして実装して残せるから」だけだと、エンジニア以外の職業（コンサル、経営企画など）でも当てはまり、エンジニアを選んだ理由として弱い。

**なぜダメか：** 面接官は「なぜエンジニアという職種なのか」を知りたい。「効率化」は動機の一部だが、プログラミングや技術への興味、コードを書くことの魅力が伝わらない。

**どう改善するか：** 「効率化が好きで、それを動く仕組みとして実装して残せるからです。特に、コードを書いて実際に動かすことで、自分のアイデアが形になる瞬間に魅力を感じています」のように、エンジニアならではの「コードを書く」「動かす」「形にする」を一文足す。

---

#### Q: 具体的に、最近どんなことを効率化しましたか？（何を仕組みとして実装しましたか？）

**ここがダメ：** 「通勤は片道30分ほどで、そのうち徒歩の10分間はテキストを読めません」の説明が長く、本質（情報収集の自動化）が埋もれやすい。

**なぜダメか：** 面接では短時間で要点を伝える必要がある。時間の内訳の説明に字数を割きすぎると、「なぜ効率化したか」の動機が薄く聞こえる。

**どう改善するか：** 「AI分野は情報の更新が速く、毎日テキストで追うのが負担でした。そこで、ニュース収集から要約、音声化までを自動化し、通勤中に聴ける形にしました。特に、徒歩中はテキストを読めない時間も、音声ならインプットに変えられて、情報収集の習慣が定着しました」のように、問題→解決→効果の順で簡潔にまとめる。

---

#### Q: そのアプリはどこまで自動化していますか？

**ここがダメ：** 特になし。自動化の範囲が明確で、自分がやることは「開いて聴くだけ」と分かりやすい。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

#### Q: ニュースはどの媒体から集めていますか？

**ここがダメ：** 「noteとQiitaとZennと公式ブログです」だけだと、なぜこの4つを選んだのか、他の媒体（Twitter、Reddit、技術ブログなど）は検討しなかったのかが分からない。

**なぜダメか：** 技術選定の思考プロセスを見たい面接官もいる。「なぜこの4つか」を一言添えると、判断力が伝わる。

**どう改善するか：** 「noteとQiitaとZennと公式ブログです。これらの媒体は、AI技術の最新情報が多く、かつテキストベースで要約しやすいため選びました」のように、選定理由を一言足す。

---

#### Q: 「Claude Codeに関するニュースだけ」はどう判定していますか？

**ここがダメ：** 「キーワードで判定しています」だけだと、具体的なキーワードや判定ロジックが分からず、技術的な深掘りに答えられない。

**なぜダメか：** 面接官によっては「どういうキーワードか」「誤検知はどう防いでいるか」を聞くことがある。準備不足だと「作ったけど中身は分かっていない」と見える。

**どう改善するか：** 「キーワードで判定しています。具体的には『Claude Code』『Claude Code Editor』などのキーワードを含む記事を抽出し、誤検知を減らすためにタイトルと本文の両方をチェックしています」のように、具体的なキーワードと判定方法を一言足す。

---

#### Q: YouTubeは収集していますか？

**ここがダメ：** 「していません（以前の回答が誤りでした）」の「以前の回答が誤りでした」は面接では不要。過去のミスを強調する必要はない。

**なぜダメか：** 面接では簡潔に「していません」で十分。「以前の回答が誤りでした」は、準備不足や記憶違いの印象を与えかねない。

**どう改善するか：** 「していません。現時点ではテキストベースの媒体に絞っています」のように、簡潔に答え、必要なら理由を一言添える。

---

#### Q: 既存のニュースアプリではなく自作した理由は？

**ここがダメ：** 特になし。既存サービスで満たせないニーズ（特定キーワードの横断検索、音声化）が明確で、自作の理由が説得力がある。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

#### Q: 作る前は情報収集にどれくらい時間がかかっていて、何が一番しんどかったですか？

**ここがダメ：** 特になし。時間（1時間）と負担（ノイズの選別）が具体的で、Beforeの状況が伝わる。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

#### Q: 作った後は、何がどう変わりましたか？（Before / After）

**ここがダメ：** 「時間そのものは大きく変わっていませんが」の前置きが長く、改善効果が弱く聞こえる。

**なぜダメか：** 面接官は「効率化した」と言うなら、時間削減や生産性向上を期待しがち。「時間は変わらない」と先に言うと、効率化の効果が薄く見える。

**どう改善するか：** 「時間は変わらないものの、『自分が欲しい情報』に寄せられた状態でインプットできるようになりました。結果として、短時間でも質の高い情報を多く読めるようになり、キャッチアップの密度が上がりました」のように、「時間は変わらない」を補足にし、「質の向上」を主軸にする。あるいは「時間は変わらないものの、情報の質と密度が上がり、同じ時間でより多くの価値ある情報をキャッチアップできるようになりました」と、時間効率の向上を強調する。

---

#### Q: 「要約の質が上がった」の判断基準は？

**ここがダメ：** 「自分が欲しい情報に対して、情報の密度が高いかどうかです」だけだと、主観的で客観的な基準が分からない。

**なぜダメか：** 「質が上がった」と言うなら、判断基準を明確にできると説得力が増す。「密度が高い」だけだと、どう測っているかが曖昧。

**どう改善するか：** 「自分が欲しい情報に対して、情報の密度が高いかどうかです。具体的には、要約を聞いて『これは知りたかった』と感じる情報が、以前より多く含まれているかで判断しています」のように、判断の具体例を一言足す。

---

#### Q: 作って終わりにならないために、どう改善していますか？

**ここがダメ：** 特になし。継続的な改善（LLMの乗り換え、UI/UX改善）が明確で、作って終わらない姿勢が伝わる。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

#### Q: 失敗ケース（要約が外れた時）はどう直しますか？

**ここがダメ：** 「プロンプトを直すこともあれば、LLMを変えることもあります」だけだと、どう判断して直すのか、改善のプロセスが分からない。

**なぜダメか：** 面接官は「問題をどう分析して解決するか」を見たい。単に「直す」だけでなく、原因分析や判断基準があると説得力が増す。

**どう改善するか：** 「プロンプトを直すこともあれば、LLMを変えることもあります。まず、要約が外れた原因を分析し、プロンプトの問題なら修正し、モデルの限界なら別のLLMに乗り換える、という判断をしています」のように、原因分析→判断→対応の流れを一言足す。

---

#### Q: 進路（大学）を決めたときに、何を重視していましたか？（高校）

**ここがダメ：** 特になし。重視した条件（家から通える、国公立、学費負担）が明確で、高校時代の価値観が伝わる。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

#### Q: その条件の中で、九工大を第一志望にした理由は？（高校・深掘り）

**ここがダメ：** 1つ目と2つ目が「家から通える」「国公立」で、前問と重複している。

**なぜダメか：** 面接官は「九工大を選んだ理由」を知りたい。前問と同じ条件を繰り返すと、九工大ならではの魅力が伝わらない。

**どう改善するか：** 「3つあります。1つ目は、情報工学を専門的に学べる唯一の学部があることです。2つ目は、国公立で学費面の負担を抑えられることです。3つ目は、就職実績が強く、将来の選択肢が広がると考えたことです」のように、九工大ならではの理由（情報工学専門学部）を最初に置く。

---

#### Q: いつ頃からエンジニアを志向するようになりましたか？（大学〜就活）

**ここがダメ：** 「大学に入って授業で初めてコードを書き始めた頃から興味を持ち始め、就職を意識するタイミングでエンジニア志望が明確になりました」だと、興味を持った時期と志望が明確になった時期が曖昧。

**なぜダメか：** 面接官は「いつからエンジニアになりたいと思ったか」を知りたい。「興味を持ち始めた」と「志望が明確になった」は別のタイミングなので、区別した方が伝わる。

**どう改善するか：** 「大学に入って授業で初めてコードを書き始めた頃から興味を持ち始めました。その後、個人開発や実務を通じて、エンジニアとして働きたいという志望が明確になりました」のように、興味→志望の流れを明確にする。

---

#### Q: なぜ「初めてコードを書き始めた頃」から興味を持ったんですか？具体的に教えてください（大学・深掘り）

**ここがダメ：** 特になし。「手順やルールをコードに落とすことで、同じ作業を毎回同じ品質で再現できる点」が具体的で、効率化志向との接続も明確。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

#### Q: エンジニアを志向するきっかけは何ですか？（大学〜就活）

**ここがダメ：** 「自分が作ったものが動く」「仕組みとして残る」だけだと、他の職種（デザイナー、建築士など）でも当てはまり、エンジニアならではの魅力が弱い。

**なぜダメか：** 面接官は「なぜエンジニアという職種なのか」を知りたい。コードを書くこと、技術で問題を解決することの魅力が伝わらない。

**どう改善するか：** 「大学の授業でコードを書いたときに、『自分が作ったものが動く』『仕組みとして残る』ことに面白さを感じました。特に、コードを書くことで、自分のアイデアが実際に動く形になる瞬間に魅力を感じ、エンジニアを志すようになりました」のように、コードを書くことの魅力を一言足す。

---

#### Q: 趣味は何ですか？休日はどう過ごしていますか？

**ここがダメ：** 「アニメと個人開発」が並列で、それぞれをなぜ好きか・どう繋がっているかが分からない。また、「個人開発」が仕事の延長にしか聞こえず、バランスの悪さを心配される可能性がある。

**なぜダメか：** 趣味は人間性やストレス耐性の手がかりになる。エピソードがなければ「趣味：個人開発」が仕事の延長にしか聞こえず、息抜きのなさを心配される可能性がある。

**どう改善するか：** 「2つあります。1つ目はアニメで、休日は作品を観てリフレッシュしています。2つ目は個人開発で、Claude Codeを使いながら、自分が欲しい仕組みや機能を形にしています。気分で、アニメでリセットする日と、個人開発で作りたいものを形にする日を使い分けています」のように、両方の役割を説明する。あるいは「アニメはストーリーや世界観の構築に惹かれていて、設計やUXを考えるときの参考にもなっています」とエンジニアとの接続を一言添えてもよい。

---

#### Q: エンジニアの仕事で、特にやりがいを感じるのはどんなところですか？

**ここがダメ：** 「ここが面倒だったのが、自動化できて楽になったよ」といった声をもらえる瞬間」だけだと、ユーザーの声に依存したやりがいに聞こえ、自分自身の達成感や成長実感が伝わらない。

**なぜダメか：** 面接官は「あなた自身が何にやりがいを感じるか」を知りたい。ユーザーの声はやりがいの一部だが、それだけだと「他人の評価に依存している」ように見える。

**どう改善するか：** 「『ここが面倒だったのが、自動化できて楽になったよ』といった声をもらえる瞬間に、一番やりがいを感じます。また、自分が作った仕組みが実際に使われ、継続的に価値を生み出している実感も、やりがいの一つです」のように、ユーザーの声と自分の達成感の両方を一言ずつ足す。

---

### Q: なぜ「時間」を最も大切だと思うようになったのか？

**ここがダメ：** 「時間があれば〜できる」の繰り返しが多く、具体的な原体験やエピソードがなく抽象的。

**なぜダメか：** 面接官は「いつ・どの場面で」そう思ったかが知りたい。一般論だけで終わると、あなた個人の価値観として伝わりにくい。

**どう改善するか：** 「あと少し時間があれば…」と感じた具体的なシーンを1つ入れる（例：受験期、バイトと学業の両立時など）。「その経験から、時間は取り戻せない資産だと感じるようになりました」のように、体験→気づきの流れを短く添える。

---

### Q: 「本当に価値のあること」とは具体的に何？

**ここがダメ：** 前問（好きな人・食べ物・仕事・努力）とほぼ同じ内容で、回答が重複している。

**なぜダメか：** 「具体的に何？」に対して、もう一歩踏み込んだ具体例（例：誰と何をしている時間か、どの仕事のどの局面か）がないと、深掘りに答えたことにならない。

**どう改善するか：** 「意思決定・クリエイティブな時間」を前面に置き、エンジニアとしての文脈を足す。「設計や要件の判断を考える時間、新しい機能をゼロから組み立てる時間など、手を動かすより頭を使う時間が価値があると感じています」のように、職種と結びつける。

---

### Q: 趣味は？休日は何をしている？

**ここがダメ：** 「アニメと個人開発」が並列で、それぞれをなぜ好きか・どう繋がっているかが分からない。

**なぜダメか：** 趣味は人間性やストレス耐性の手がかりになる。エピソードがなければ「趣味：個人開発」が仕事の延長にしか聞こえず、バランスの悪さや息抜きのなさを心配される可能性がある。

**どう改善するか：** 「休日は気分で、アニメでリセットする日と、個人開発で作りたいものを形にする日を使い分けています」のように、両方の役割を一文で説明する。あるいは「アニメはストーリーや世界観の構築に惹かれていて、設計やUXを考えるときの参考にもなっています」とエンジニアとの接続を一言添えてもよい。

---

### Q: いつから「効率化が好き」と思うようになった？（高校時代・Anki）

**ここがダメ：** Ankiの体験で終わっており、「その結果、プログラミングに興味を持った」流れがこの回答だけでは弱い。

**なぜダメか：** 「効率化が好き」→「だからエンジニア」の橋が、このブロック内では「ソフトウェアの力で効率が上がる」の一言にしかなく、エンジニア志望とのつながりが薄い。

**どう改善するか：** 文末に「この経験から、効率化を実現する仕組みそのものに興味が涌き、プログラミングを学び始めるきっかけになりました」のように、Anki→ソフトウェア→プログラミング→エンジニア、という流れを一文で補う。下の「面接用表現例」と内容を揃えてもよい。

---

### なぜエンジニアか（面接用表現例）

※前回の添削で「手段として」→「技術の力で実現できることに魅力を感じている」に修正済み。現状の表現で問題なし。

---

### Q: 「AIを使いこなすエンジニアしか生き残れない」と思う根拠は？

**ここがダメ：** 「AIで代替できないことにフォーカスして仕事をする必要がある」で終わっており、自分がこれから何をしたいかが伝わりにくい。

**なぜダメか：** 根拠の説明はできているが、「ではあなたは何にフォーカスしたいのか」が抜けている。面接官は「この人在籍したら、どう働く人か」を知りたい。

**どう改善するか：** 最後に「自分は、要件の整理・設計・優先順位の判断など、意思決定とクリエイティブな部分に強みを活かしていきたいと考えています」のように、自分の役割イメージを一文足す。

---

### Q: 「AIに仕事を奪われる」という意見にはどう反論する？

**ここがダメ：** 「反論はありません」の言い方だと、「反論する気がない」「思考が浅い」と受け取られるリスクがある。

**なぜダメか：** 聞かれているのは「反論」ではなく「あなたの見解」。賛成の理由を述べる場合は、「反論はしないが、理由はこう考えている」と区別した方が伝わる。

**どう改善するか：** 「奪われるというより、仕事の内容が変わるという捉え方をしています」や「反論というより、自分はこう考えている、というスタンスです」と前置きし、そのうえで「単純作業から解放され、意思決定やクリエイティブな作業に集中できる」と続ける。

---

### Q: フルリモートがいい理由は？

**ここがダメ：** 自宅の設備と通勤時間の活用だけに終わっており、「会社・チームにとってのメリット」の視点がない。

**なぜダメか：** 面接官は「リモートでも成果を出せるか」「チームに貢献できるか」も見ている。自分都合だけだと、「出社しない理由」の言い訳に聞こえかねない。

**どう改善するか：** 「集中して実装に没頭できるため、スプリント内で確実に成果を出しやすい环境だと考えています」のように、リモート＝成果につながる、という一文を足す。設備の話は「そのために環境を整えています」で簡潔に締める。

---

### Q: 出社のメリットは認識しているか？

**ここがダメ：** 「はい。」のあと、メリットの説明だけになっており、自分がどう折り合いをつけているかが見えない。

**なぜダメか：** 「認識しているか」には「理解しているか」と「ではどうリモートで補うか」の両方が含まれがち。「はい」＋説明だけだと、押し切りに聞こえることがある。

**どう改善するか：** 「はい。雰囲気や非言語の情報は出社の方が伝わりやすいと思います。その分、リモートではカメラの使い方や、書く・図にすることでの共有を意識しています」のように、認識＋リモートでの補い方まで一言添える。

---

### Q: リモートでのコミュニケーションの工夫は？

**ここがダメ：** 「相手の目を見ると画面上では違う方向を向いているように見えるので」の説明が長く、本質（カメラを見る・構成を考える）が埋もれやすい。

**なぜダメか：** 面接では短時間で要点を伝える必要がある。技術的な理由の説明に字数を割きすぎると、実践内容が薄く聞こえる。

**どう改善するか：** 「目線をカメラに向けることと、話す順番・構成を意識して説明するようにしています。チーム開発でレビューや共有をするうちに、相手に伝わる言い回しを意識するようになりました」のように、やっていることと、身につけた経緯を簡潔にまとめる。

---

### Q: なぜ時間より成果を重視する？

**ここがダメ：** 「残業しても脳が疲れていると生産性が落ちる」など、ネガティブな理由が先に来ている。

**なぜダメか：** 「長時間労働を否定したい」という印象が強くなり、評価制度への不満やスタンスの押し付けに聞こえるリスクがある。

**どう改善するか：** 「短時間でも成果を出せる働き方をしたい」を先に置く。「成果が明確に評価される環境の方が、自分は集中して取り組めます。長時間より、いかにアウトプットの質と量を上げるかを重視しています」のように、ポジティブな理由を主にして、疲労の話は補足程度に。

---

### Q: なぜ自社プロダクトの会社を志望するのか？

**ここがダメ：** 特になし。理由・具体例・面接用表現の流れが整理されており、そのまま使える。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。「AI時代は情報の鮮度が重要」と「一次情報を活かせる」の接続が明確で説得力がある。

---

### 5年後のキャリアビジョン（面接用表現例）

**ここがダメ：** 特になし。御社での経験→チームリード→企画〜実装まで、の階段が分かりやすい。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

## ガクチカ（テレアポ）

### Q: なぜ蓄電池販売のバイトを選んだ？

**ここがダメ：** 「時給が高かった」を2つ目に置いていると、金銭目的が強く印象に残る。

**なぜダメか：** 面接では「なぜその経験をしたか」を成長意欲と結びつけて語ることが多い。時給を先に出されると、動機の中心がお金に見えがち。

**どう改善するか：** 順序を「1. 知らない人と話してコミュニケーション力を伸ばしたかった 2. そのうえで、時給も良かったので選びました」とする。あるいは「成長の機会と待遇の両方を満たしていた」とまとめ、時給は「条件の一つ」として軽く触れる程度にする。

---

### Q: なぜ最初から1位だったのですか？

**ここがダメ：** 特になし。「最初から」への訂正と、「真似る→改善する」のスタンスが伝わる。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

### Q: 大変だったことは？

**ここがダメ：** 特になし。断られへのストレス→分析→仕組み化→軽減、の流れが明確。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

### Q: チームへの貢献は？

**ここがダメ：** 特になし。スクリプト共有・新人教育・属人化しない、がエンジニアの文化と結びついている。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

## E資格インターン

### Q: 1年間続けられたモチベーションは？

**ここがダメ：** 特になし。好奇心と「仕組みを知りたい」が伝わる。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

### Q: 資格を取らなかったのはなぜ？

**ここがダメ：** 「受験費用と得られる価値を天秤にかけた」とあるが、前半で「費用が高額だった」を強調しすぎると、コスト避けの印象が強くなる。

**なぜダメか：** 面接官は「資格より実務で使う力を選んだ」という判断理由を聞きたい。費用の話が先に立つと、判断の軸が「お金」に見えがち。

**どう改善するか：** 「資格そのものより、カリキュラムで得た知識と実装力を大事にしたかった」を先に置く。「受験費用も高かったため、その分は別の学習や個人開発に回す選択をしました」のように、コストは後から理由として添える。

---

### Q: AIについて何を知っていますか？

**ここがダメ：** 特になし。ブラックボックスではなく中身を理解して使う、というスタンスが分かる。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

## 卒業研究

### Q: なぜこのテーマを選んだ？

**ここがダメ：** 「E資格の知識が活かせるから」が中心で、テーマそのものへの興味が弱く聞こえる。

**なぜダメか：** 「やりたいテーマがあったから」と「たまたまスキルが合ったから」では、意欲の伝わり方が違う。受け身の動機に聞こえやすい。

**どう改善するか：** 「化学・生物データをAIで扱うテーマに興味があり、かつE資格で学んだ機械学習がそのまま使えると知って選びました」のように、「興味」を前半に、「活かせる」を後半に置く。

---

### Q: 研究で一番楽しかったことは？

**ここがダメ：** 「データ加工・パラメータ変更で精度が上がるプロセス」だけだと、技術趣味に寄りすぎて、研究の社会的意義が伝わりにくい。

**なぜダメか：** 面接官によっては「何のための研究か」「社会や学術にどう繋がるか」も見る。楽しいの中に、少しでも意義を織り込んだ方がよい。

**どう改善するか：** 「精度を上げる過程が楽しいのはもちろん、動物実験の代替になりうるモデルづくりに携われたことにもやりがいを感じました」のように、応用・意義を一文足す。

---

### Q: 研究内容を簡単に説明してください／なぜ説明可能AIを使ったか／苦労したこと

**ここがダメ：** 特になし。課題・手法・成果・苦労の内容が整理されている。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

## ポートフォリオ

### AIニュース音声要約アプリ「なぜ作ったか」

**ここがダメ：** 「自分の課題を自分で解決する」が最後の一文で、印象が弱い。

**なぜダメか：** 強みとして「自分の課題を自分で解決」を挙げているなら、このアプリはその代表例。動機の中心として前面に出した方が一貫する。

**どう改善するか：** 冒頭で「自分で使いたい情報を、自分で作るツールにしたかったからです」と置き、「AI情報のキャッチアップが大変だったので、通勤時間をインプット時間に変える仕組みを作りました」と続ける。「自分の課題を自分で解決する」は最後の締めとして残してよい。

---

### Q: なぜ「音声」にしたのか？テキストではダメだった理由は？

**ここがダメ：** 特になし。歩きながら使いたい→音声、の論理が明確。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

### 電子書籍→PDF変換「なぜ作ったか」

**ここがダメ：** 本の偏りを避け、複数本から共通知見を取りたい、という動機はよいが、「AIで分析はまだ」という注意が本文にはなく、面接で不用意に「AIで横断分析しています」と言うと齟齬になる。

**なぜダメか：** 事実と違う説明は信頼を損なう。事前に「どこまで実現済みか」を整理しておく必要がある。

**どう改善するか：** 回答の最後に「現時点ではPDF化まで完成しており、AIでの横断分析はこれから活用していく予定です」と一文入れておく。文書内の「注意」とセットで、面接では「完成している機能」と「今後の使い方」を分けて話す。

---

### InRequest「なぜNext.js？他のフレームワークは検討したか？」

**ここがダメ：** 「面接官に評価されやすいフレームワークは？とClaude Codeに聞いて推薦された」を本音として書いているが、このまま面接で言うと判断の主体がAI・他人の評価になっており、説得力が落ちる。

**なぜダメか：** 技術選定は「自分で理由を説明できるか」が問われる。「AIが勧めたから」は補助理由にはなっても、主理由にはしづらい。

**どう改善するか：** 面接では「面接用の補足（技術的な理由）」だけを使う旨を、このブロック内で明記する。「本音は〜だが、面接では次の技術的理由で答える」と書いておくと、準備しやすい。

---

## チーム開発経験（面接用表現）

**ここがダメ：** 特になし。Issue駆動・PR・レビュー・可読性・コミットメッセージが押さえられている。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

## 強み・弱み

### Q: 「観察→分析→仕組み化」のテレアポ以外の具体例は？

**ここがダメ：** 「無料にできないか」が先に来ており、コスト削減の話に聞こえやすい。

**なぜダメか：** 強みは「自分に特化した情報が欲しい→仕組み化した」にある。無料化が前面だと、強みが「節約」にずれる。

**どう改善するか：** 「自分に必要な情報だけを、必要な形式で得たいと思った」を先に置く。「Audibleは便利だが、ノイズが多く、自分専用のニュースが音声で欲しかったので、アプリで仕組み化しました」のように、ニーズ→解決の順で言う。

---

### 弱み（詳細・対策・面接用表現）

**ここがダメ：** 「一旦完成させて、指摘されたら直せばいい」をそのまま面接で言うと、品質よりスピードを優先しすぎる印象になりうる。

**なぜダメか：** 弱みを話すときは「気づいた→こう変えた」を伝えたい。昔のスタンスを強調しすぎると、今もそう思っているように受け取られやすい。

**どう改善するか：** 面接用では「今は実装前に認識合わせをして、スピードを維持しつつミスを防いでいます」を主軸にし、「以前は一旦出してから直す考えでしたが、手戻りを経験して方針を変えました」と経緯を短く添える程度にする。

---

## ストレス・挫折・対人関係

### Q: ストレスを感じるのはどんな時？

**ここがダメ：** 「曖昧な説明や回り道をされると」という言い方だと、ストレスの原因が相手の説明力にあるように聞こえる。

**なぜダメか：** ストレス質問は、自己理解と対処力を示す場。原因を相手に寄せすぎると、協調性やコミュニケーション力に不安を持たれやすい。

**どう改善するか：** 「自分が理解できない状態が続くときです。説明が曖昧だったり、前提が違うまま進んだりすると、そこを解消したくなります」のように、「理解できない状態」を主語にし、相手を責めない言い方にする。

---

### Q: ストレス解消法は？

**ここがダメ：** 特になし。原因分析→行動で変える、というスタンスが一貫している。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

### Q: 留年以外の挫折経験は？／どう立ち直った？／面接用表現

**ここがダメ：** 特になし。浪人→分析→計画→実行、と学びが明確。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

### Q: チームでの自分の役割は？

**ここがダメ：** 特になし。「誰もやらないところをやる」はチーム貢献として説明しやすい。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

### Q: 苦手なタイプの人は？どう対処する？

**ここがダメ：** 「話が長い人」だけを言うと、対人スキルや許容度を心配されやすい。「無駄だと感じてしまう」もやや刺々しい。

**なぜダメか：** 苦手な人の質問は、人間性と対処の両方を見ている。苦手の理由が相手の話し方に寄りすぎると、自分は変われないと思われがち。

**どう改善するか：** 「話が長く、要点が掴みづらい方が苦手です。その場合は『いま何の話でしたっけ？』と優しく確認して、目的に戻るようにしています」のように、苦手の理由を「要点が掴みづらい」に寄せ、対処法を具体的かつ柔らかくする。

---

### Q: 意見が対立したときどうする？

**ここがダメ：** 特になし。相手を聞く→良し悪しで判断→折れる／通す、の流れが分かる。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

## 想定質問集

### 自己紹介

**ここがダメ：** 特になし。学歴・ガクチカ・強み・現状・志望がコンパクトにまとまっている。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

### なぜ当社か（志望企業共通の軸）

**ここがダメ：** 「[具体的なツール名]」のまま本番に持っていくと、その場で考えて噛んだり、企業ごとに詰めていない印象になる。

**なぜダメか：** 志望理由は企業研究の深さを示す部分。具体的ツール名・サービス名を1つでも入れた方が、「調べている」と伝わる。

**どう改善するか：** 企業ごとに［ ］内を実際のツール名・取り組みに置き換えたメモを用意する。複数社受ける場合は、企業別に短く整理したシートがあると安心。

---

### Q: 簿記2級を取った理由は？

**ここがダメ：** 「将来の投資活動に活かせると考えて」は、面接によっては「副業・投資に軸足があるのでは」と受け取られることがある。

**なぜダメか：** 会計は企業理解に役立つが、投資目的が前面に出すぎると、本業への集中を疑われるケースがある。

**どう改善するか：** 「企業の財務や経営状況を読み解く力をつけたくて取りました。就職活動時の企業理解や、プロダクトの採算を考えるうえでも役立っています」のように、本業・就活・仕事の判断に繋がる理由を主にする。

---

### Q: TOEIC 680を取った理由は？英語を使う予定は？

**ここがダメ：** 「現時点で英語を使う具体的な予定はありません」だけだと、資格の活かし方が弱く、受験の動機もぼやける。

**なぜダメか：** 資格は「なぜ取ったか」「今後どう使うか」の両方があると説得力が増す。「予定なし」で終わると、取った意味が薄く聞こえがち。

**どう改善するか：** 「学校の機会で受験し、それ以降も技術ドキュメントや英語の技術情報を読むときに活用しています。今後は海外の技術発信やOSSへの関与でも活かしたいです」のように、現在の活用と今後の方向性を一言ずつ足す。

---

### Q: 高校時代からエンジニアになりたかったきっかけは？

**ここがダメ：** 特になし。Anki→ソフトへの興味→コード→楽しさ→エンジニア、の流れがはっきりしている。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

### Q: 10年後はどうなっていたい？（本音）

**ここがダメ：** 「独立」「しっかり稼げる」をこのまま面接の主軸にすると、定着やチームへのコミットより自分の稼ぎが中心に見えるリスクがある。

**なぜダメか：** 長期的な自立は悪くないが、入社初期は「まずは御社で成果を出し、成長する」ことが前提。先に独立・稼ぎを強調しすぎると、短期離職の不安を招きやすい。

**どう改善するか：** 面接では「面接用表現（控えめver）」を基本にし、独立や稼ぎは「そういう段階を遠くの目標として考えている」程度に留める。

---

### Q: 他にどんな会社を受けている？／複数内定が出たらどう選ぶ？

**ここがダメ：** 志望企業名を「サイボウズ、SmartHR、note、ツクリンク」と具体的に列挙している。受けている会社同士を比較されたり、ランク付けされていると受け取られたりするリスクがある。

**なぜダメか：** 「他社を受けること」自体は自然だが、社名を並べると「うちは第何志望か」を意識されやすく、熱意が分散しているように見える場合がある。

**どう改善するか：** 「AI駆動開発とフルリモートを軸に、自社プロダクトのBtoB SaaSを中心に受けています」のように、業態・志向・条件で答える。社名を聞かれたら「同様の志向の企業を何社か受けています」と概括し、詳しくは「選考が進んでいる段階では控えさせてください」と断る選択肢もある。

---

## 現職について

### 入社理由（面接用表現）

**ここがダメ：** 「新卒としては比較的高い給与水準だったこと」をそのまま言うと、転職理由の「年収の伸び」と組み合わせて「給与重視」と受け取られるリスクがある。

**なぜダメか：** 入社理由に給与を入れること自体はよいが、面接では「市場価値や成長機会を考えて選んだ」という言い方の方が、転職時の年収の言及と整合しやすい。

**どう改善するか：** 「当時は自社プロダクトで経験を積めることと、待遇のバランスを踏まえて選びました」のように、給与を「待遇」に含めた概括にする。あるいは「自分の市場価値を意識しつつ、長く成長できる環境を重視して選びました」と、給与を前面に出さない言い方にする。

---

### Q: 入社前にこれらの不満点は予測できなかったか？／「またすぐ辞めるのでは？」／現職のAI駆動開発の状況は？

**ここがダメ：** 特になし。予測できなかった理由、今回の違い、現職での提案と環境の限界が整理されている。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

### Q: 現職に対する感謝はあるか？／面接用表現（転職理由）

**ここがダメ：** 特になし。感謝→理由→転職の決意の流れがはっきりしている。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

## 浪人・留年・休学

### Q: 浪人した理由を教えてください

**ここがダメ：** 九工大の良さ（唯一の情報工学専門学部・学費・就職率など）の説明が長く、質問の「浪人した理由」より「九工大を選んだ理由」が中心になっている。

**なぜダメか：** 聞かれているのは「なぜ浪人という選択をしたか」（諦めきれなかった・再挑戦した理由）。大学の魅力は「だから受けたかった」の理由として必要だが、長すぎると「浪人した理由」の答えが埋もれる。

**どう改善するか：** 前半は「情報工学を専門的に学べる九工大に強く惹かれ、現役で受験しましたが不合格でした」で一度区切り、「諦めきれず、1年浪人して再受験し、合格しました」で締める。九工大の詳細（唯一の学部・学費・就職率など）は「志望動機は」と聞かれたとき用に短くまとめておき、浪人理由では簡潔に触れる程度にする。

---

### Q: 留年した理由を教えてください

**ここがダメ：** 特になし。反省・学び・休学中の使い方がセットになっており、「遊んでいた」とは言わない指針とも合っている。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

## スキルの学び方（面接用表現）

**ここがダメ：** 特になし。経歴・AI活用・個人開発・「作りながら学ぶ」が一つの流れになっている。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

## 失敗から学んだ経験（面接用ストーリー・面接用表現）

**ここがダメ：** 特になし。状況→課題→行動→結果、そして「認識合わせ」という行動変容が明確。

**なぜダメか：** －

**どう改善するか：** 現状のままでよい。

---

## 添削後の活用のしかた

- 「ここがダメ」＝面接官が引っかかりやすい・あなたの意図が伝わりにくい点
- 「なぜダメか」＝そのまま言うとどう見えがちか
- 「どう改善するか」＝言い回しや順序・追加する一文の目安

本番では一字一句ではなく、「改善の方向性」を踏まえて、自分の言葉で話すと伝わりやすいです。重要な質問（志望動機・転職理由・弱み・他社状況・浪人理由など）から、改善案を自分の口で言えるようにしておくことをおすすめします。

---

# Part 5: 面接対策 — Argus技術Q&A


> Argus プロジェクトをベースにした AI エンジニア面接対策
> 各回答は口頭で1〜3分を想定

---

## 目次

1. [プロジェクト概要](#1-プロジェクト概要)
2. [技術的深掘り](#2-技術的深掘り)
3. [AI/LLM 関連](#3-aillm-関連)
4. [設計判断](#4-設計判断)
5. [課題と解決](#5-課題と解決)
6. [チーム・プロセス](#6-チームプロセス)
7. [弱みへの対策](#7-弱みへの対策)
8. [企業別対策](#8-企業別対策)
9. [パーソナル・キャリア](#9-パーソナルキャリア)

---

## 1. プロジェクト概要

### Q1: Argus とは何ですか？一言で説明してください。

**回答:**

Argus は、Claude Agent SDK を中核にしたマルチエージェントシステムです。Slack をインターフェースとして、自然言語でタスク実行・リサーチ・SNSコンテンツ生成を行います。Railway VPS 上で24時間稼働し、全エージェントの行動を Hook ベースで記録する Observation-First アーキテクチャを採用しています。

TypeScript の pnpm monorepo で、12パッケージ、1,165以上のテスト、18の DB テーブルで構成されています。

---

### Q2: なぜこのプロジェクトを作ったのですか？

**回答（STAR）:**

- **Situation**: AI エージェントの実用化が急速に進む中、「動くデモ」はたくさんあるが「本番運用に耐えるシステム」はまだ少ないと感じていました。
- **Task**: AI エージェントを24時間稼働させる際に必要な設計判断 — 観測可能性、障害復旧、コスト管理、人間の介入ポイント — を体系的に解決するシステムを作ることにしました。
- **Action**: Claude Agent SDK のリリースをきっかけに、CLI プロセス起動方式から SDK ベースに全面移行。Hook によるツール実行記録、MCP によるナレッジ統合、Episodic Memory による自己改善を段階的に実装しました。
- **Result**: Slack から自然言語で指示するだけで、タスク実行・リサーチ・SNS投稿まで一貫して処理できるシステムが完成。10プラットフォームへの自動投稿パイプラインや、自律的な Inbox Agent まで発展しました。

---

### Q3: このプロジェクトの一番の技術的チャレンジは何でしたか？

**回答:**

「AIエージェントの行動を信頼するのではなく、検証可能にする」という設計思想を一貫させることです。

具体的には、SDK が `success: true` を返しても、レスポンステキストに「失敗しました」「エラー」などのパターンがあれば失敗として扱う `detectTaskFailure()` のような仕組みが必要でした。AIの出力をそのまま信頼すると、静かに失敗するケースが頻出します。

また、全ツール実行を Hook で記録し、後から「何が起きたか」を再構成できるようにする Observation-First アーキテクチャの設計も大きなチャレンジでした。これは単にログを取るだけでなく、ツール実行の開始・終了・失敗をそれぞれ異なるタイミングで DB に書き込み、かつメインの実行フローをブロックしない設計が求められました。

---

## 2. 技術的深掘り

### Q4: アーキテクチャの全体像を説明してください。

**回答:**

3層構造です。

**アプリケーション層**として、Slack Bot（ユーザーインターフェース）、Agent Orchestrator（Cron スケジューラー + REST API）、Dashboard（Next.js 16 モニタリング UI）の3つのアプリケーションがあります。

**コア層**として、Agent Core が Claude Agent SDK をラップし、Hook 注入・セッション管理・結果正規化を担当。DB パッケージが Drizzle ORM で18テーブルを管理します。

**統合層**として、Knowledge、Personal Knowledge、Gmail、Google Calendar の4つの MCP サーバーがあり、エージェントに外部サービスへのアクセスを提供します。

全アプリケーションが Agent Core と DB を共有し、MCP サーバーはエージェントの子プロセスとして stdio で通信します。Railway VPS 上の単一 Docker コンテナ内で PM2 がプロセス管理を行い、Cloudflare Tunnel で外部公開しています。

---

### Q5: Session-per-Thread モデルについて詳しく説明してください。

**回答:**

1つの Slack スレッドが1つの Claude セッションに対応します。

新しいスレッドでは `query()` で新規セッションを作成し、DB に `sessionId` を保存します。同じスレッドへの返信は `resume()` でセッションを継続します。resume に失敗した場合は、透過的に新規 `query()` にフォールバックします。

このモデルの利点は、ユーザーが「会話の文脈」を意識せずに複数のタスクを並行して進められることです。チャンネルAのスレッドでリサーチしながら、チャンネルBのスレッドでコード生成を依頼できます。

また、Inbox Agent でも同様のパターンを使っています。タスク完了後にユーザーがスレッドでフォローアップすると、同じセッションで会話を継続できます。

---

### Q6: monorepo 構成で工夫した点は？

**回答:**

pnpm workspace を使い、`@argus/` スコープで12パッケージを管理しています。

設計上最も重視したのは**依存関係の方向性**です。アプリ → コア → 統合 の順に依存が流れ、逆方向の依存は一切ありません。例えば、Agent Core は Slack Bot の存在を知らないし、Knowledge MCP サーバーは Orchestrator の存在を知りません。

これにより、パッケージ単体でのテストが可能になり、1,165以上のテストが全て `pnpm test` 一発で実行できます。

もう一つの工夫は、共通の DB スキーマパッケージです。`@argus/db` にスキーマを集約することで、型安全なテーブルアクセスが全パッケージで保証されます。スキーマ変更は1箇所で行い、`pnpm db:push` で反映します。

---

## 3. AI/LLM 関連

### Q7: プロンプトエンジニアリングで意識していることは？

**回答:**

3つのポイントがあります。

**第一に、コンテキストの段階的開示**です。全情報をプロンプトに詰め込むのではなく、MCP サーバー経由で必要な情報を必要なときに取得させます。Knowledge の ID 参照 + オンデマンド取得がこの設計の核です。

**第二に、Episodic Memory の注入**です。`lessons` テーブルに蓄積されたエラーパターンと解決策を `formatLessonsForPrompt()` でフォーマットし、セッション開始時にプロンプトに注入します。これにより、過去に「Gmail トークンが見つからない」で失敗したなら、次回はそのツールをスキップするのではなく、トークン再取得を試みるようになります。

**第三に、intent ベースの prompt 設計**です。Inbox Agent の分類器が返す `executionPrompt` は、ユーザーの自然言語を「エージェントが実行しやすい指示」に変換したものです。「来週の火曜に会議設定して」→「Google Calendar の create_event を使って次の火曜日にイベントを作成してください」のように具体化します。

---

### Q8: エージェントのコスト管理はどうしていますか？

**回答（STAR）:**

- **Situation**: 10プラットフォームの SNS 提案を毎朝生成すると、各提案で複数回の SDK 呼び出しが発生し、コストが膨らむリスクがありました。
- **Task**: 品質を落とさずにコストを最適化する仕組みが必要でした。
- **Action**: 3つのアプローチを採用しました。
  1. **Dual-Mode Execution**: macOS + Claude CLI が存在する環境では Max Plan（ローカル実行、無料）を自動検出。本番サーバー（Linux）では API キーを使用。ローカル開発のコストをゼロにしました。
  2. **分類には安価なモデル**: Inbox Agent の意図分類には Claude Haiku を使い、実行には Sonnet/Opus を使い分けます。分類のコストは1件 $0.001 以下です。
  3. **承認ゲート**: 動画レンダリング（15〜30分）やポッドキャスト生成など、コストの高い処理は Slack の承認ボタンをゲートにして、無駄な実行を防止しています。
- **Result**: ローカル開発は実質無料、本番のランニングコストは $0.04/セッション程度に収まっています。

---

### Q9: Episodic Memory について詳しく教えてください。

**回答:**

`lessons` テーブルが Episodic Memory の実体です。

ツール実行が失敗すると、`PostToolUseFailure` Hook がエラー内容と文脈を `lessons` テーブルに記録します。例えば「Gmail API で認証エラーが発生した → トークン再取得スクリプトを実行して解決した」という情報が保存されます。

次のセッション開始時に、直近のレッスンを `formatLessonsForPrompt()` で整形し、システムプロンプトに注入します。エージェントはこの情報を参照して、同じ失敗を繰り返さないように行動を調整します。

注意点として、stale なレッスンの管理があります。「Gmail トークンが見つからない」というレッスンが残っていると、エージェントが Gmail ツール自体をスキップしてしまうケースがありました。定期的なクリーンアップが必要です。

---

## 4. 設計判断

### Q10: なぜ MCP（Model Context Protocol）を採用したのですか？

**回答（STAR）:**

- **Situation**: エージェントが Knowledge ベース、Gmail、Calendar にアクセスする必要がありました。REST API、プロンプト注入、直接 DB アクセスなど複数の選択肢がありました。
- **Task**: エージェントにとって自然なツール体験を提供しつつ、権限分離を実現する方法を選定する必要がありました。
- **Action**: MCP サーバーを採用しました。理由は3つです。
  1. **ネイティブなツール統合**: MCP ツールは Bash や Read と同じ並びでエージェントのツールパレットに表示されます。REST API を curl で呼ぶ必要がありません。
  2. **権限分離**: Collector ロールは CRUD 全操作、Executor ロールは検索のみ。MCP サーバー側でツールの可視性を制御し、サービス層でも二重チェックします。
  3. **プロセス分離**: MCP サーバーは子プロセスとして動作するため、Knowledge のメモリリークがメインプロセスに影響しません。
- **Result**: 4つの MCP サーバー（Knowledge, Personal, Gmail, Calendar）を同一パターンで実装でき、新しい外部サービス追加時も同じアーキテクチャで拡張できています。

---

### Q11: なぜ Hook ベースの観測を選んだのですか？ログ解析じゃダメですか？

**回答:**

ログ解析は「事後」の観測です。Hook ベースは「リアルタイム」の観測です。

Argus では `PreToolUse` Hook でツール実行開始時刻を DB に記録し、`PostToolUse` Hook で結果・実行時間・ステータスを書き込みます。これにより、エージェントの実行中に Slack へプログレス通知を送ることができます。ユーザーは「今エージェントが何をしているか」をリアルタイムで見られます。

ログ解析の場合、実行完了後にログファイルをパースして「何が起きたか」を復元する必要があり、リアルタイム通知は不可能です。また、ログのフォーマットが変わるたびにパーサーを修正する必要があります。

実装上の工夫として、`buildSDKHooks()` というブリッジ関数を作りました。これは Argus 独自の `ArgusHooks`（シンプルなコールバック3つ）を SDK の `HookCallbackMatcher[]` フォーマットに変換します。消費側（Slack Bot、Orchestrator）は SDK の内部仕様を知らずに、自分の観測ロジックだけ書けば良い設計です。

---

### Q12: CLI プロセス起動から Agent SDK への移行はどう進めましたか？

**回答（STAR）:**

- **Situation**: 当初は `child_process.spawn()` で `claude` CLI を起動し、stdout/stderr をパースしていました。CLI の出力フォーマットが undocumented で、バージョンアップのたびにパーサーが壊れていました。
- **Task**: SDK への移行で、3つのアプリ（Slack Bot, Orchestrator, Dashboard）に影響を出さずに内部実装を置き換える必要がありました。
- **Action**: ファサードパターンで移行しました。`agent-core` パッケージの公開 API（`query()`, `resume()`, `AgentResult`, `ArgusHooks`）は一切変えず、内部だけ SDK の `query()` AsyncGenerator に置き換えました。`consumeSDKStream()` で AsyncGenerator を `AgentResult` に正規化する変換層を挟むことで、消費側のインポートを一行も変えずに済みました。
- **Result**: 消費側3アプリのコード変更ゼロで移行完了。Hook による リアルタイム観測、型安全なメッセージ処理、安定したセッション管理を獲得しました。

---

## 5. 課題と解決

### Q13: 本番運用で最も困った問題は何ですか？

**回答（STAR）:**

- **Situation**: Slack Bot を再起動した後、一部のメッセージが古いコードで処理される問題が間欠的に発生しました。
- **Task**: 原因を特定し、再発しない仕組みを作る必要がありました。
- **Action**: 調査の結果、Slack Socket Mode が原因でした。Socket Mode は接続中の全インスタンスにメッセージをラウンドロビン配信します。新しいプロセスを起動しても、古いプロセスが kill されていないと、メッセージの半分が古いコードで処理されてしまいます。対策として、起動スクリプトに「既存プロセスの全 kill → 新規起動」のシーケンスを組み込みました。`tsx watch` の監視対象から `packages/**/dist/**` を除外し、依存パッケージのビルドで不要な再起動が発生しないようにしました。
- **Result**: 再起動時の間欠的失敗がゼロになり、24時間稼働の安定性が大幅に向上しました。

---

### Q14: Inbox Agent で「成功したのに実は失敗」というケースはどう対処しましたか？

**回答:**

SDK レベルでは `success: true` が返るのに、エージェントのレスポンス本文に「失敗しました」「できません」「認証エラー」と書いてあるケースです。

`detectTaskFailure()` 関数で、レスポンスの末尾500文字を正規表現でスキャンします。「失敗しました」「できません」「エラーが発生」「認証.*エラー」「No.*tokens? found」などのパターンにマッチしたら、タスクを failed に更新し、Slack リアクションを ❌ に変更します。

同様に `detectPendingInput()` では、レスポンス中の疑問符数をカウントし、3つ以上あればエージェントがユーザーに質問中と判断して waiting ステータスにします。

これはヒューリスティクスなので完璧ではありませんが、「静かな失敗」を大幅に減らせました。将来的には、構造化された失敗シグナルを SDK 側に提案したいと考えています。

---

### Q15: テスト戦略はどうしていますか？

**回答:**

1,165以上のテストを12パッケージに分散して管理しています。

**ユニットテスト**が中心です。各 `.ts` ファイルと同じディレクトリに `.test.ts` をコロケーションしています。DB 層は `vi.mock()` でモック、Agent Core は `fakeStream()` で SDK の AsyncGenerator をモックします。

**テストのポイント**は3つあります。

1. **SDK メッセージのモック**: `fakeStream()` で `SDKSystemMessage`, `SDKAssistantMessage`, `SDKResultSuccess` を任意の順序で流せるようにしています。`session_id` は全メッセージで一致させる必要がある（result メッセージが最後に上書きするため）といった SDK の挙動も再現します。
2. **Hook テスト**: `buildSDKHooks()` の変換が正しいことを、入力オブジェクトの型と出力コールバックの呼び出し回数で検証します。
3. **MCP サーバーテスト**: ツールハンドラーの入出力を直接テスト。ロールベースの権限（Collector/Executor）が正しく動作することを検証します。

---

## 6. チーム・プロセス

### Q16: 一人で開発して何が学べましたか？チーム開発との違いは？

**回答:**

最大の学びは「将来の自分のためにドキュメントを書く」ことの重要性です。

ADR（Architecture Decision Record）を5本書きました。各 ADR には Context（なぜその問題が存在するか）、Decision（何を選んだか）、Alternatives（何を選ばなかったか、なぜか）、Consequences（良い点・悪い点）を記載しています。

2ヶ月後に自分のコードを読み返したとき、ADR がなければ「なぜ MCP を使ったのか」「なぜ CLI 起動をやめたのか」を思い出すのに時間がかかります。特に Alternatives セクションは、「検討した上で却下した選択肢」を記録するもので、同じ議論を繰り返さないための保険です。

チーム開発との違いで言えば、レビューアーがいない分、テストとドキュメントの品質を高くする必要がありました。1,165以上のテストは「レビューアーの代わり」でもあります。

---

### Q17: 今後 Argus をどう発展させたいですか？

**回答:**

3つの方向があります。

**第一に、マルチエージェント協調**です。現在は1つのタスクに1つのエージェントが対応していますが、複雑なタスクでは複数のエージェントが協力する設計を入れたいです。例えば、リサーチエージェントが情報を集め、ライティングエージェントが記事を書き、レビューエージェントが品質チェックするパイプラインです。

**第二に、観測データの活用**です。全ツール実行が DB に記録されているので、「どのツールがよく使われるか」「どのパターンで失敗しやすいか」を分析し、エージェントの行動を最適化するフィードバックループを作りたいです。

**第三に、MCP エコシステムの拡張**です。現在4つの MCP サーバーがありますが、Notion、GitHub Issues、Jira など外部サービスをさらに統合し、エージェントの行動範囲を広げたいと考えています。

---

### Q18: （英語版）Can you describe the Observation-First architecture?

**Answer:**

Sure. The core idea is that every tool invocation by every agent is recorded to the database in real-time, not after the fact.

We use a hook-based system. When the Claude Agent SDK executes a tool — say, reading a file or searching the knowledge base — our `PreToolUse` hook fires and records the start timestamp to the `tasks` table. When the tool completes, `PostToolUse` records the result, duration, and status. If it fails, `PostToolUseFailure` captures the error and creates an entry in the `lessons` table for episodic memory.

The key design choice was to build a bridge layer called `buildSDKHooks()`. It converts our simplified `ArgusHooks` interface — which has just three callbacks — into the SDK's `HookCallbackMatcher` format. This means consumer applications like the Slack bot only need to implement simple callback functions for their observation logic, without understanding SDK internals.

The practical benefit is twofold: first, users see real-time progress in Slack threads as tools execute. Second, the dashboard can reconstruct the complete execution history of any session — which tools were called, in what order, how long each took, and whether they succeeded or failed.

---

### Q19: 技術選定で最も重要視することは何ですか？

**回答:**

**観測可能性**と**段階的な劣化**です。

Argus の設計で一貫しているのは、「何が起きたか後から分かる」ことです。エージェントは予測不可能な行動をとることがあります。だからこそ、全行動を記録し、再構成できる必要があります。

段階的な劣化とは、一部が壊れても全体が止まらない設計です。API キーがなければキーワード分類にフォールバック。resume が失敗すれば新規 query にフォールバック。CLI ヘルスチェックが失敗すれば SNS バッチをスキップ。常に「次善の策」が用意されています。

この2つは AI システムに限った話ではなく、あらゆる本番システムに適用できる原則だと考えています。

---

## 7. 弱みへの対策

### Q20: なぜ Rails ではなく TypeScript/Node.js を選んだのですか？

**回答（STAR）:**

- **Situation**: AI エージェントシステムの技術選定をする際、Rails（Ruby）と TypeScript/Node.js のどちらをベースにするかを検討しました。
- **Task**: AI SDK との親和性、型安全性、エコシステムの成熟度を基準に選定する必要がありました。
- **Action**: TypeScript/Node.js を選択した理由は3つです。
  1. **AI SDK のネイティブサポート**: Claude Agent SDK、OpenAI SDK、MCP SDK は全て TypeScript/JavaScript がファーストクラスです。Ruby 版は存在しないか、コミュニティ版で品質にばらつきがあります。AI エージェント開発では SDK との直接的な型の一致が開発速度と安全性に直結します。
  2. **フルスタックの型一貫性**: フロントエンド（Next.js/React）からバックエンド（Node.js）、DB スキーマ（Drizzle ORM）まで TypeScript で統一できます。`@argus/db` で定義した型がダッシュボードの React コンポーネントまでそのまま流れるので、API 境界での型の不一致が起きません。
  3. **AsyncGenerator / Stream 処理**: Claude SDK の `query()` は AsyncGenerator を返します。Node.js のイベントループモデルはストリーミングレスポンスの処理に最適で、`consumeSDKStream()` のような変換層を自然に書けます。
- **Result**: 12パッケージの monorepo 全体が単一の型システムで統合され、SDK の型定義をそのまま活用できています。「Rails でも作れたか」と聞かれれば作れますが、AI エージェント開発においてはTypeScript のメリットが圧倒的でした。

**補足（Rails に対するリスペクト）:**

Rails の Convention over Configuration や ActiveRecord パターンには大きな学びがあります。実際、Argus でも「設定より規約」の思想は取り入れています。例えば、MCP サーバーの実装パターンを4サーバーで統一し、新しいサーバー追加時にゼロから設計する必要がない構成にしています。

---

### Q21: 個人プロジェクトにしては規模が大きいですが、なぜですか？

**回答（STAR）:**

- **Situation**: 「AI エージェントを作ってみよう」というところから始まりましたが、本番運用を始めると次々に必要な機能が見つかりました。
- **Task**: 24時間稼働するシステムには、単なるプロトタイプでは解決できない課題群（観測可能性、障害復旧、コスト管理、権限分離）がありました。
- **Action**: 3つの要因が規模拡大を可能にしました。
  1. **AI 駆動開発**: Argus 自体の開発に AI を活用しました。Claude Code を使った TDD（RED→GREEN→REFACTOR）サイクルで、テスト作成→実装→リファクタリングを高速に回せました。スキル定義やサブエージェント委譲のワークフローを整備し、1人でも大規模な開発を維持できる体制を構築しています。
  2. **monorepo による分離統治**: 12パッケージに分割することで、各パッケージは100〜500行程度の焦点を絞ったコードになっています。個々のパッケージの複雑度は低く、全体の複合によって規模が生まれています。
  3. **段階的な成長**: 最初から12パッケージを設計したわけではありません。ADR（Architecture Decision Records）で判断を記録しながら、CLI→SDK 移行、ファイルシステム→DB 移行、単一ナレッジ→MCP 分離と段階的に進化させました。
- **Result**: 1,165以上のテストがあることで、リファクタリングやパッケージ追加時の安全性が担保され、一人でも継続的にスケールさせることができています。

---

### Q22: AI エージェントの安全性をどう担保していますか？

**回答:**

4層の安全設計を採用しています。

**第1層: 権限分離（Principle of Least Privilege）**
MCP サーバーでロールベースのアクセス制御を実装しています。Collector ロールは CRUD 全操作（5ツール）、Executor ロールは検索のみ（2ツール）。ツールの可視性を MCP サーバー側で制御し、さらにサービス層で `requireCollector()` によるダブルチェックを行います。仮にエージェントが権限外の操作を試みても、2重の壁で阻止されます。

**第2層: 行動の検証（Trust but Verify）**
`detectTaskFailure()` で SDK の `success: true` を鵜呑みにせず、レスポンス本文の失敗パターンをスキャンします。`detectPendingInput()` でエージェントが質問中かどうかを判定し、自律実行の暴走を防ぎます。

**第3層: 観測可能性（Observation-First）**
全ツール実行を `PreToolUse` / `PostToolUse` Hook で DB に記録します。「エージェントが何をしたか」は全て後から再構成可能です。ダッシュボードでリアルタイム監視でき、異常な行動パターン（同じツールの連続失敗、予期しないツール呼び出し）を検出できます。

**第4層: Human-in-the-Loop**
コストの高い操作（動画レンダリング、ポッドキャスト生成）は Slack の承認ボタンをゲートにしています。Inbox Agent の自律レベルも、タスクの分類結果に応じて「自動実行」「承認待ち」「拒否」を分岐させ、全てが自動実行されないように設計しています。

**補足（既知の限界）:**

`detectTaskFailure()` はヒューリスティクスなので完璧ではありません。構造化された失敗シグナル（SDK レベルでの成功/失敗メタデータ）が理想で、将来的には SDK への提案も検討しています。

---

## 8. 企業別対策

### LayerX（設計課題選考 + eval-driven development）

#### Q23: LayerX の PR-Agent や eval-driven development と Argus のアプローチの違いは？

**回答:**

LayerX さんが PR-Agent で取り組んでいる「コードレビューの AI 自動化」と、Argus の「エージェント行動の観測・検証」は、同じ課題の異なるレイヤーを解決しています。

PR-Agent は**コード品質**の自動検証です。diff を解析し、レビューコメントを自動生成する。Argus の Hook ベース観測は**実行品質**の自動記録です。エージェントが「何をしたか」「成功したか」を構造化データとして蓄積します。

eval-driven development との接点で言うと、Argus の `detectTaskFailure()` は一種の eval です。SDK の `success: true` を信頼せず、レスポンスの内容をパターンマッチで検証する。ただし、これはヒューリスティクスベースです。本格的な eval-driven アプローチでは、テストケースとゴールド標準を定義し、regression を定量的に検出する仕組みが必要です。Argus の `lessons` テーブルに蓄積された失敗パターンは、eval データセットの原型と見ることもできます。

設計課題として出された場合は、「観測データから eval データセットを自動生成し、エージェントの行動品質を定量評価するパイプライン」を提案するのが自然な延長線上だと考えています。

#### Q24: 設計課題が出た場合の進め方は？

**回答:**

まず ADR（Architecture Decision Record）を書きます。Argus でも5本の ADR を作成しており、Context → Decision → Alternatives → Consequences の構造で設計判断を記録する習慣があります。

設計課題では、以下のプロセスで進めます:

1. **要件の明確化**: 制約条件（時間、スケーラビリティ要件、技術スタック）を整理
2. **3つのアプローチを比較**: それぞれの Trade-off を図示（例: 整合性 vs 可用性、コスト vs レイテンシ）
3. **プロトタイプコードで説明**: 抽象的な議論ではなく、TypeScript の型定義やインターフェースで設計意図を伝える
4. **テスト戦略を含める**: その設計をどうテストするかまで提案する

---

### PKSHA（ライブコーディング + 研究発表）

#### Q25: ライブコーディングで Argus の設計力を見せるなら？

**回答:**

3つのデモ候補があります。

**候補1: MCP サーバーのライブ実装**（15分）
新しい MCP サーバー（例: Notion 連携）を一からライブコーディングする。Tool 定義 → Handler 実装 → ロールベース権限 → テストの流れで、Argus の設計パターンが再利用可能であることを示す。

**候補2: Hook ベースの観測ロジック追加**（10分）
新しい Hook（例: コスト集計 Hook）を追加する。`ArgusHooks` インターフェースにコールバックを追加し、`buildSDKHooks()` で SDK フォーマットに変換するデモ。抽象化の有効性を実演。

**候補3: AsyncGenerator のストリーム変換**（10分）
`consumeSDKStream()` と同様のパターンで、任意の AsyncGenerator を正規化する関数をライブ実装。TypeScript の型推論を活用したジェネリクス設計を見せる。

#### Q26: 7,000体の AI エージェント（PKSHA の事例）との技術的な違いは？

**回答:**

PKSHA さんの7,000体は「特定タスクに特化したエージェントの大量デプロイ」です。Argus は「汎用エージェントが MCP ツールで多様なタスクを実行する」モデルです。

スケーリングのアプローチが根本的に異なります。PKSHA は水平スケーリング（エージェント数を増やす）、Argus は垂直統合（1つのエージェントのツール数を増やす）です。

Argus のアーキテクチャを大規模化する場合の提案:
- Session-per-Thread モデルを維持しつつ、タスクキューでエージェント実行をスケールアウト
- 現在の `lessons` テーブルを共有学習ストアに拡張し、エージェント間で失敗パターンを共有
- MCP サーバーをマイクロサービス化し、エージェントプールからネットワーク経由でアクセス

---

### SmartHR（TypeScript/React 枠 + AI 開発部）

#### Q27: TypeScript/React のエンジニアとして、AI 開発にどう貢献できるか？

**回答（STAR）:**

- **Situation**: SmartHR さんが2025年8月に AI 開発部を新設されたということは、既存の TypeScript/React エコシステムに AI 機能を統合する段階だと推測します。
- **Task**: 「AI 専門家を雇う」のではなく「TypeScript エンジニアが AI を使いこなす」方が既存コードベースとの親和性が高いはずです。
- **Action**: Argus で培った3つのスキルが直接活かせます。
  1. **Claude Agent SDK の実践経験**: SDK の AsyncGenerator モデル、Hook によるイベント監視、セッション管理を本番運用レベルで実装しています。
  2. **MCP によるツール統合**: 外部サービス（Gmail、Calendar、Knowledge）を MCP サーバーとして統合した経験は、SmartHR の既存 API を AI エージェントに接続する際に直接応用できます。
  3. **安全設計**: ロールベースのアクセス制御、`detectTaskFailure()` による出力検証、Human-in-the-Loop の承認ゲートなど、AI の出力を信頼しすぎない設計思想は、人事情報を扱う SmartHR のシステムで特に重要です。
- **Result**: 「TypeScript が書けて、AI エージェントの本番運用経験がある」エンジニアとして、AI 開発部の立ち上げに貢献できると考えています。

---

### サイボウズ（OSS 文化 + kintone + 生成 AI）

#### Q28: OSS 文化やチーム開発をどう考えていますか？

**回答:**

サイボウズさんの「チームワークあふれる社会を創る」というミッションに強く共感します。

Argus は個人プロジェクトですが、「未来の自分や他者が理解できる設計」を一貫して重視しています。具体的には:

- **ADR 5本**: 設計判断を Context → Decision → Alternatives → Consequences で記録。「なぜ MCP を選んだのか」「なぜ CLI から SDK に移行したのか」を後から辿れます。
- **1,165以上のテスト**: 「コードの意図をテストで伝える」思想。テストがドキュメント代わりになっています。
- **CLAUDE.md によるオンボーディング**: プロジェクトのルール・規約・アーキテクチャを構造化して記述。新しいコントリビューター（AIエージェント含む）が迷わずに開発を始められる設計です。

サイボウズさんが新人研修資料を毎年全公開されているのは「知識の共有がチーム力を高める」という信念の表れだと思います。Argus の Episodic Memory（`lessons` テーブル）も同じ思想です — エージェントの失敗と学びを組織の知識として蓄積し、次の実行に活かす。

OSS コントリビューションの経験としては、Argus の設計パターン（Hook ベース観測、MCP 権限分離、SDK ファサード）を記事やブログで公開する予定で、コミュニティへの還元を意識しています。

---

### note（シニア職 + LLM/推薦/ベクトル検索）

#### Q29: LLM やベクトル検索の実装経験は？

**回答:**

Argus の Knowledge MCP サーバーで、LLM とベクトル検索に近い設計を実践しています。

**Knowledge の検索アーキテクチャ:**
- `search` ツールがクエリを受け取り、PostgreSQL の `text` 型フィールドに対して全文検索を実行
- タグベースのフィルタリング + テキスト検索の組み合わせで、セマンティックな意図をカバー
- 将来的には pgvector による埋め込みベクトル検索を導入予定（スキーマに embedding カラムを追加する設計は準備済み）

**Episodic Memory の推薦的要素:**
- `lessons` テーブルの蓄積データを `formatLessonsForPrompt()` で関連度順にフィルタし、セッション開始時にプロンプトに注入
- これは「過去の類似失敗パターンをレコメンドする」仕組みであり、推薦システムのコンセプトに近いです

**正直な限界:**
本格的なベクトル検索（FAISS, Pinecone, Weaviate）や大規模推薦システムの本番運用経験はまだありません。ただし、PostgreSQL ベースのデータモデル設計、TypeScript での API 実装、MCP プロトコルによるツール統合の経験は、ベクトル検索基盤の上層実装に直接活かせます。

---

## 9. パーソナル・キャリア

> 既存の個人面接Q&A（interview_episodes.md）から抽出・統合。
> 回答は「結論→理由Nつ→1つずつ深掘り」の型で統一。

### Q30: なぜエンジニアになりたいのですか？

**回答:**

理由は2つあります。1つ目は、提案だけで終わらせず、実際に「動くもの」として形にできるのがエンジニアだと思ったからです。2つ目は、自分の性格として、考えるだけでなく手を動かして仕組みを作り切る方がやりがいを感じるからです。

コンサルのように「こうしたらいい」と示すことも重要ですが、私は最終的に成果として残る形まで持っていきたいので、エンジニアを選びました。

---

### Q31: なぜAI駆動開発の会社を志望するのですか？

**回答:**

理由は2つあります。1つ目は、実務を通じて「AIに任せられる範囲が急速に広がっている」と実感しており、開発の前提が変わっていると感じているからです。2つ目は、その最前線の環境で経験を積むことで、自分の成長速度と成果の質を上げられると考えているからです。

根拠としては、1年間の実務でAIに任せられる範囲がどんどん広がっていることを体感しており、新機能追加の際の要件の叩き上げなど、上流の思考の質までAIで上がる手応えがあります。

---

### Q32: フルリモートがいい理由は？

**回答:**

理由は2つあります。1つ目は、集中して実装に没頭でき、任された期間内で成果を出しやすいからです（自宅に3画面やスタンディングデスクを整備済み）。2つ目は、通勤時間を仕事や学習に充てて、成長と成果に直結させたいからです。

出社のメリット（非言語コミュニケーション、雑談からの関係構築、意思決定速度）は認識しています。だからこそリモートでは、目線をカメラに向ける、文章や図で共有して認識を揃える、区切りで「ここまで大丈夫ですか？」と確認する、といった工夫を意識しています。

---

### Q33: ガクチカ — テレアポで常に1位だった話

**回答（STAR）:**

- **Situation**: 大学時代、人見知り克服とコミュニケーション力向上のため、蓄電池販売のテレアポのアルバイトを始めました。
- **Task**: 成果を上げつつ、限られた稼働時間で効率的に働く必要がありました。
- **Action**: 3つのことを行いました。
  1. 成果を出している先輩のやり方を徹底的に観察して"型"を真似た
  2. 真似して終わりにせず、自分の結果を記録して改善を回した
  3. 断られるパターンを分析し「断られる前に対処する」スクリプトに改善した
- **Result**: 常にチーム内1位を維持。作成したスクリプトをチームに共有し、新人教育にも活用。チーム全体の月間アポ獲得数が約1.3倍に向上（約120件→約155件）。

---

### Q34: 転職理由は何ですか？

**回答:**

理由は2つあります。1つ目は、AI駆動開発を組織として本格的に取り入れている環境で経験を積みたいからです。現職では個人レベルでClaude Codeを活用していますが、組織全体としてはまだ浸透途中です。2つ目は、将来のキャリアの伸びしろを見据えた選択をしたいからです。

現職には大きく感謝しています。社会人1年目として、メール・電話対応からチーム開発のお作法、コードレビューまで教えていただきました。その基礎があるからこそ、次のステップとしてAI駆動開発の最前線で成長したいと考えています。

---

### Q35: 浪人・留年について教えてください

**回答（浪人）:**

九州工業大学に行きたかったのですが現役では不合格で、諦めきれず1年浪人して合格しました。こだわった理由は3つあります。1つ目は国立なので学費負担を抑えられること、2つ目は情報工学に特化したカリキュラムで専門を体系的に学べること、3つ目は就職実績も含めて「情報で勝負する」土台が作れることです。

**回答（留年）:**

正直に申し上げると、大学1〜2年の頃は学業よりバイトに時間を取られすぎて、単位を落としてしまいました。原因は2つあります。1つ目は、卒業に必要な単位を逆算して履修計画を立てていなかったこと。2つ目は、バイトと学業の優先順位の線引きが曖昧だったことです。

この経験から「目標から逆算して優先順位をつける」重要性を痛感し、以降は計画的に行動するようになりました。休学期間中はAIのインターンや営業のアルバイトに取り組み、E資格カリキュラム完走やテレアポ1位という成果にも繋げられました。

---

### Q36: 強みと弱みを教えてください

**回答（強み）:**

「観察→分析→仕組み化」のサイクルを回せることです。テレアポでは先輩のやり方を観察してスクリプトを改善し、Argusでは全ツール実行をHookで記録して改善データを蓄積する仕組みを作りました。

**回答（弱み）:**

自分が理解できない状態が続くとストレスを感じます。説明が曖昧だったり前提が違うまま進んだりすると、解消したくなります。対処として、原因の仮説を立てて言語化し、解消のための具体的な行動を取るようにしています。じっと我慢するより、行動で現状を変えるタイプです。

---

### Q37: 「またすぐ辞めるのでは？」という懸念にどう答えますか？

**回答:**

同じ失敗を繰り返すつもりはありません。ポイントは2つあります。

1つ目は、新卒のときは正直、将来を十分に見据えられていなかったことを自覚していて、今回はAI駆動開発の動向、会社の評価制度、将来性まで調べたうえで転職活動をしていることです。2つ目は、一つの会社で長く働くことで得られる成長や信頼があると考えており、腰を据えて成果を出すつもりだということです。

---

### Q38: 5年後はどうなっていたいですか？

**回答:**

3段階で考えています。

**1年後**: チームの戦力として、AI駆動開発のプラクティスを実務で確立し、周囲にも共有できるレベルになりたいです。

**3年後**: アーキテクチャ設計やテックリードの役割を担い、AI×ソフトウェアの設計判断ができるエンジニアになりたいです。

**5年後**: 新規プロダクトやAI機能の立ち上げをリードできる存在になりたいです。技術選定からチーム構築、品質担保まで一貫して携われるエンジニアが目標です。

---

## 付録: 数字で語れるポイント

| 指標                       | 数値                                      |
| -------------------------- | ----------------------------------------- |
| テスト数                   | 1,165+                                    |
| パッケージ数               | 12                                        |
| DB テーブル数              | 18                                        |
| MCP サーバー数             | 4（Knowledge, Personal, Gmail, Calendar） |
| SNS プラットフォーム数     | 10                                        |
| ADR 数                     | 5                                         |
| 稼働時間                   | 24/7（Railway VPS）                       |
| SDK 移行時の消費側変更     | 0行                                       |
| Inbox Agent 最大並列数     | 3                                         |
| Deep Research タイムアウト | 30分                                      |

---

# Part 6: 面接対策 — Argus完全ガイド


このドキュメントは面接で Argus について聞かれたとき、**設計判断の理由、トレードオフ、失敗と学び、今後の改善点**まで含めて答えられるようにするためのものです。

---

## 1. 一言で説明する（エレベーターピッチ）

> 「Argus は、AI エージェントの運用を自動化するシステムです。Slack から指示を出すと Claude が自律的にタスクを実行し、その過程を全て記録・可視化します。12パッケージの pnpm monorepo で、1,192 のテストケースがあります。」

**30秒版:**

> 「個人で運用している AI エージェントシステムで、Slack Bot、管理ダッシュボード、スケジューラーの3つのアプリと9つの共有パッケージで構成されています。Claude Agent SDK を使ってエージェントを実行し、MCP サーバーで Gmail やカレンダーと連携します。monorepo 設計で型安全性を保ちながら、1,192 テストで品質を担保しています。」

---

## 2. なぜ作ったか（動機）

### 聞かれ方

- 「なぜこのプロジェクトを作ったんですか？」
- 「どんな課題を解決したかったんですか？」

### 答え方

**課題**: AI エージェント（Claude）を日常業務に使いたいが、毎回 CLI を手動で叩くのは非効率だった。特に以下の問題があった：

1. **実行の再現性がない** — 同じプロンプトでも結果が変わる。何がうまくいって何がダメだったかの記録がない
2. **ツール連携が手動** — Gmail を確認して、カレンダーに予定を入れて、Slack に報告して…という手動フローが多すぎる
3. **スケジュール実行ができない** — 毎朝のニュース収集や定期的なコード品質チェックを自動化したい
4. **観測できない** — エージェントが裏で何をやっているか見えない。どのツールをどのくらいの時間使ったか分からない

**解決策**: Slack をインターフェースにして、エージェントの実行・観測・記憶を一元管理するシステムを構築した。

---

## 3. アーキテクチャ（全体像）

### 聞かれ方

- 「アーキテクチャを説明してください」
- 「どういう構成になっていますか？」

### 答え方

```
ユーザー
  ↓ Slack メッセージ
slack-bot (Port 3939)
  ├── SessionManager: query() / resume() で Claude Agent SDK を実行
  ├── MCP サーバー: Gmail, Calendar, Knowledge を疎結合に統合
  ├── Hooks: 全ツール実行を DB に記録
  └── 結果を Slack スレッドに返信

agent-orchestrator (Port 3950)
  ├── Cron スケジューラー: 定期タスクの実行
  ├── Knowledge REST API: ナレッジベースの CRUD
  ├── Daily Planner: 毎朝のデイリープラン生成
  └── Code Patrol: 週次のコード品質チェック

dashboard (Port 3150)
  ├── セッション一覧・詳細表示
  ├── ナレッジベース管理
  ├── ファイルブラウザ（動画・音声配信）
  └── Quick Query（ダッシュボードから直接 Claude に質問）

共有パッケージ (9個)
  ├── agent-core: SDK ラッパー（query, resume, hooks）
  ├── db: Drizzle ORM + PostgreSQL スキーマ
  ├── gmail: Gmail MCP サーバー
  ├── google-calendar: Calendar MCP サーバー
  ├── knowledge: Knowledge MCP サーバー（権限分離）
  ├── knowledge-personal: パーソナルナレッジ MCP サーバー
  ├── r2-storage: Cloudflare R2 ストレージ
  ├── slack-canvas: Slack Canvas 管理
  └── tiktok: TikTok API 連携
```

### 深掘り用：なぜこの構成か

**Q: なぜ3つのアプリに分けたのか？**

A: 関心の分離。slack-bot は「ユーザーとの対話」、orchestrator は「自律的なスケジュール実行」、dashboard は「可視化」という異なる責務を持つ。1つのプロセスにまとめると、Slack Bot の障害がダッシュボードに影響するなど、障害の伝播が起きる。PM2 で個別にプロセス管理することで、1つが落ちても他は動き続ける。

**Q: なぜ monorepo なのか？**

A: 3つのアプリが共有する型定義（DB スキーマ、AgentResult 型等）を一元管理するため。別リポジトリだと、DB スキーマを変更するたびに複数リポジトリを同期する必要がある。pnpm workspace の workspace:\* プロトコルで常に最新のローカルパッケージを参照できる。

**Q: なぜ pnpm なのか？npm や yarn ではダメなのか？**

A: 3つの理由：

1. **ストレージ効率**: pnpm はハードリンクで node_modules を共有するので、monorepo でのディスク使用量が大幅に少ない
2. **厳密な依存解決**: phantom dependencies（明示的に依存宣言していないパッケージの使用）を防ぐ
3. **workspace プロトコル**: `workspace:*` で常にローカルのパッケージを参照でき、monorepo の開発体験が良い

---

## 4. 技術選定の理由

### 聞かれ方

- 「なぜこの技術を選んだんですか？」
- 「他の選択肢と比較しましたか？」

### Claude Agent SDK（最重要）

**選定理由**: 最初は Claude CLI をサブプロセスとして起動し、stdout をパースしていた（cli-runner.ts / stream-parser.ts）。しかし以下の限界があった：

- CLI の出力フォーマットが非公式で、バージョンアップで壊れる
- セッション管理が不安定（resume の挙動が一貫しない）
- hooks（ツール実行の前後処理）ができない

SDK（@anthropic-ai/claude-agent-sdk）に移行したことで：

- **型安全な AsyncGenerator**: `query()` が `AsyncGenerator<SDKMessage>` を返し、型で分岐処理できる
- **公式の hooks API**: `HookCallbackMatcher[]` でツール実行の前後に任意の処理を挿入
- **安定したセッション管理**: `resume()` でセッションを確実に継続

**トレードオフ**: SDK は独自バンドルの cli.js を使うため、ローカルの Claude CLI とは別。Max Plan（ローカル CLI 経由の無料利用）を使う場合の切り替えロジックが複雑になった。

### Drizzle ORM

**選定理由**: TypeScript ファースト。スキーマ定義が TypeScript で書け、クエリの戻り値が型安全。Prisma と比較して：

- **Prisma**: コード生成が必要（`prisma generate`）。ビルドステップが増える。クライアントの型が巨大
- **Drizzle**: コード生成不要。スキーマ定義がそのまま型になる。軽量（バンドルサイズが小さい）

**トレードオフ**: Prisma ほどのエコシステムやドキュメントの充実度はない。複雑な relation のクエリはやや書きにくい。

### MCP（Model Context Protocol）

**選定理由**: エージェントのツール拡張を疎結合にしたかった。MCP なしだと、Gmail 連携のコードが agent-core に直接組み込まれ、依存が密結合になる。MCP サーバーとして分離することで：

- **独立してテスト可能**: Gmail MCP サーバー単体でテストできる
- **動的なツール追加**: Playwright MCP はキーワード検出時のみ追加（約 7,000 トークン節約）
- **権限分離**: Knowledge MCP は Collector（書き込み可）と Executor（読み取りのみ）で権限を分ける

**トレードオフ**: MCP サーバーは child process として起動されるため、起動時のオーバーヘッドがある。また、MCP プロトコル自体がまだ発展途上で、仕様変更のリスクがある。

### Next.js 16 + React 19（Dashboard）

**選定理由**: App Router でサーバーコンポーネントが使え、DB から直接データを取得してレンダリングできる。API ルートでファイル配信（MP4/MP3）もできるので、別途ファイルサーバーを立てる必要がない。

### Supabase + PostgreSQL

**選定理由**: Firebase から移行した。Firebase は NoSQL（Firestore）で、リレーショナルなデータ（sessions → messages → tasks の関係）を扱うのが不自然だった。PostgreSQL + Drizzle ORM にすることで、型安全な SQL クエリが書ける。Supabase はマネージド PostgreSQL として最も手軽。

---

## 5. 設計パターンの解説

### セッション管理

**「1 Slack Thread = 1 Session」の原則**

- 新しいスレッドでメッセージが来たら `query()` で新セッション開始
- 既存スレッドなら `resume()` でセッション継続（文脈を保持）
- resume が失敗したら query にフォールバック（SDK のセッションが期限切れの場合）
- user/assistant 両方のメッセージを DB に保存し、後から再構成可能

**なぜこの設計か**: Slack のスレッドがユーザーにとって自然な「会話の単位」だから。別々のスレッドは別々の文脈として扱うのが直感的。

### Hooks（観測パターン）

**最も重要な設計判断の一つ。**

- `PreToolUse`: ツール実行前に開始時刻を記録 + Slack に「〜を実行中...」と通知
- `PostToolUse`: ツール実行後に結果・所要時間・ステータスを DB に保存
- `onToolFailure`: ツール失敗時にエラーを lessons テーブルに記録（エピソード記憶）

**なぜ観測が重要か**: エージェントは「ブラックボックス」になりがち。何が起きたか後から分かるようにしないと、問題の原因特定ができない。tasks テーブルに全ツール実行を記録することで、「あの処理で何分かかったか」「どのツールが失敗したか」を定量的に把握できる。

### 権限分離（Collector/Executor）

- **Collector エージェント**: Knowledge の add/update/archive/search/list（書き込み権限あり）
- **Executor エージェント**: Knowledge の search のみ（読み取り専用）

**なぜ**: エージェントに全権限を与えると、誤って重要なナレッジを上書きしたり削除したりするリスクがある。最小権限の原則で「壊れにくさ」を作る。

### DB クライアントの遅延初期化

`Proxy` を使い、最初の DB アクセス時にのみ接続を確立する。

**なぜ**: Next.js のビルド時に `import { db } from "@argus/db"` が評価されるが、ビルド時には DATABASE_URL がない。遅延初期化にすることで、ビルドは通るが実際の接続はランタイムまで遅延される。Dockerfile でダミー DATABASE_URL を使うハックも不要になる。

### Max Plan 自動切り替え

- macOS + `~/.local/bin/claude` が存在 → Max Plan（ローカル Claude Desktop 経由、API キー不要）
- Linux（サーバー）→ API キー使用

**なぜ**: ローカル開発時は Max Plan（月額制の Claude Desktop に含まれる）を使えば API コストがゼロ。サーバーでは Claude Desktop がないので API キーが必要。この切り替えを自動化した。

**注意点**: `which claude` コマンドは子プロセスの PATH 依存で失敗するケースがあったため、`fs.existsSync()` で直接ファイルの存在をチェックする方式に変更した。

---

## 6. テスト戦略

### 聞かれ方

- 「テストはどうやって書いていますか？」
- 「1,192 テストケースって多いですが、どういう方針ですか？」

### 答え方

**方針**: 全てのモジュールにコロケーションテスト（`foo.ts` の隣に `foo.test.ts`）を置く。

**テストの種類**:

- **Unit テスト（99%）**: `vi.mock()` で依存をモックし、関数単位でテスト
- **Integration テスト（1ファイル）**: orchestrator の統合テスト
- **テスト環境**: Vitest 4、dashboard は jsdom + Testing Library

**テスト対象の優先順位**:

1. **ビジネスロジック**: メッセージ分類、タスク実行判定、進捗通知フォーマット
2. **データ変換**: SDK メッセージの AgentResult への変換、mrkdwn フォーマット
3. **エラーハンドリング**: フォールバック、タイムアウト、不正入力

**SDK のテスト方法**: `fakeStream()` ヘルパーで `AsyncGenerator<SDKMessage>` をモック。実際の Claude API を呼ばずに、SDK の応答パターン（init → assistant → result）をシミュレート。

**なぜこの量か**: エージェントの挙動は非決定的（同じ入力でも異なる出力）だが、その周辺のコード（入力のパース、出力のフォーマット、DB への保存）は決定的。決定的な部分を徹底的にテストすることで、非決定的なエージェントの出力に対しても「周辺が壊れていない」という安心感を持てる。

---

## 7. 失敗と学び

### 聞かれ方

- 「開発で苦労したことは？」
- 「失敗から学んだことは？」

### 答え方（3つ用意）

#### 失敗1: CLI ラッパーの限界

**何が起きたか**: 最初は Claude CLI をサブプロセスとして起動し、stdout をパースしていた。しかし CLI のバージョンアップで出力フォーマットが変わり、パーサーが壊れた。

**学び**: 非公式なインターフェースに依存すると、上流の変更で壊れる。公式 SDK に移行したことで、型安全かつ安定した統合ができるようになった。レガシーコード（cli-runner.ts, stream-parser.ts）は参考用に残しているが、もう使っていない。

#### 失敗2: Slack Socket Mode の複数インスタンス問題

**何が起きたか**: slack-bot を再起動する際、古いプロセスを kill せずに新しいプロセスを起動してしまった。Slack Socket Mode は接続中の全インスタンスにメッセージをラウンドロビン配信するため、メッセージが古いコードで処理されて間欠的に失敗した。

**学び**: プロセス管理は「起動」だけでなく「停止」も重要。PM2 を導入し、`pm2 restart` で確実にプロセスを入れ替えるようにした。

#### 失敗3: lessons テーブルの stale データ

**何が起きたか**: lessons テーブル（エピソード記憶）に「Gmail トークンが見つからない」というレッスンが残っていた。その後トークンを設定したのに、エージェントがレッスンを参照して「Gmail は使えない」と判断し、Gmail ツールをスキップし続けた。

**学び**: エピソード記憶は「状況が変わったら更新・削除する」仕組みが必要。lessons の自動クリーンアップスクリプトを導入し、古いレッスンを定期削除するようにした。

---

## 8. 今後の改善点

### 聞かれ方

- 「今後改善したい点は？」
- 「もし作り直すとしたら何を変えますか？」

### 答え方

1. **E2E テストの追加**: 現在は Unit テストが中心。Slack Bot の end-to-end フロー（メッセージ送信 → SDK 実行 → DB 保存 → Slack 返信）をテストするフレームワークを構築したい

2. **コスト最適化**: 現在は全てのリクエストで Opus を使っているが、簡単な質問には Haiku で十分。リクエストの複雑さに応じてモデルを自動選択する仕組みを入れたい

3. **マルチテナント化**: 現在は自分専用だが、チームで使えるようにするには認証・認可の仕組みが必要。Dashboard に認証を追加し、ユーザーごとにセッションを分離する

4. **エラーリカバリの強化**: SDK のセッションが切れた場合のリカバリがフォールバック方式（resume 失敗 → 新規 query）だが、メッセージ履歴を引き継ぐ仕組みがない

5. **メトリクス・ダッシュボード**: tasks テーブルのデータを集計して、ツール使用頻度・平均実行時間・エラー率を可視化したい

---

## 9. 数字で語る

面接では「数字」が説得力を持つ。以下を暗記しておく：

| 指標                      | 数値                                                |
| ------------------------- | --------------------------------------------------- |
| パッケージ数              | 12（3 apps + 9 packages）                           |
| テストケース数            | 1,192                                               |
| テストファイル数          | 91                                                  |
| TypeScript 行数           | 約 54,500行                                         |
| DB テーブル数             | 17                                                  |
| MCP サーバー数            | 4（Gmail, Calendar, Knowledge, Knowledge-Personal） |
| 対応 SNS プラットフォーム | 10                                                  |
| スキル定義数              | 32                                                  |
| ADR（設計判断記録）数     | 5                                                   |
| 設計文書数                | 17                                                  |
| 開発期間                  | 約3ヶ月（2025年12月〜）                             |
| デプロイ環境              | Railway VPS + Cloudflare Tunnel + Access            |

---

## 10. よくある面接質問 Q&A

### Q: このプロジェクトで一番難しかったことは？

A: 「Claude Agent SDK への移行判断と実行」です。既に CLI ラッパーで動いていたので「動いているものを変える」リスクがあった。しかし CLI の出力パーサーが壊れやすく、hooks も使えなかった。SDK の AsyncGenerator API を理解し、既存の公開 API（AgentResult 型）を変えずに内部実装だけ差し替える設計にしたことで、消費側（slack-bot, orchestrator, dashboard）のコードを一切変更せずに移行できました。

### Q: チーム開発を意識した設計はありますか？

A: はい、3つあります：

1. **monorepo + 型安全**: パッケージ間の依存を TypeScript の型で保証。DB スキーマの変更が消費側で即座にコンパイルエラーになる
2. **権限分離**: Collector/Executor パターンで最小権限を実現。新しいエージェントを追加する人が Knowledge を壊すリスクを減らす
3. **ADR**: 5つの Architecture Decision Records で設計判断の経緯を文書化。後から join する人が「なぜこうなっているか」を理解できる

### Q: セキュリティはどう考えていますか？

A: 3つのレイヤーで対策しています：

1. **アプリケーション**: `.claude/settings.json` で deny-first の権限設定。`.env`、`rm -rf`、`DROP TABLE` 等の危険な操作を拒否
2. **インフラ**: Cloudflare Access でメール認証。Dashboard は認証なしではアクセスできない
3. **データ**: API キーやトークンは環境変数で管理し、コードにハードコードしない。DB のトークンカラムも環境変数経由

### Q: パフォーマンスの工夫は？

A: 3つあります：

1. **Playwright MCP の動的追加**: ブラウザ操作が必要なキーワードが検出された時のみ Playwright MCP サーバーを起動。常時起動だと約 7,000 トークンのツール定義が常に送信されるが、動的追加で不要時のコストを削減
2. **進捗通知のスロットル**: Slack への進捗メッセージを 5秒/8秒 スロットルで送信。ツールが高速に連続実行される場合のメッセージ氾濫を防止
3. **DB クライアントの遅延初期化**: Proxy パターンで初回アクセス時のみ接続。ビルド時やテスト時の不要な接続を回避

### Q: AI でコード書いてるだけじゃないの？

A: Claude Code を活用して開発していますが、**設計判断は全て自分で行っています**。例えば：

- CLI → SDK 移行の判断は、CLI パーサーが壊れた経験から自分で決断した
- MCP による疎結合設計は、直接統合で依存が絡まった経験からの学び
- 権限分離（Collector/Executor）は、エージェントがナレッジを誤って上書きした事故から設計した

AI はコードの実装を高速化するツールであり、**何を作るか・なぜそう設計するかは人間が決める**。CLAUDE.md や skills/ の設計パターンは「AI に何をさせるか」のコンテキストエンジニアリングであり、これ自体がスキル。

### Q: なぜ個人開発なのにこんなに規模が大きいのか？

A: Claude Code を使って開発しているからです。ただし「AI に全部書かせた」のではなく、**AI の生産性を最大化する仕組み自体を設計した**のがポイントです：

- `CLAUDE.md` にプロジェクトの全体像とコーディング規約を集約 → AI が一貫したコードを生成
- `.claude/rules/` でアーキテクチャルールを文書化 → AI が設計パターンを踏襲
- `.claude/skills/` でタスクのテンプレートを定義 → 繰り返しタスクの品質が安定
- hooks で段階的開示 → AI のコンテキストウィンドウを効率的に使用

これは「AI 駆動開発のワークフロー設計」であり、単にコードを書く以上のスキル。

### Q: Firebase から Supabase に移行した理由は？

A: 3つの理由：

1. **データモデルの不一致**: Firestore は NoSQL で、sessions → messages → tasks のリレーショナルな構造を扱うのが不自然。join ができないのでクライアント側で結合する必要があった
2. **型安全性**: Drizzle ORM + PostgreSQL なら、スキーマ定義がそのまま TypeScript の型になる。Firestore のドキュメント型は手動で定義が必要
3. **SQL の表現力**: 集計クエリ（ツール使用頻度、平均実行時間）が SQL なら簡潔に書ける

---

## 11. 企業別のアピールポイント

### ラッコ向け

- **AI 活用**: Claude Agent SDK 統合、CLAUDE.md によるコンテキストエンジニアリング → 「AI を前向きに受け入れ、自ら学び、チームに展開できる」
- **AWS**: （サブプロジェクトで補強後）Lambda + API Gateway + DynamoDB の実装経験
- **フルリモート**: テキストベースのコミュニケーション文化（ADR、設計文書17本）

### アシアル向け

- **技術スタック一致**: TypeScript, React, Node.js, Next.js, Jest (Vitest)
- **AI 活用**: GitHub Copilot, ChatGPT を活用する文化に Argus の AI 駆動開発が刺さる
- **グローバル志向**: 英語ドキュメントの読み書き、OSS ツールの活用

### SO Technologies / Helpfeel 向け

- **React/Node.js の実務力**: Dashboard (React 19) + Orchestrator (Express 5)
- **テスト文化**: 1,192 テストケース、コロケーション方式

### テックタッチ向け

- **AI Agent 経験**: Claude Agent SDK、MCP、hooks、セッション管理 → AI Agent 事業の立ち上げに直接活かせる
- **設計力**: 権限分離、エピソード記憶、コンテキストエンジニアリング

### note 向け

- **AI 活用が日常**: CLAUDE.md、skills、hooks の設計 → 「AI コーディングエディタを日常的に活用」
- **個人 Web サービス開発**: Argus 自体が「個人で運用している Web サービス」

### GitLab / Sales Marker 向け

- **TypeScript + AI**: GitLab Duo のエディタ拡張、Sales Marker の Next.js フロントエンド
- **非同期コミュニケーション**: ADR、設計文書、テキストベースの意思決定

---

## 12. 自己紹介テンプレート（2分）

> 九州工業大学情報工学科を2025年3月に卒業し、約1年の実務経験があります。
>
> 技術スタックは TypeScript、React、Next.js、Node.js が中心で、個人開発として「Argus」という AI エージェント運用システムを作っています。
>
> Argus は Slack から指示を出すと Claude が自律的にタスクを実行するシステムで、12パッケージの pnpm monorepo、1,192 のテストケース、4つの MCP サーバーで構成されています。
>
> 特に力を入れたのは、Claude Agent SDK の統合と MCP によるツール拡張の疎結合設計です。最初は CLI ラッパーで実装していましたが、安定性の問題から SDK に移行する判断をし、公開 API を変えずに内部実装を差し替えました。
>
> AI を「使う」だけでなく、「AI の生産性を最大化するワークフロー」を設計することに興味があり、CLAUDE.md やスキル定義によるコンテキストエンジニアリングも実践しています。
>
> 御社の[事業/技術]に、この経験を活かして貢献したいと考えています。

---

_作成日: 2026年2月14日_

---

# Part 7: Argus コードベースガイド


> 面接対策・自己学習用の包括的リファレンス。
> 各フォルダ・ファイルの「なぜそこにあるのか」「中で何をしているのか」「どんな書き方をしているのか」を解説する。

---

## 目次

1. [はじめに — このドキュメントの読み方](#1-はじめに)
2. [全体フォルダ構成 — モノレポの地図](#2-全体フォルダ構成)
3. [packages/agent-core — AI エージェントの心臓部](#3-packagesagent-core)
4. [packages/db — データの永続化層](#4-packagesdb)
5. [packages/knowledge & knowledge-personal — ナレッジ管理 MCP](#5-packagesknowledge--knowledge-personal)
6. [packages/gmail & google-calendar — Google 連携](#6-packagesgmail--google-calendar)
7. [packages/r2-storage, slack-canvas, tiktok — その他の連携](#7-packagesr2-storage-slack-canvas-tiktok)
8. [apps/slack-bot — Slack ユーザーインターフェース](#8-appsslack-bot)
9. [apps/agent-orchestrator — バックエンドオーケストレーター](#9-appsagent-orchestrator)
10. [apps/dashboard — Web ダッシュボード](#10-appsdashboard)
11. [ルート設定ファイル群 — プロジェクトの骨格](#11-ルート設定ファイル群)
12. [.claude/ ディレクトリ — AI エージェント設定](#12-claude-ディレクトリ)
13. [横断的パターン集 — コードベース全体の設計原則](#13-横断的パターン集)
14. [面接想定 Q&A](#14-面接想定-qa)

---

## 1. はじめに

### このドキュメントの読み方

本ドキュメントは **TECH_STACK_AND_ARCHITECTURE.md の姉妹編** として、「何を選んだか」ではなく **「コードがどう配置され、どう書かれているか」** にフォーカスする。

各セクションは以下の構成で統一されている:

| アイコン                       | セクション                     | 内容 |
| ------------------------------ | ------------------------------ | ---- |
| **ひとことまとめ**             | 1 文で「これは何？なぜ必要？」 |
| **身近なたとえ**               | 日常生活の例えで概念を説明     |
| **図で理解する**               | ASCII 図、フロー図、比較図     |
| **もう少し詳しく**             | 中級者向けの技術解説           |
| **実際のコード（上級者向け）** | 最小限のコード例               |
| **理解度チェック**             | 理解の確認クイズ               |

### 前提知識

- TypeScript の基本文法（型、インターフェース（「型の設計図」。実装を含まず構造だけを定義したもの）、ジェネリクス（型を引数として受け取り、汎用的に使える仕組み））
- Node.js のモジュールシステム（ESM の `import` / `export`）
- Git の基本操作

---

## 2. 全体フォルダ構成

### ひとことまとめ

> Argus は「モノレポ（1 つのリポジトリに複数のプロジェクトをまとめる管理方法）」で構成されており、`apps/`（実際に動くプログラム）と `packages/`（共有部品）に分かれている。

### 身近なたとえ

```
Argus は 1 つの「会社」

apps/     = 各部署のオフィス（実際にお客さん対応する場所）
packages/ = 共有の備品室・倉庫（各部署が使う共通の道具）
.claude/  = AI 助手の設定書・マニュアル
```

レゴで例えると、`packages/` が個々のブロック、`apps/` がブロックを組み合わせた完成品。

### 図で理解する

#### モノレポの構造

```
argus/ ← 「会社」全体
│
├── apps/ ← 「各部署のオフィス」（実際に稼働するプログラム）
│   │
│   ├── slack-bot/       🤖 受付（お客さんと話す窓口）
│   ├── dashboard/       📊 管理室（状況を見るモニター）
│   └── orchestrator/    🕐 スケジューラ（定期作業の管理人）
│
├── packages/ ← 「共有の備品・道具」（各部署が使う共通部品）
│   │
│   ├── agent-core/      🧠 AI の脳みそ（Claude SDK のラッパー）
│   ├── db/              💾 データの倉庫（PostgreSQL スキーマ定義）
│   ├── knowledge/       📚 知識の図書館（組織ナレッジ管理）
│   ├── knowledge-personal/ 📝 個人メモ帳（パーソナリティ管理）
│   ├── gmail/           📧 メール配達人（Gmail API + OAuth2）
│   ├── google-calendar/ 📅 予定管理人（Google Calendar 連携）
│   ├── r2-storage/      📦 ファイル倉庫（クラウドストレージ）
│   ├── slack-canvas/    🖼️ 掲示板係（Slack Canvas API）
│   └── tiktok/          🎵 動画配信係（TikTok API + 認証）
│
├── .claude/ ← 「AI 助手の設定書」
│   ├── agents/          🤖 エージェント定義（4 種類の AI 助手）
│   ├── rules/           📏 社内ルール（アーキテクチャ・コーディング規約）
│   ├── skills/          🎯 スキル定義（32 個の専門技能）
│   └── settings.json    🔒 権限設定（やっていいこと・ダメなことのリスト）
│
├── docs/                📄 ドキュメント
├── scripts/             🔧 運用・テストスクリプト
│
├── package.json         📋 プロジェクト全体の設定表
├── pnpm-workspace.yaml  🗂️ ワークスペース定義（「この中の全部がウチの社員」）
├── tsconfig.json        ⚙️ TypeScript 共通設定
├── Dockerfile           🐳 本番環境の設計図
├── ecosystem.config.cjs 🏭 PM2 設定（プロセス管理ツールの設定）
└── .env                 🔑 環境変数（パスワードや API キーの一覧）
```

#### 依存関係の方向

```
┌─────────────────────────────────────────────────────┐
│  apps/（完成品 = ブロックを組み合わせたもの）        │
│                                                     │
│  slack-bot ──→ agent-core, db, gmail, calendar...   │
│  dashboard ──→ agent-core, db                       │
│  orchestrator ──→ agent-core, db, knowledge...      │
└──────────────────────┬──────────────────────────────┘
                       │ 常に「上 → 下」の一方向
                       ▼
┌─────────────────────────────────────────────────────┐
│  packages/（共通部品 = 個々のブロック）              │
│                                                     │
│  knowledge ──→ db                                   │
│  google-calendar ──→ gmail（認証を共有）            │
│  （packages 間の依存は最小限に抑える）              │
└─────────────────────────────────────────────────────┘
```

**重要な原則**: 依存は常に `apps/ → packages/` の一方向。部品（packages）が完成品（apps）に依存することはない。

### こうしなかったらどうなる？

もし `packages/` と `apps/` を分けずに 1 つのフォルダに全部入れたら:

- 「この関数はどのプログラムから使われているの？」が分からなくなる
- 複数のアプリで同じ処理をコピペすることになり、修正時に全部直す必要が出る
- チーム開発で「自分の担当範囲」が曖昧になる

### 理解度チェック

1. `apps/` と `packages/` の違いを一言で説明できるか？
2. `slack-bot` が依存しているパッケージを 3 つ挙げられるか？
3. なぜ `google-calendar` は `gmail` に依存しているか？

---

## 3. packages/agent-core

### ひとことまとめ

> AI エージェント（Claude）を動かすための中核エンジン。AI への指示の送信、応答の受信、実行記録の保存を担当する。

### 身近なたとえ

agent-core は「通訳者」のようなもの。あなた（アプリ）が「こう聞いて」と頼むと、通訳者が AI に正しく伝えて、返答を整理して返してくれる。通訳者自身はメモ帳（データベース）を持たず、「メモが必要なら持ってきて」と頼む側に任せる。

### 図で理解する

#### 実行パイプライン（AI に質問してから回答が返るまで）

```
あなた: 「明日の天気を教えて」
         │
         ▼
    ┌─────────────┐
    │  query()    │  AI への質問を準備する
    │  新規セッション │  （タイムアウトも設定）
    └──────┬──────┘
           │
           ▼
    ┌─────────────────┐
    │ consumeSDKStream │  AI の応答を少しずつ受け取る
    │ ストリーム消費    │  （YouTube のストリーミング再生のように）
    └──────┬──────────┘
           │
           │  メッセージが 1 つずつ届く:
           │  📋 system  → セッション ID を取得
           │  💬 assistant → テキストやツール呼び出し
           │  ✅ result → 最終結果とコスト
           │
           ▼
    ┌─────────────┐
    │ AgentResult │  まとめた結果を返す
    │  { success, message, toolCalls }
    └─────────────┘
```

#### ストリーミングの利点（なぜ全部待たないのか）

```
❌ 全部待つ方式（ダウンロードしてから再生）
   AI が 100 個のメッセージを生成...
   ──────────────────────── 全部届くまで何も表示できない
                                              │やっと表示

✅ ストリーミング方式（少しずつ再生）
   メッセージ 1 → 即表示
   メッセージ 2 → 即表示    ← ユーザーは待たされない！
   メッセージ 3 → エラー！ → 即中断（残りを待たない）
```

### 図で理解する: DI（依存性注入）

「agent-core は DB に直接依存しない」という設計の核心を図で説明する。

```
❌ Before（直接依存 = がっちり固定）

┌──────────┐    ┌──────┐
│agent-core│───→│  db  │ ← この線が「がっちり固定」
└──────────┘    └──────┘
問題: db を変えると agent-core も壊れる
     テスト時にも本物の DB が必要

✅ After（DI = 規格書だけ決める）

┌──────────┐    ┌────────────┐    ┌──────┐
│agent-core│───→│ 規格書     │←───│  db  │
└──────────┘    │（interface）│    └──────┘
                └────────────┘
OK: 規格書さえ満たせば何でも差し込める
   テスト時は「ダミー DB」を差し込める
   将来 MongoDB に変えても agent-core は無傷
```

> **身近なたとえ**: 充電器の規格（USB-C）を決めておけば、どのメーカーの充電器でも使える。agent-core は「充電口の形」だけ定義し、実際の充電器（DB 実装）は使う側が持ってくる。

#### DI の具体的な対応表

| 規格書（インターフェース）             | 定義場所             | 実装場所                             |
| -------------------------------------- | -------------------- | ------------------------------------ |
| `SessionStore`（セッション記録の規格） | session.ts           | slack-bot の session-manager.ts      |
| `LessonStore`（教訓記録の規格）        | lessons.ts           | orchestrator が DB クエリで実装      |
| `ObservationDB`（観測記録の規格）      | observation-hooks.ts | 各 app が Drizzle インスタンスを渡す |
| `ArgusHooks`（フック処理の規格）       | hooks.ts             | 各 app がコールバックを実装          |

### もう少し詳しく

#### ファイル構成と各ファイルの役割

```
packages/agent-core/src/
├── agent.ts              🎯 核心: AI に質問する・会話を続ける
├── session.ts            📋 セッション記録の「規格書」（実装は含まない）
├── hooks.ts              🔌 フック変換器（Argus 形式 → SDK 形式）
├── observation-hooks.ts  👁️ AI がツールを使った記録をDBに保存する仕組み
├── mcp-base-server.ts    🏭 MCP サーバーの共通テンプレート（全 MCP サーバーが継承）
├── mcp-config.ts         ⚙️ MCP サーバー設定の共通定義
├── fire-and-forget.ts    🔥 結果を待たない処理の安全な実行
├── text-utils.ts         ✂️ テキスト加工（分割、日本語要約）
├── lessons.ts            📖 教訓のフォーマッター
├── artifact-uploader.ts  📸 成果物の検出（Before/After で比較）
├── types.ts              📐 型定義（AgentResult, Block, ToolCall 等）
└── index.ts              🚪 公開 API の窓口（外部に公開するものを選別）
```

#### `query()` — エラー時の安全設計

AI 処理でエラーが起きたとき、`throw`（エラーを投げる）ではなく `errorResult()` で `success: false` を返す。

**こうしなかったらどうなる？**

```
❌ throw する場合:
  ユーザー A のリクエストで API エラー
  → throw → 未キャッチ例外でプロセスクラッシュ
  → ユーザー B, C, D も同時に Slack Bot と切断！

✅ success: false を返す場合:
  ユーザー A のリクエストで API エラー
  → { success: false, error: "..." } を返す
  → ユーザー A には「失敗しました」と通知
  → ユーザー B, C, D は通常通り利用継続
```

> **身近なたとえ**: 1 つの電話が故障しても交換機全体は止まらない仕組み。問題のある回線だけを切断し、他の回線は正常に動き続ける。

#### `AbortController` によるタイムアウト制御

`AbortController` は、実行中の処理を途中でキャンセルするための Web 標準 API。

> **身近なたとえ**: レストランで 30 分待っても料理が来なければ「もう結構です」と言える仕組み。注文が通っているのに永遠に待たされることを防ぐ。

#### 観測フック — AI の行動を記録する仕組み

AI がツール（道具）を使うたびに「いつ始めて、いつ終わって、何秒かかったか」を記録する。

```
AI: 「メール検索ツールを使います」
   │
   ▼  PreToolUse（開始通知）
   Map に記録: { ゼッケン番号: "tool-123", 開始時刻: 14:00:00, DB ID: "abc" }
   │
   ▼  ... 3 秒間処理 ...
   │
   ▼  PostToolUse（終了通知）
   Map から取り出し: 「ゼッケン 123 番、14:00:03 通過 → タイム 3 秒」
   DB を更新 → Map から削除
```

> **身近なたとえ**: マラソンのチェックポイントで、各ランナーの通過時刻をゼッケン番号で記録する仕組み。

#### McpBaseServer — MCP サーバーの共通テンプレート

```
┌─────────────────────────────────────────────────┐
│  McpBaseServer（共通テンプレート）               │
│  ・Server インスタンス生成    ← 全店共通         │
│  ・ListTools ハンドラ登録     ← 全店共通         │
│  ・CallTool ハンドラ登録      ← 全店共通         │
│  ・StdioServerTransport 接続  ← 全店共通         │
├─────────────────────────────────────────────────┤
│  サブクラスが実装する部分:                       │
│  ・getTools()        → どんな道具があるか        │
│  ・handleToolCall()  → 道具をどう使うか          │
│  ・formatResult()    → 結果をどう整形するか      │
└─────────────────────────────────────────────────┘
         │
         │ 継承
         ▼
┌────────────┐ ┌────────────┐ ┌────────────┐ ┌────────────┐
│ knowledge  │ │ knowledge- │ │   gmail    │ │  google-   │
│   MCP      │ │ personal   │ │   MCP      │ │ calendar   │
│  サーバー  │ │   MCP      │ │  サーバー  │ │   MCP      │
└────────────┘ └────────────┘ └────────────┘ └────────────┘
 メニューと    メニューと     メニューと     メニューと
 調理法だけ    調理法だけ     調理法だけ     調理法だけ
 独自に定義    独自に定義     独自に定義     独自に定義
```

> **身近なたとえ**: マクドナルドのフランチャイズのように、「店舗の設計図」を本部が用意し、各店舗はメニューと調理法だけを独自に実装する。

#### `fireAndForget()` — 安全な「撃ちっぱなし」

非同期処理（時間のかかる処理）を `await`（結果を待つ命令）せずに放置すると、エラー時に「Unhandled Promise Rejection」という警告が出て、最悪プロセスがクラッシュする。`fireAndForget()` は「結果は待たないが、エラーだけは記録する」安全な方法。

### 実際のコード（上級者向け）

<details><summary>query() の実装</summary>

```typescript
export async function query(
  prompt: string,
  options?: AgentOptions,
): Promise<AgentResult> {
  try {
    const sdkOptions = buildOptions(options);
    if (options?.timeout) {
      const controller = new AbortController();
      setTimeout(() => controller.abort(), options.timeout);
      sdkOptions.abortController = controller;
    }
    const stream = sdkQuery({ prompt, options: sdkOptions });
    return await consumeSDKStream(stream);
  } catch (error) {
    return errorResult(
      `Execution error: ${error instanceof Error ? error.message : "Unknown"}`,
    );
  }
}
```

</details>

<details><summary>consumeSDKStream() の実装</summary>

```typescript
async function consumeSDKStream(
  stream: AsyncGenerator<SDKMessage, void>,
): Promise<AgentResult> {
  for await (const msg of stream) {
    switch (msg.type) {
      case "system": // sessionId を取得
      case "assistant": // テキスト・ツール呼び出しを蓄積
      case "result": // コスト・成否を記録
    }
  }
  return { sessionId, message, toolCalls, success };
}
```

`AsyncGenerator`（非同期ジェネレータ）: データを一度に全部ではなく、少しずつ順番に生成・返却する仕組み。`for await...of` で 1 つずつ受け取りながら処理する。

</details>

<details><summary>観測フックの実装</summary>

```typescript
export function createDBObservationHooks(obsDB, dbSessionId): ArgusHooks {
  const taskIds = new Map<string, { dbId: string; startTime: number }>();
  return {
    onPreToolUse: async ({ toolUseId, toolName, toolInput }) => {
      const [inserted] = await obsDB.db
        .insert(obsDB.tasks)
        .values({
          sessionId: dbSessionId,
          toolName,
          toolInput,
          status: "running",
        })
        .returning();
      taskIds.set(toolUseId, { dbId: inserted.id, startTime: Date.now() });
    },
    onPostToolUse: async ({ toolUseId, toolResult }) => {
      const tracked = taskIds.get(toolUseId);
      if (!tracked) return;
      const durationMs = Date.now() - tracked.startTime;
      await obsDB.db
        .update(obsDB.tasks)
        .set({ toolResult, durationMs, status: "completed" })
        .where(obsDB.eq(obsDB.tasks.id, tracked.dbId));
      taskIds.delete(toolUseId);
    },
  };
}
```

</details>

### 理解度チェック

1. `query()` が throw ではなく `errorResult()` を返す理由を、「Slack Bot は 1 プロセスで全ユーザーに対応している」という点から説明できるか？
2. ストリーミング方式（少しずつ受け取る）の 3 つのメリットは？
3. DI（依存性注入）により、テスト時にどんな利点があるか？
4. `McpBaseServer` を使うと、新しい MCP サーバーの追加がなぜ楽になるか？
5. `fireAndForget()` を使わずに Promise を放置すると何が起こるか？

---

## 4. packages/db

### ひとことまとめ

> データベース（情報を永続的に保存する場所）の設計図と接続方法を定義するパッケージ。全 15 テーブルのスキーマ（テーブル構造の設計図）を管理する。

### 身近なたとえ

`packages/db` は「データの倉庫の設計図」。どんな棚（テーブル）があり、各棚にどんな箱（カラム）が並んでいるかを定義する。実際の倉庫（PostgreSQL サーバー）は別の場所にあるが、設計図があるおかげで全員が同じ構造を理解できる。

### 図で理解する

#### テーブルの全体像（15 テーブル、6 カテゴリ）

```
┌─────────────────────────────────────────────────────────┐
│                  📊 Argus のデータベース                 │
├─────────────────────────────────────────────────────────┤
│                                                         │
│  💬 セッション系          🤖 エージェント系             │
│  ┌──────────┐             ┌──────────┐                  │
│  │ sessions │─┐           │ agents   │─┐               │
│  └──────────┘ │           └──────────┘ │               │
│  ┌──────────┐ │           ┌─────────────────┐          │
│  │ messages │←┘           │agent_executions │←┘        │
│  └──────────┘             └─────────────────┘          │
│  ┌──────────┐                                          │
│  │  tasks   │                                          │
│  └──────────┘                                          │
│                                                         │
│  📚 ナレッジ系            📧 Gmail 系                  │
│  ┌────────────┐           ┌──────────────┐              │
│  │ knowledges │           │ gmail_tokens │              │
│  └────────────┘           └──────────────┘              │
│  ┌────────────────┐       ┌────────────────┐            │
│  │ personal_notes │       │ gmail_messages │            │
│  └────────────────┘       └────────────────┘            │
│  ┌──────────┐             ┌────────────────┐            │
│  │ lessons  │             │ gmail_outgoing │            │
│  └──────────┘             └────────────────┘            │
│                                                         │
│  📥 Inbox/予定系          📱 SNS 系                     │
│  ┌─────────────┐          ┌───────────┐                 │
│  │ inbox_tasks │          │ sns_posts │                 │
│  └─────────────┘          └───────────┘                 │
│  ┌───────┐                ┌───────────────┐             │
│  │ todos │                │ tiktok_tokens │             │
│  └───────┘                └───────────────┘             │
│  ┌─────────────┐                                        │
│  │ daily_plans │          🖼️ 共通                       │
│  └─────────────┘          ┌─────────────────┐           │
│                           │ canvas_registry │           │
│                           └─────────────────┘           │
└─────────────────────────────────────────────────────────┘
```

#### Proxy パターン — 「使うときだけ接続する」仕組み

```
❌ 普通の接続方式:
  import { db } from "@argus/db"
  → この瞬間にデータベース接続開始！
  → Next.js のビルド時（DB不要）でもエラーになる

✅ Proxy 方式（Argus の採用方式）:
  import { db } from "@argus/db"
  → まだ接続しない（空のハコだけ用意）

  db.select(...)  ← ここで初めてクエリを実行しようとする
  → この瞬間に接続開始！（遅延初期化）
  → Next.js ビルド時は db.select() を呼ばないのでエラーにならない
```

> **身近なたとえ**: 冷蔵庫の電気は、ドアを開けたときに初めてライトが点く。ドアを閉めたまま（使わないまま）なら電気は使わない。

### もう少し詳しく

#### ファイル構成

```
packages/db/src/
├── schema.ts         📐 全 15 テーブルの設計図 + 型エクスポート
├── client.ts         🔌 Proxy で遅延初期化される DB 接続
├── index.ts          🚪 schema + client の公開窓口
└── migrations/       📜 マイグレーション SQL（DB 構造の変更履歴）
    ├── 0000_...sql   🏗️ 初期: sessions, messages, tasks, knowledges, agents
    ├── 0001_...sql   📧 Gmail/Inbox/Lessons/SNS/DailyPlans 追加
    ├── 0002_...sql   🎵 TikTok トークン追加
    ├── 0003_...sql   📊 SNS フェーズ管理カラム追加
    ├── 0004_...sql   ✅ Todos テーブル追加
    └── 0005_...sql   🖼️ Canvas Registry, Gmail Outgoing, Personal Notes 追加
```

#### Proxy パターンの 3 つの利点

1. **遅延初期化**: 初回アクセス時のみ DB 接続。ビルド時にインポートしてもエラーにならない
2. **シングルトン保証**（一度だけ接続を作る）: モジュールスコープの `_db` に一度だけインスタンスを格納し、以降は同じ接続を再利用
3. **環境変数チェックの遅延**: `DATABASE_URL` の検証は実際に DB を使う瞬間まで遅延。テストやビルド時にダミーの環境変数が不要

#### `$inferSelect` と `$inferInsert` の違い

| 型             | 用途                        | `id` や `createdAt`           |
| -------------- | --------------------------- | ----------------------------- |
| `$inferSelect` | DB から取得したデータの型   | 全て**必須**                  |
| `$inferInsert` | DB に新規登録するデータの型 | **省略可能**（DB が自動補完） |

#### 3 つのエントリポイント（パッケージの読み込み方）

```typescript
import { db, sessions } from "@argus/db"; // 全部入り
import { sessions, messages } from "@argus/db/schema"; // テーブル定義だけ
import { db } from "@argus/db/client"; // DB 接続だけ
```

### 実際のコード（上級者向け）

<details><summary>Proxy による遅延初期化</summary>

```typescript
let _db: PostgresJsDatabase | undefined;

export const db: PostgresJsDatabase = new Proxy({} as PostgresJsDatabase, {
  get(_target, prop, receiver) {
    if (!_db) {
      const connectionString = process.env.DATABASE_URL;
      if (!connectionString) throw new Error("DATABASE_URL is not set");
      const client = postgres(connectionString, {
        max: 10,
        idle_timeout: 20,
        connect_timeout: 10,
      });
      _db = drizzle(client);
    }
    return Reflect.get(_db, prop, receiver);
  },
});
```

Proxy（オブジェクトへのアクセスを横取りして別の処理を挟める JavaScript の仕組み）の `get` トラップで、`db.何か` にアクセスした瞬間に初回のみ接続を行う。

</details>

<details><summary>スキーマ定義パターン</summary>

```typescript
export const sessions = pgTable("sessions", {
  id: uuid("id").primaryKey().defaultRandom(),
  sessionId: varchar("session_id", { length: 255 }).notNull(),
  createdAt: timestamp("created_at").defaultNow().notNull(),
  updatedAt: timestamp("updated_at").defaultNow().notNull(),
});

// FK（外部キー）の関数参照 — 宣言順に依存しない
export const messages = pgTable("messages", {
  sessionId: uuid("session_id")
    .references(() => sessions.id)
    .notNull(),
});

// 型の自動導出
export type Session = typeof sessions.$inferSelect;
export type NewSession = typeof sessions.$inferInsert;
```

</details>

### 理解度チェック

1. なぜ `db` が Proxy で実装されているのか、3 つの利点を挙げられるか？
2. `$inferSelect` と `$inferInsert` の違いは？
3. マイグレーション履歴から、機能追加の順序を説明できるか？

---

## 5. packages/knowledge & knowledge-personal

### ひとことまとめ

> AI が「知識」を保存・検索するための MCP（Model Context Protocol: AI がツール（道具）を使うための通信規約）サーバー。組織的ナレッジ（knowledge）と個人メモ（knowledge-personal）の 2 種類がある。

### 身近なたとえ

- **knowledge** = 会社の共有図書館。書き込み権限を持つ「司書」（Collector）と、閲覧のみの「利用者」（Executor）がいる
- **knowledge-personal** = 個人の手帳。誰でも自由に読み書きできる

### 図で理解する

#### 権限分離 — 2 重のセキュリティゲート

```
┌─────────────────────────────────────────────────────┐
│              knowledge パッケージ                    │
├─────────────────────────────────────────────────────┤
│                                                     │
│  Collector（司書）ロール    Executor（利用者）ロール │
│  ┌───────────────────┐     ┌───────────────────┐    │
│  │ knowledge_search  │     │ knowledge_search  │    │
│  │ knowledge_list    │     │ knowledge_list    │    │
│  │ search_lessons    │     │ search_lessons    │    │
│  │ knowledge_add     │     └───────────────────┘    │
│  │ knowledge_update  │      ↑ 書き込みツールが      │
│  │ knowledge_archive │        見えない              │
│  └───────────────────┘                              │
│                                                     │
│  【1 層目】ツール公開層:                            │
│    そもそも書き込みツールを見せない                  │
│                                                     │
│  【2 層目】ビジネスロジック層:                       │
│    万が一突破されても requireCollector() で最終阻止  │
│                                                     │
└─────────────────────────────────────────────────────┘
```

**なぜ 2 層で守るのか（多層防御: Defence-in-Depth）**:

```
❌ 1 層だけの場合:
  設定ミスでツールが見えてしまう → 即座にデータ書き換え可能！

✅ 2 層の場合:
  設定ミスでツールが見えてしまう →
  → でも requireCollector() が最終防衛線として機能
  → 書き込みは阻止される！
```

> **身近なたとえ**: マンションの入口（1 層目: オートロック）と部屋の鍵（2 層目: 個別の鍵）の 2 重セキュリティ。オートロックが壊れても、部屋の鍵があるから安全。

#### 2 パッケージの比較

| 観点        | knowledge（共有図書館）                            | knowledge-personal（個人手帳）                 |
| ----------- | -------------------------------------------------- | ---------------------------------------------- |
| ドメイン    | 組織的ナレッジ                                     | 個人メモ・パーソナリティ                       |
| 権限        | Collector（書き込み可） / Executor（読み取りのみ） | ロール制なし（全ツール利用可能）               |
| DB テーブル | `knowledges`                                       | `personalNotes`                                |
| 検索結果    | Knowledge 配列                                     | **行番号・前後コンテキスト付き**               |
| 更新        | content 全置換                                     | **append（追記） / replace（置換） 選択可能**  |
| 固有機能    | `search_lessons`                                   | `personal_context`（パーソナリティ構造化取得） |

### もう少し詳しく

#### McpBaseServer の継承パターン

セクション 3 で解説した `McpBaseServer` を継承して MCP サーバーを構築する。

```
McpBaseServer（テンプレート）
    │
    │ 継承
    ▼
KnowledgeMcpServer
    │
    ├── getTools()        → ロールに応じてツール一覧を返す
    ├── handleToolCall()  → switch 文で各ツールを振り分け
    └── formatResult()    → success/error パターンに変換
```

**`handleToolCall()` が外部から呼べる理由**: MCP プロトコル経由だとトランスポート層（通信の下回り）のセットアップが必要で、テストが複雑化する。`handleToolCall()` を直接呼べるようにすることで、通信部分をバイパスしてロジックだけをテストできる。orchestrator の `knowledge-api.ts` のように HTTP API から直接ナレッジ操作を呼ぶ場面でも活用される。

#### personal の特徴的設計: ファイル名 = セクション名

```typescript
type PersonalitySection =
  | "identity" // self/identity.md    → アイデンティティ
  | "values" // self/values.md      → 価値観
  | "strengths" // self/strengths.md   → 強み（弱みも含む）
  | "thinking" // self/thinking.md    → 思考スタイル
  | "preferences" // self/preferences.md → 好き嫌い
  | "routines"; // self/routines.md    → 日課
```

### 実際のコード（上級者向け）

<details><summary>KnowledgeMcpServer の実装</summary>

```typescript
export class KnowledgeMcpServer extends McpBaseServer {
  constructor(
    private service: KnowledgeService,
    private role: KnowledgeRole,
  ) {
    super("knowledge-server", "0.1.0");
    this.tools = this.initializeTools();
  }

  protected getTools(): McpToolDefinition[] {
    return this.tools; // ロールに応じてフィルタ済み
  }

  protected handleToolCall(
    name: string,
    args: Record<string, unknown>,
  ): Promise<unknown> {
    switch (name) {
      case "knowledge_search":
        return this.service.search(args.query);
      case "knowledge_add":
        return this.service.add(args);
      // ...
    }
  }

  protected formatResult(result: unknown): CallToolResult {
    // { success: true, data } → text content / { success: false, error } → isError: true
  }
}
```

</details>

### 理解度チェック

1. MCP サーバーが `McpBaseServer` を継承するメリットは？
2. 権限分離が「2 層」で行われている理由を説明できるか？
3. knowledge と knowledge-personal の違いを 3 つ挙げられるか？

---

## 6. packages/gmail & google-calendar

### ひとことまとめ

> Gmail と Google カレンダーに接続するためのパッケージ。OAuth2 認証（ユーザーの代わりに Google サービスにアクセスする許可を得る仕組み）を Gmail パッケージが一元管理し、カレンダーもその認証を再利用する。

### 身近なたとえ

Gmail パッケージは「社員証の発行所」。Google のサービスにアクセスするための「社員証」（OAuth2 トークン）を管理する。カレンダーパッケージは「社員証」を借りて Google カレンダーにアクセスする。

### 図で理解する

#### OAuth2 認証の共有設計

```
┌───────────────────────────────────────────┐
│  gmail パッケージ（社員証の発行所）        │
│                                           │
│  auth.ts                                  │
│  ├── createOAuth2Client()   社員証の発行  │
│  ├── getAuthUrl()           発行窓口      │
│  ├── handleCallback()       受け取り      │
│  ├── refreshTokenIfNeeded() 有効期限確認  │
│  └── getAuthenticatedClient() 使える状態  │
│                            で渡す         │
└────────────┬──────────────────────────────┘
             │
        「社員証を貸して」
             │
             ▼
┌───────────────────────────────────────────┐
│  google-calendar パッケージ               │
│                                           │
│  calendar-client.ts                       │
│  └── import { getAuthenticatedClient }    │
│         from "@argus/gmail"               │
│      ↑ Gmail の認証をそのまま再利用       │
└───────────────────────────────────────────┘
```

#### 5 分バッファ付きトークンリフレッシュ

```
トークンの有効期限: 14:00

❌ バッファなし:
  13:59:58 に API リクエスト送信
  → 通信に 3 秒かかる
  → 14:00:01 にサーバーに届く → 「期限切れです！」エラー

✅ 5 分バッファあり:
  13:55 に「もうすぐ切れるな」と検知
  → 新しいトークンを取得
  → 13:59:58 に API リクエスト送信
  → 新しいトークンなので問題なし！
```

### もう少し詳しく

#### UTF-8 文字化けの修正

日本語メールは文字コードの問題で「文字化け」することがある。メールが中継サーバーを経由するたびに、誤った文字コード変換が行われることがあり、最悪 3 重にエンコードされてしまう。

```
元の日本語: 「こんにちは」
  → 1 回誤変換 → æ—¥æ— ¬èª...
  → 2 回誤変換 → Ã¦â€"Â¥Ã¦...
  → 3 回誤変換 → Ãƒâ€ ...

修正処理（最大 3 回ループ）:
  1 回目のデコードで 1 層剥がす
  2 回目のデコードでもう 1 層剥がす
  3 回目のデコードで元に戻る → 「こんにちは」
  ※ 変化がなくなった時点で停止
```

#### Google Calendar の MCP ツール

AI が正しい形式で日時を入力できるよう、ツールの説明文に ISO8601 形式の例を含める工夫をしている。

### 実際のコード（上級者向け）

<details><summary>UTF-8 文字化け修正</summary>

```typescript
function decodeHeader(raw: string): string {
  let decoded = raw;
  for (let i = 0; i < 3; i++) {
    const bytes = stringToCP1252Bytes(decoded);
    try {
      const utf8 = new TextDecoder("utf-8", { fatal: true }).decode(bytes);
      if (utf8 === decoded) break; // 変化なし → 収束
      decoded = utf8;
    } catch {
      break;
    } // UTF-8 として不正 → これ以上デコード不要
  }
  return decoded;
}
```

CP1252（Windows で広く使われていた西欧文字の文字コード）→ UTF-8 の多重エンコーディング問題を最大 3 回の反復デコードで修正。

</details>

### 理解度チェック

1. なぜ Gmail パッケージの認証スコープに Calendar も含まれている？
2. 「5 分バッファ」の目的は？
3. 文字化け修正で「最大 3 回ループ」する理由は？

---

## 7. packages/r2-storage, slack-canvas, tiktok

### ひとことまとめ

> 外部サービスと連携するための 3 つのパッケージ。ファイル保存（R2）、Slack の掲示板（Canvas）、TikTok への動画投稿をそれぞれ担当する。いずれも MCP サーバーではなく、ライブラリとして直接利用される。

### 身近なたとえ

- **r2-storage** = レンタル倉庫（ファイルを預けて URL で取り出せる）
- **slack-canvas** = 会社の掲示板（情報を貼り出す・更新する）
- **tiktok** = 動画投稿代行サービス（URL を教えれば取りに来てくれる）

### 図で理解する

#### TikTok の PKCE 認証（Gmail との違い）

```
Gmail の OAuth2:
  サーバーが「秘密の合言葉」(client_secret) を持っている
  → サーバーだけが知っている合言葉で本人確認

TikTok の PKCE:
  ┌─ クライアント ─┐     ┌─ TikTok サーバー ─┐
  │                │     │                   │
  │ ランダムな     │     │                   │
  │ 「合言葉」を   │     │                   │
  │ 生成           │     │                   │
  │     ↓          │     │                   │
  │ そのハッシュ値  ──→ 保存                  │
  │ を送る         │     │                   │
  │     ...        │     │                   │
  │ 後で元の       │     │                   │
  │ 「合言葉」を   ──→  ハッシュ値を計算して │
  │ 送る           │     │ 最初のと一致？     │
  │                │     │ → OK！ 本人確認完了│
  └────────────────┘     └───────────────────┘
```

> **身近なたとえ**: 「封筒に答えを入れて先に渡しておき、後で答え合わせをする」方式。秘密の合言葉をコードに埋め込まなくて済む。

#### TikTok の動画アップロード（PULL_FROM_URL 方式）

```
❌ 以前の方式（FILE_UPLOAD）:
  動画ファイルを小分けにして何度も送る
  → コードが複雑、メモリも大量に必要

✅ 現在の方式（PULL_FROM_URL）:
  [1] 動画を R2（クラウド倉庫）に置く
       ↓
  [2] TikTok に「ここに動画があるよ」と URL を教える
       ↓
  [3] TikTok が自分で取りに来る
       ↓
  [4] 5 秒おきに「もう終わった？」と確認（最大 180 秒）
       ↓
  [5] 完了！（ユーザーの TikTok 受信トレイに届く）
```

> **身近なたとえ**: 以前は「荷物を小分けにして何度も配達」だったのが、「倉庫の場所を教えて取りに来てもらう」方式に変更。圧倒的に簡単。

### もう少し詳しく

#### r2-storage

- 依存は `@aws-sdk/client-s3` のみ（Cloudflare R2 は Amazon S3 互換の API を使えるため）
- `uploadVideo()` という名前だが、実装はファイル種別を問わない汎用アップローダー（歴史的経緯で名前だけが残っている）

#### slack-canvas

- **Slack SDK を使わない軽量設計**: Canvas API は 2 つのエンドポイント（create / edit）しか使わないため、`fetch()` で直接呼ぶ
- `upsertCanvas()`（upsert = update + insert の造語。あれば更新、なければ新規作成）
- `canvas-registry.ts`: 機能名 → Canvas ID の対応を DB で管理

#### tiktok

- **TikTok 固有仕様**: SHA256 のハッシュエンコードが `hex`（通常は Base64）
- **Inbox モード**: 直接投稿は TikTok の審査が必要だが、受信トレイ投稿は審査不要
- **SNS 投稿ワークフロー**: 10 プラットフォーム対応の一部。`sns_posts` テーブルで投稿履歴を一元管理

### 理解度チェック

1. slack-canvas が Slack SDK を使わない理由は？
2. TikTok の PKCE 認証が Gmail の OAuth2 と異なる点は？
3. PULL_FROM_URL 方式が FILE_UPLOAD 方式より優れている点を 2 つ挙げられるか？
4. `publishVideoByUrl()` の処理フローを順番に説明できるか？

---

## 8. apps/slack-bot

### ひとことまとめ

> ユーザーと AI の「対話窓口」。Slack でメッセージを受け取り、AI に処理させ、結果を Slack に返す。Inbox パイプラインや 10 プラットフォーム対応の SNS 投稿管理を含む、Argus 最大のアプリケーション。

### 身近なたとえ

slack-bot は「総合受付と各専門窓口が並んだカウンター」。SNS 関連のメッセージは SNS 窓口へ、受信箱関連は Inbox 窓口へ、それ以外は総合窓口へと自動で振り分けられる。

### 図で理解する

#### ハンドラ登録順序 — 「専門窓口」を先に設置

```
メッセージが到着
   │
   ▼
┌──────────────┐
│ SNS 窓口     │──→ SNS チャンネルのメッセージ？ → YES → SNS 処理
└──────┬───────┘
       │ NO
       ▼
┌──────────────┐
│ Inbox 窓口   │──→ Inbox チャンネルのメッセージ？ → YES → Inbox 処理
└──────┬───────┘
       │ NO
       ▼
┌──────────────┐
│ DailyPlan 窓口│──→ DailyPlan チャンネル？ → YES → DailyPlan 処理
└──────┬───────┘
       │ NO
       ▼
┌──────────────┐
│ 総合窓口     │──→ どこにも該当しない → 汎用メッセージ処理
└──────────────┘
```

> **身近なたとえ**: 「専門の窓口」を先に設置し、どこにも該当しないメッセージだけが「総合窓口」に行く。

#### Inbox パイプライン — メッセージ処理の 4 段階

```
あなた: 「明日の会議の準備をして」
         │
         ▼
    ┌──────────────────┐
    │ ① 分類            │  AI(Haiku) or キーワードで仕分け
    │   classifier.ts   │  「これは予定関連の依頼だな」
    │                   │  → intent: research / code_change / todo / ...
    │                   │  → autonomyLevel: 2（全自動実行）
    │                   │  → summary: 体言止め 15 文字以内
    └────────┬─────────┘
             │
             ▼
    ┌──────────────────┐
    │ ② 順番待ち        │  タスクキュー（同時実行制限 3）
    │   index.ts        │  「3 件まで同時処理。空きがあるから即開始」
    │                   │  アトミックなステータス更新で二重実行防止
    └────────┬─────────┘
             │
             ▼
    ┌──────────────────┐
    │ ③ 実行            │  Agent SDK で AI を動かす
    │   executor.ts     │  intent 別タイムアウト設定
    │                   │  (research: 30 分, question: 5 分)
    └────────┬─────────┘
             │
             ▼
    ┌──────────────────┐
    │ ④ 報告            │  Block Kit でリッチなレポートを投稿
    │   reporter.ts     │  「明日 10 時の会議の資料をまとめました」
    └──────────────────┘
```

#### アトミックなタスク取得 — 二重実行を防ぐ仕組み

```
❌ 2 ステップ方式（危険）:
  ワーカー A: タスクを取り出す
  ワーカー B: 同じタスクを取り出す ← 二重実行！
  ワーカー A: ステータスを running に変更
  ワーカー B: ステータスを running に変更

✅ 1 ステップ方式（楽観的ロック）:
  「ステータスが queued のものだけを running に変える」を 1 つの SQL で実行
  → ワーカー A: 成功！（ステータスが queued → running）
  → ワーカー B: 失敗（もう running になっているので条件不一致）→ スキップ
```

> **身近なたとえ**: コンビニのレジで「商品を手に取る」と「お会計する」を同時にやるイメージ。手に取った瞬間に「売約済み」の札が付くので、他のお客さんが同じ商品を取ることはできない。

#### SNS 投稿管理 — 10 プラットフォーム対応

```
毎朝 4:00 JST に自動起動
         │
         ▼
┌─────────────────────────────────────────────────┐
│  PhasedGenerator（段階的パイプライン実行エンジン）│
│                                                 │
│  短文コンテンツ（X, Threads）: 2 フェーズ       │
│  ┌────────┐  ┌────────┐                         │
│  │ 構成   │→│ 執筆   │                         │
│  └────────┘  └────────┘                         │
│                                                 │
│  長文コンテンツ（Qiita, Zenn, note 等）: 4 フェーズ │
│  ┌────────┐  ┌────────┐  ┌────────┐  ┌────────┐│
│  │ 調査   │→│ 構成   │→│ 執筆   │→│ 校正   ││
│  │research│  │structure│  │content │  │optimize││
│  └────────┘  └────────┘  └────────┘  └────────┘│
│       ↓          ↓          ↓          ↓       │
│     JSON → 次フェーズの入力として渡す           │
└─────────────────────────────────────────────────┘
         │
         ▼ 投稿案を Slack に送信
         │
    ユーザーが承認/編集/スキップ/スケジュール
         │
         ▼
    最適投稿時間に自動公開
    (X: 7:30, 12:15, 18:00  YouTube: 平日 18:00 等)
```

> **身近なたとえ**: 料理で「買い物→下ごしらえ→調理→盛り付け」を分けるのと同じ。一度に全部やろうとすると混乱するが、工程を分ければ各工程に集中でき、失敗しても「下ごしらえからやり直し」で済む。

**なぜフェーズ分割するのか（一括 vs 段階的の比較）**:

| 観点     | 一括生成                     | 段階的（Argus 方式）                    |
| -------- | ---------------------------- | --------------------------------------- |
| 品質     | 各工程が雑になりがち         | 各フェーズで AI が 100% 集中            |
| 失敗時   | 全部やり直し                 | 失敗フェーズからリトライ                |
| デバッグ | どこで問題が起きたか不明     | JSON で各フェーズの入出力が記録される   |
| 共通化   | プラットフォーム毎に個別実装 | 長文 4 フェーズ / 短文 2 フェーズを共有 |

#### 対応プラットフォーム一覧

| プラットフォーム | タイプ   | 投稿頻度        | フェーズ数 | 特記事項                    |
| ---------------- | -------- | --------------- | ---------- | --------------------------- |
| X                | 短文     | 1 日 3 投稿     | 2          | カテゴリローテーション      |
| Threads          | 短文     | 1 日 2 投稿     | 2          | X と似た構造                |
| Instagram        | 短文     | 1 日 1 投稿     | 2          | TikTok 動画完成時に自動生成 |
| Qiita            | 長文記事 | 1 日 1 投稿     | 4          | 技術記事                    |
| Zenn             | 長文記事 | 1 日 1 投稿     | 4          | GitHub PR 方式で投稿        |
| note             | 長文記事 | 1 日 1 投稿     | 4          | カジュアルな長文            |
| YouTube          | 動画     | 1 日 1 投稿     | 4          | メタデータ + スクリプト生成 |
| TikTok           | 動画     | 1 日 1 投稿     | 4          | PULL_FROM_URL 方式          |
| GitHub           | コード   | 平日のみ 1 投稿 | 4          | リポジトリ公開              |
| Podcast          | 音声     | 毎日 1 投稿     | 4          | エピソード生成 + 配信       |

### もう少し詳しく

#### ファイル構成

```
apps/slack-bot/src/
├── index.ts               🚀 起動処理（ハンドラ登録順序が重要）
├── app.ts                 🔌 Socket Mode 接続（ping タイムアウト対策済み）
├── session-manager.ts     🧵 1 Thread = 1 Session の管理
│
├── handlers/
│   ├── message.ts         💬 汎用メッセージ（モデル切替・画像処理・Agent 実行）
│   ├── deep-research.ts   🔍 ディープリサーチ（WebSearch 100 回想定）
│   ├── daily-plan.ts      📋 デイリープラン編集
│   ├── daily-plan-actions.ts  ✅ チェックボックスアクション
│   ├── gmail-actions.ts   📧 Gmail 返信/送信の Block Kit アクション
│   │
│   ├── inbox/             📥 受信処理パイプライン
│   │   ├── index.ts       🎫 タスクキュー（同時実行制限 3）
│   │   ├── classifier.ts  🏷️ AI 分類 + キーワードフォールバック
│   │   ├── executor.ts    ⚡ Agent SDK 実行 + フェーズ追跡
│   │   ├── reporter.ts    📊 Block Kit レポート生成
│   │   └── todo-handler.ts ✅ ToDo CRUD
│   │
│   └── sns/               📱 SNS 投稿管理（10 プラットフォーム対応）
│       ├── index.ts       🔎 正規表現トリガー検出
│       ├── actions.ts     👆 承認/編集/スキップ/スケジュール
│       ├── generation/    🎨 コンテンツ生成（PhasedGenerator 基盤）
│       ├── platforms/     🌐 プラットフォーム別公開処理（10 種）
│       ├── scheduling/    🕐 cron + 最適投稿時間
│       └── ui/            🖼️ Block Kit ビルダー + バリデーション
│
├── canvas/                🖼️ Slack Canvas 連携
├── prompts/               📝 システムプロンプト定義
└── utils/                 🔧 ユーティリティ
    ├── mrkdwn.ts          📄 Markdown → Slack mrkdwn 変換
    ├── progress-reporter.ts 📊 進捗表示（1 メッセージを更新し続ける方式）
    └── reactions.ts       👍 リアクション操作の冪等ラッパー
```

#### CustomSocketModeReceiver — 接続安定化

Socket Mode（Bot 側から Slack に WebSocket 接続を張り、メッセージをリアルタイムに受信する方式）のデフォルト設定では、ping タイムアウトが 5 秒。クラウド環境ではネットワーク遅延が大きく、5 秒以内に応答が返らず接続が頻繁に切断される。20 秒に拡大して安定化。

> **身近なたとえ**: 電話で相手が「もしもし」と言った後 5 秒以内に返事しないと切れてしまう設定を、20 秒に変更。

#### 動的 MCP サーバー追加

Playwright（ブラウザ操作ツール）は約 7,000 トークンのコストがかかるため、キーワード検出時（「ブラウザ」「スクショ」等）のみ追加する。

#### SNS スケジューラの詳細

- **毎朝 4:00 JST**: 全プラットフォームの投稿案を AI で生成
- **毎分ポーリング**: `scheduled` ステータスの投稿を確認し、投稿時刻が来たら自動公開
- **キャッチアップ機能**: Mac のスリープで 4:00 AM を逃した場合、起動 30 秒後に未生成分を検知して即座に生成開始
- **リトライ機構**: JSON パースに失敗した場合は指数バックオフ（1 秒→2 秒→4 秒）で自動リトライ
- **CliUnavailableError**: Claude CLI のログイン切れを検出し、10 プラットフォーム分の無駄な実行を防止

#### ユーティリティの設計

- **`progress-reporter.ts`**: スレッドに大量のメッセージを投稿する代わりに、`chat.update` で 1 つのメッセージを更新し続ける。2 秒間隔のスロットル（一定間隔より高頻度の実行を抑制する仕組み）で Slack rate limit（API 呼び出し回数の上限）対策
- **`reactions.ts`**: 冪等（べきとう: 同じ操作を何度実行しても結果が変わらない性質）ラッパー。`already_reacted` / `no_reaction` エラーを静かに処理
- **`mrkdwn.ts`**: コードブロック退避/復元パターン。NUL 文字をセンチネル（番兵値: データの区切り目印として使う特殊な値）として使用

### 理解度チェック

1. ハンドラの登録順序が重要な理由は？
2. Inbox のタスクキューで「アトミックなステータス更新」が必要な理由は？
3. PhasedGenerator が複数フェーズに分割する理由を 3 つ挙げられるか？
4. SNS スケジューラの「キャッチアップ機能」とは？
5. Argus が対応している 10 の SNS プラットフォームを全て挙げられるか？

---

## 9. apps/agent-orchestrator

### ひとことまとめ

> バックグラウンドで定期的に動く「管理人」。コードの健康診断、メール監視、デイリープラン生成など、人間が手動でやると面倒な作業を自動化する。

### 身近なたとえ

orchestrator は「ビルの管理人室」。夜間の警備巡回（Code Patrol）、郵便物のチェック（Gmail チェッカー）、朝の予定表作成（Daily Planner）など、定期的な仕事を黙々とこなす。

### 図で理解する

#### スケジューラ一覧

```
┌─────────────────────────────────────────────┐
│  orchestrator のスケジューラ（管理人の業務表）│
├─────────────────────────────────────────────┤
│                                             │
│  毎朝 3:50   📋 Daily Planner              │
│              （今日の予定表を作成）          │
│                                             │
│  毎朝 5:00   📰 Daily News Canvas          │
│              （ニュースまとめ）              │
│                                             │
│  5 分毎      📧 Gmail チェッカー            │
│              （未読メールの確認 + AI 分類）  │
│                                             │
│  毎分        🔄 DB 上のエージェント         │
│              （agents.schedule に基づき実行） │
│                                             │
│  土曜 3:00   🔍 Code Patrol                 │
│              （コード品質の自動巡回）        │
│                                             │
│  土曜 3:50   🔧 Consistency Check           │
│              （モノレポ整合性チェック）       │
└─────────────────────────────────────────────┘
```

#### Code Patrol パイプライン（12 ステップ）

```
[1] Before-scan ─── 3 種並列スキャン
     │  ├── pnpm audit（脆弱性チェック）
     │  ├── シークレット検出（パスワード漏れ）
     │  └── tsc（型エラーチェック）
     ▼
[2] 問題なし? ──── YES → 即レポート投稿して終了 🎉
     │ NO
     ▼
[3] git stash ─── 安全ネット（現在の作業を退避）
     ▼
[4] Slack 通知 ─── 「修正中...」
     ▼
[5] Claude 修正 ─── AI に修正を依頼
     ▼
[6] After-scan ─── 修正後の再スキャン
     ▼
[7] git diff ──── 変更量取得
     ▼
[8] pnpm build && pnpm test ── 検証
     ▼
[9] 検証失敗? ── YES → git checkout . でロールバック（元に戻す）
     ▼
[10] git stash pop ── 作業復元
     ▼
[11] AI 品質分析 ── Sonnet で別途分析
     ▼
[12] Slack レポート + Knowledge 保存
```

> **身近なたとえ**: 毎週土曜の深夜に「夜間警備員」が自動でコードの健康診断を行う。問題を見つけたら AI に修正を依頼し、修正が正しいか検証してから適用する。失敗したら元に戻すので安全。

### もう少し詳しく

#### ファイル構成

```
apps/agent-orchestrator/src/
├── index.ts               🚀 Express サーバー(:3950) + スケジューラ
├── agent-executor.ts      🔄 リトライ付きエージェント実行エンジン
├── scheduler.ts           🕐 node-cron ベースのスケジューラ
├── knowledge-api.ts       📚 Knowledge REST API (CRUD)
├── gmail-checker.ts       📧 Gmail 未読チェック + AI 分類 + Slack 通知
├── slack-notifier.ts      📢 Slack 通知（fetch() 直接）
│
├── canvas/                🖼️ Slack Canvas 連携
│   ├── execution-canvas.ts    エージェント実行ログ（10 秒スロットル）
│   ├── gmail-canvas.ts        未対応メール一覧
│   └── daily-news-canvas.ts   デイリーニュース
│
├── code-patrol/           🔍 週次コード品質巡回
│   ├── scanners.ts        スキャナ（pnpm audit / シークレット / tsc 並列）
│   ├── patrol-runner.ts   12 ステップのパイプライン
│   ├── remediation.ts     修正 + 検証 + ロールバック
│   └── report-builder.ts  Block Kit レポート生成
│
├── consistency-checker/   🔧 週次モノレポ整合性チェック
│   ├── checkers.ts        10 種類のチェック関数（並列実行）
│   └── reporter.ts        Block Kit レポート生成
│
├── daily-planner/         📋 デイリープラン生成
│   ├── collectors.ts      4 ソース並列収集（Calendar, Gmail, Tasks, Todos）
│   └── builders.ts        Block Kit + Canvas Markdown 生成
│
└── demo/                  🎓 Collector/Executor パターンのデモ
```

#### 環境変数ガードパターン

```
┌──────────────────────────────────────────────┐
│  同じコードを全環境にデプロイ                │
│                                              │
│  本番:                                       │
│    DAILY_PLAN_CHANNEL=C12345  → 有効         │
│    CODE_PATROL_CHANNEL=C67890 → 有効         │
│    GMAIL_ADDRESS=test@...     → 有効         │
│                                              │
│  CI:                                         │
│    （環境変数なし）                          │
│    → 全スキップ（ログに記録してスキップ）    │
│                                              │
│  開発:                                       │
│    DAILY_PLAN_CHANNEL=C12345  → 有効         │
│    （他はなし）→ スキップ                    │
└──────────────────────────────────────────────┘
```

throw でエラーにするのではなくログを出してスキップすることで、他のスケジュールジョブに影響を与えない。

#### Consistency Checker が Claude を使わない理由

チェック内容（tsconfig 参照の整合性、依存バージョンの一致等）は正解が一意に決まるものばかり。AI の判断は不要で、決定的（deterministic: 同じ入力に対して常に同じ結果を返す性質）に実行できる。これにより毎回同じ結果が保証され、偽陽性が発生しない。

#### Promise.all の多用

データ収集やスキャンでは一貫して `Promise.all` で並列化して高速化:

```
❌ 順番に実行（遅い）:
  カレンダー取得（2 秒）→ メール取得（3 秒）→ タスク取得（1 秒）= 合計 6 秒

✅ 並列実行（速い）:
  カレンダー取得（2 秒）┐
  メール取得  （3 秒）  ├→ 合計 3 秒（最も遅いものに合わせる）
  タスク取得  （1 秒）  ┘
```

### 理解度チェック

1. Code Patrol が検証失敗時にロールバックする手順を説明できるか？
2. 環境変数ガードパターンの目的は？
3. Consistency Checker が Claude を使わない理由は？

---

## 10. apps/dashboard

### ひとことまとめ

> AI エージェントの活動状況を Web ブラウザで確認するための管理画面。Next.js 16 で構築され、セッション履歴・ナレッジ管理・生成ファイルの閲覧ができる。

### 身近なたとえ

dashboard は「管制室のモニター」。AI エージェントが今何をしているか、過去に何をしたか、どんな知識を蓄積しているかを一目で確認できる。

### 図で理解する

#### Server Component と Client Component の使い分け

```
┌───────────────────────────────────────────────┐
│  Server Component（サーバー側で実行）          │
│  = キッチン（お客さんには見えない裏方）        │
│                                               │
│  できること:                                  │
│  ✅ DB に直接アクセス（SELECT * FROM ...)      │
│  ✅ 秘密の情報を扱う（API キー等）            │
│                                               │
│  できないこと:                                │
│  ❌ ボタンクリックの処理                       │
│  ❌ useState 等の React Hooks                  │
│                                               │
│  例: ページコンポーネント、SessionList         │
├───────────────────────────────────────────────┤
│  Client Component（ブラウザ側で実行）          │
│  = テーブル（お客さんが操作する場所）          │
│                                               │
│  できること:                                  │
│  ✅ ボタンクリック、フォーム送信               │
│  ✅ useState, usePathname 等の React Hooks     │
│                                               │
│  できないこと:                                │
│  ❌ DB に直接アクセス                          │
│                                               │
│  例: Navigation, QueryForm, MessageViewer     │
└───────────────────────────────────────────────┘
```

> **身近なたとえ**: Server Component は「キッチン」で料理を作る部分（お客さんは見えない）。Client Component は「テーブル」でお客さんが操作する部分。データの準備はキッチンで済ませて、お客さんが触る部分だけをテーブルに出す。

**パターン**: ページ（Server）でデータをフェッチし、表示コンポーネントに props で渡す。インタラクティブ部分だけ `"use client"` にする。

#### Range Request — 動画のシーク再生を可能にする仕組み

```
❌ Range Request なし:
  「2 分 30 秒から再生したい」
  → 動画全体（500MB）をダウンロードし直し
  → 再生開始まで数十秒待つ...

✅ Range Request あり:
  「2 分 30 秒から再生したい」
  → 「bytes=15728640-17825791」だけリクエスト（2MB）
  → 即座に再生開始！
```

### もう少し詳しく

#### ファイル構成

```
apps/dashboard/src/
├── app/
│   ├── layout.tsx           🏠 ルートレイアウト (Server) — サイドバー + メイン
│   ├── globals.css          🎨 Tailwind CSS 4 + CSS 変数
│   ├── page.tsx             🏠 トップページ (Server)
│   ├── sessions/
│   │   ├── page.tsx         📋 セッション一覧 (Server)
│   │   └── [id]/page.tsx    📄 セッション詳細 (Server) — Promise.all で並列フェッチ
│   ├── agents/page.tsx      🤖 エージェント実行履歴 (Server)
│   ├── knowledge/page.tsx   📚 ナレッジ一覧 (Server)
│   ├── files/page.tsx       📁 生成ファイル (Server)
│   └── api/
│       ├── query/route.ts       🔍 POST — Claude Agent 問い合わせ
│       ├── files/route.ts       📂 GET — ファイル一覧 JSON
│       ├── files/[...path]/route.ts  🎬 GET — メディア配信（Range 対応）
│       └── sessions/[id]/feedback/route.ts  💬 POST — セッション継続
│
└── components/
    ├── Navigation.tsx         🧭 Client — アクティブページ判定
    ├── SessionList.tsx        📋 Server — 純粋表示
    ├── MessageViewer.tsx      💬 Client — Markdown レンダリング
    ├── ToolCallList.tsx       🔧 Client — アコーディオン表示
    ├── QueryForm.tsx          📝 Client — 質問入力フォーム
    ├── FeedbackForm.tsx       💬 Client — セッション継続フォーム
    ├── KnowledgeList.tsx      📚 Server — グリッドカード表示
    ├── AgentExecutionList.tsx 🤖 Client — コスト抽出ヘルパー
    └── FileList.tsx           📁 Client — 画像/動画プレビュー
```

#### `force-dynamic` による SSR 強制

Next.js App Router ではページがデフォルトで静的生成（SSG: ビルド時にページの HTML を事前に作っておく方式）される。DB クエリを含むページはリクエストごとに最新データを取得する必要があるため、`export const dynamic = "force-dynamic"` でサーバーサイドレンダリング（SSR）を強制する。

#### Next.js 16 の params Promise

Next.js 16 では `params` が Promise になった（15 以前は同期オブジェクト）。`await params` が必要。

#### HTML ネイティブ要素の活用

`<details>` / `<summary>` タグで、React の state 管理やライブラリなしでアコーディオン UI を実現。

### 理解度チェック

1. `export const dynamic = "force-dynamic"` が必要な理由は？
2. `Navigation.tsx` が Client Component でなければならない理由は？
3. Range Request 対応が必要なユースケースは？

---

## 11. ルート設定ファイル群

### ひとことまとめ

> プロジェクト全体の「骨格」を定める設定ファイル群。パッケージ管理、TypeScript 設定、Docker ビルド、プロセス管理の設定が含まれる。

### 身近なたとえ

ルート設定ファイルは「会社の社則集」。社員名簿（pnpm-workspace.yaml）、業務マニュアル（tsconfig.json）、ビルの設計図（Dockerfile）、勤務シフト表（ecosystem.config.cjs）がまとめられている。

### 図で理解する

#### 主要設定ファイルの関係

```
argus/
├── package.json          📋 プロジェクトの「名刺」
│   └── scripts:          「pnpm test で全テスト」等のコマンド集
│
├── pnpm-workspace.yaml   🗂️ 「社員名簿」
│   └── "packages/* と apps/* がウチの社員だよ"
│
├── tsconfig.json          ⚙️ 「業務マニュアル」
│   └── strict モード、ESM、Project References
│
├── Dockerfile             🐳 「本番ビルの設計図」
│   └── Stage 1: ビルド → Stage 2: 本番（軽量化）
│
├── ecosystem.config.cjs   🏭 「勤務シフト表」
│   └── 3 プロセス（slack-bot, dashboard, orchestrator）
│
├── .npmrc                 📦 node-linker=hoisted（互換性確保）
├── eslint.config.js       📏 コードスタイルルール
├── .prettierrc            🎨 フォーマットルール
├── .jscpd.json            🔍 コピペ検出（5% 閾値）
└── .gitattributes         📦 大きなファイルの管理（Git LFS）
```

#### Docker マルチステージビルド

```
Stage 1: ビルド環境（大きい）
┌──────────────────────────────────┐
│  Node.js 22 + pnpm              │
│  ソースコード全部                │
│  node_modules（開発用含む）      │
│  → pnpm build でコンパイル       │
│                                  │
│  ※ DATABASE_URL=dummy でOK      │
│    （Proxy で遅延初期化だから）  │
└────────────┬─────────────────────┘
             │ ビルド結果だけをコピー
             ▼
Stage 2: 本番環境（軽量）
┌──────────────────────────────────┐
│  Node.js 22 + PM2               │
│  ビルド済みファイルのみ          │
│  → 不要なファイルを持たない      │
│  → イメージサイズが小さい        │
└──────────────────────────────────┘
```

> **身近なたとえ**: 料理を作るときは大きなキッチン（Stage 1）が必要だが、お客さんに出すときは完成品のお皿（Stage 2）だけあればいい。

#### PM2 設定（3 プロセス）

```
┌──────────────────────────────────────┐
│  PM2（プロセス管理ツール）           │
│                                      │
│  プロセス 1: slack-bot    :3939      │
│  プロセス 2: dashboard    :3150      │
│  プロセス 3: orchestrator :3950      │
│                                      │
│  → どれか 1 つが落ちても自動再起動   │
│  → 他のプロセスに影響しない          │
└──────────────────────────────────────┘
```

### もう少し詳しく

#### TypeScript Project References の目的

Project References（プロジェクト参照）は TypeScript コンパイラにパッケージ間のビルド依存関係を認識させる機能。

```
❌ Project References なし:
  1 ファイル修正 → 12 パッケージ全部を再ビルド → 遅い！

✅ Project References あり:
  1 ファイル修正 → そのパッケージだけ再ビルド → 速い！
  しかも agent-core → slack-bot の順に自動でビルド
```

3 つの恩恵:

1. **インクリメンタルビルド**（変更があった部分だけを再ビルド）: 12 パッケージのうち修正した 1 つだけ再ビルド
2. **ビルド順序の自動解決**: `agent-core` → `slack-bot` の順に自動ビルド
3. **独立した型チェック**: 無関係なパッケージのエラーに影響されない

> **身近なたとえ**: 12 冊の本を翻訳する場合、全冊を最初からやり直す代わりに、修正があった章だけを翻訳し直す仕組み。

#### `node-linker=hoisted` の理由

pnpm のデフォルトはシンボリックリンクベースの厳密な構造だが、一部のツール（Claude Agent SDK、Next.js のプラグイン等）が正常に動作しない場合がある。`hoisted` で npm と同様のフラットな構造にして互換性を確保。

#### CI/CD（GitHub Actions）

```
シンプルな構成:
  checkout → pnpm → build → test

※ DATABASE_URL=dummy でビルドできるのは Proxy パターンのおかげ
```

### 理解度チェック

1. `node-linker=hoisted` を使う理由は？
2. Dockerfile のビルド時にダミーの DATABASE_URL で問題ない理由は？
3. TypeScript の Project References の 3 つの恩恵は？

---

## 12. .claude/ ディレクトリ

### ひとことまとめ

> AI エージェント（Claude Code）の設定・権限・スキルを管理するディレクトリ。「何をやっていいか」「何をやってはダメか」を明確に定義する。

### 身近なたとえ

`.claude/` は「AI 助手のマニュアル棚」。助手の役割定義書（agents/）、社内ルール（rules/）、専門技能書（skills/）、セキュリティポリシー（settings.json）が整理されている。

### 図で理解する

#### エージェント定義（4 種類の AI 助手）

```
┌─────────────────────────────────────────────────┐
│  .claude/agents/ — 4 種類の AI 助手              │
├─────────────────────────────────────────────────┤
│                                                 │
│  📝 collector.md                                │
│     役割: 情報収集・知識蓄積                    │
│     権限: Knowledge の読み書きOK                │
│     たとえ: 「司書」（本を整理・追加できる）    │
│                                                 │
│  ⚡ executor.md                                  │
│     役割: ユーザーの依頼を実行                  │
│     権限: Knowledge の読み取りのみ              │
│     たとえ: 「利用者」（本を読めるが書き込めない）│
│                                                 │
│  📊 analyzer.md                                  │
│     役割: 週次ログ分析・パターン検出            │
│     たとえ: 「分析官」（データから傾向を見つける）│
│                                                 │
│  🔍 code-reviewer.md                             │
│     役割: コードレビュー                        │
│     優先順位: 正確性 > セキュリティ > パフォーマンス│
│     たとえ: 「品質管理担当」                    │
└─────────────────────────────────────────────────┘
```

#### deny-first の権限設計

```
┌───────────────────────────────────┐
│  権限の考え方                     │
│                                   │
│  まず全部禁止 🚫                 │
│  ↓                               │
│  安全なものだけ許可 ✅           │
│                                   │
│  ❌ 明示的に禁止:                │
│     .env の読み書き              │
│     rm -rf *（全削除）           │
│     git push --force             │
│     DROP TABLE / DELETE FROM      │
│                                   │
│  ✅ 明示的に許可:                │
│     packages/** の読み取り       │
│     apps/** の読み取り           │
│     .claude/agent-output/** の書き込み │
│     ffmpeg の実行                │
│                                   │
│  → 新しい操作はデフォルトで禁止  │
│  → 許可漏れによるリスクを防ぐ    │
└───────────────────────────────────┘
```

> **身近なたとえ**: 「まず全部禁止し、安全なものだけ許可する」方針。ホワイトリスト方式とも呼ばれる。新しい操作が追加されても、明示的に許可しない限り使えないので安全。

### もう少し詳しく

#### Collector / Executor の分離理由

AI エージェントは自律的に動作するため、意図しないデータ書き換えのリスクがある。

```
❌ 全エージェントに書き込み権限:
  Executor が悪意ある指示（プロンプトインジェクション）を受ける
  → 「ナレッジを全部削除して」→ 実行できてしまう！

✅ 権限分離:
  Executor に書き込み権限なし
  → 「ナレッジを全部削除して」→ 権限エラーで阻止！
  → 最小権限の原則（必要最小限の権限だけを与える）
```

#### スキル体系（32 個、6 カテゴリ）

| カテゴリ     | スキル数 | 例                                                   |
| ------------ | -------- | ---------------------------------------------------- |
| ワークフロー | 3        | argus-workflow, daily-digest, daily-digest-thumbnail |
| 画像生成     | 6        | image-generator, svg-diagram, svg-header-image       |
| SNS          | 12       | sns-x-poster, sns-qiita-writer, sns-youtube-creator  |
| 動画         | 4        | video-studio, video-explainer, video-planner         |
| 音声         | 3        | tts, tts-dict, podcast-builder                       |
| ナレッジ     | 2        | knowledge-report, session-summary                    |

### 理解度チェック

1. deny-first の権限設計のメリットは？
2. Collector と Executor の権限分離の設計意図は？

---

## 13. 横断的パターン集

### ひとことまとめ

> コードベース全体で一貫して使われている設計パターンをまとめたもの。「Argus ではこう書く」というルールブック。

### 身近なたとえ

横断的パターンは「社内の業務マニュアル」。全社員がこのマニュアルに従うことで、誰が書いたコードでも同じ品質・同じスタイルが保たれる。

### パターン 1: `success: boolean` フラグ（throw しない）

**使用頻度**: 極めて高い（全公開関数で統一）
**なぜ重要か**: Slack Bot は 1 プロセスで全ユーザーにサービスを提供しているため、1 つのエラーでプロセスが落ちると全ユーザーが影響を受ける

```
❌ throw する方式:
  エラーが発生 → プロセスクラッシュ → 全ユーザー切断

✅ success: false を返す方式:
  エラーが発生 → { success: false, error: "..." } → 他のユーザーは影響なし
```

**Before/After の比較図**:

```
❌ Before（throw）              ✅ After（success フラグ）
┌──────────────────┐          ┌──────────────────┐
│ 関数 A           │          │ 関数 A           │
│  throw new Error │          │  return {        │
│                  │          │    success: false │
└────────┬─────────┘          │    error: "..."  │
         │                    │  }               │
    未捕捉例外！              └────────┬─────────┘
         │                             │
         ▼                             ▼
    プロセス全体が停止         呼び出し側が判断
    （全ユーザーに影響）       （問題のある処理だけ対応）
```

**具体的な障害シナリオ**:

```
throw した場合:
  10:00 ユーザー A → Calendar API ダウン → throw → プロセスクラッシュ
  10:00 ユーザー B, C, D → Bot 応答不能！

success: false の場合:
  10:00 ユーザー A → Calendar API ダウン → { success: false }
  10:00 ユーザー A に「取得失敗しました」と通知
  10:00 ユーザー B, C, D → 問題なく利用継続
```

**例外ベースとの詳細比較**:

| 観点                   | 例外ベース（throw）                                      | success フラグ（Argus 規約）                    |
| ---------------------- | -------------------------------------------------------- | ----------------------------------------------- |
| **エラーの伝播**       | 呼び出し元に暗黙的に伝播。try-catch を忘れるとクラッシュ | 戻り値として明示的に返される                    |
| **型安全性**           | throw する型を宣言できない（catch の型は `unknown`）     | 戻り値の型に含まれ、TypeScript が処理漏れを検出 |
| **Slack Bot への影響** | WebSocket 接続が切断されボット全体が停止                 | エラーは値として返されるだけで接続に影響なし    |
| **適切な場面**         | 回復不能なシステムエラー                                 | 正常なエラーケース（API 失敗等）                |

> **身近なたとえ**: エラーが起きても「ビル全体が停電する」のではなく、「問題のある部屋だけ赤ランプが点く」仕組み。

### パターン 2: コロケーション（テストファイルの配置）

**使用頻度**: 全パッケージ・全アプリで統一
**なぜ重要か**: テスト漏れを防ぎ、ファイル移動時の保守性を向上させる

```
❌ Before（別ディレクトリ）          ✅ After（コロケーション）
src/session-manager.ts              src/session-manager.ts
tests/session-manager.test.ts       src/session-manager.test.ts
                                     ↑ 同じディレクトリ！
```

**こうしなかったらどうなる？**:

- ファイル移動時にテストも手動で移動＋パス修正が必要
- 新ファイル追加時にテスト作成を後回しにしがち（ディレクトリ構造を手動で作る手間）
- 9 パッケージ + 3 アプリのモノレポでテストファイルの場所を見つけるだけで一苦労

### パターン 3: ESM 統一 + `.js` 拡張子

**使用頻度**: 全ファイルで統一
**なぜ重要か**: モジュールシステムの一貫性を保ち、ビルドエラーを防ぐ

```typescript
// パッケージ内インポートは .js 拡張子付き（ESM 規約）
export * from "./schema.js"; // ← .ts ではなく .js
export * from "./client.js";

// Node.js 組み込みモジュールは node: プレフィックス必須
import { existsSync } from "node:fs"; // ← node: 付き
import { join } from "node:path";
```

**なぜ `.ts` ではなく `.js`?**: TypeScript のソースは `.ts` だが、コンパイル後は `.js` になる。ESM では実行時に存在するファイルのパスを指定する必要があるため `.js` を指定する。TypeScript コンパイラは `.js` から対応する `.ts` を自動的に見つけてくれる。

**`node:` プレフィックスの理由**: Node.js の組み込みモジュールと npm パッケージを明確に区別するため。

### パターン 4: vi.mock による DB モック

**使用頻度**: DB を使うテスト全般
**なぜ重要か**: 本物の DB なしで高速にテストできる

```typescript
// Drizzle のチェーンメソッドを再現するモック
const mockDb: any = {
  select: vi.fn(() => mockDb),
  from: vi.fn(() => mockDb),
  where: vi.fn(() => mockDb),
  limit: vi.fn().mockResolvedValue([{ id: "test-id" }]),
  insert: vi.fn(() => mockDb),
  values: vi.fn(() => mockDb),
  returning: vi.fn().mockResolvedValue([{ id: "new-id" }]),
};
```

### パターン 5: 環境変数ガード

**使用頻度**: 全モジュールで統一
**なぜ重要か**: 同一コードを全環境にデプロイしつつ、各環境に必要な機能だけを動かせる

```typescript
if (!process.env.SOME_CHANNEL) {
  console.log("[ModuleName] Skipping: SOME_CHANNEL not set");
  return; // throw ではなくスキップ
}
```

### パターン 6: Promise.all による並列実行

**使用頻度**: データ収集・スキャン処理全般
**なぜ重要か**: 独立した処理を同時に実行して待ち時間を短縮

```typescript
// 3 種並列スキャン（順番にやると 3 倍遅い）
const [audit, secrets, typeErrors] = await Promise.all([
  runAudit(),
  scanSecrets(),
  runTypeCheck(),
]);
```

### パターン 7: ログフォーマット `[ModuleName]` プレフィックス

**使用頻度**: 全モジュールで統一
**なぜ重要か**: ログからどのモジュールの出力か即座に判別できる

```
[Agent Executor] Success: TestAgent (cost: $0.0034)
[Scheduler] Found 2 enabled agents
[Gmail Checker] Skipped: no-reply@github.com
[Code Patrol] Starting scan for 2026-02-15
```

### パターン 8: Fire-and-forget（撃ちっぱなし）

**使用頻度**: UI 付加的更新（Canvas、リアクション等）
**なぜ重要か**: 主処理をブロックせず、非クリティカルな処理を効率的に実行

```typescript
// fireAndForget() — agent-core 提供の共通ユーティリティ
import { fireAndForget } from "@argus/agent-core";
fireAndForget(updateExecutionCanvas(), "execution-canvas");
```

**判断基準**:

```
その処理が失敗したら、ユーザーに直接影響する？
├── YES → await して結果を確認（DB 書き込み、課金、重要な通知）
└── NO  → fireAndForget でOK（Canvas 更新、リアクション、SNS Canvas 表示）
```

> **身近なたとえ**: レストランで「お冷やをお持ちしました」の声かけが失敗しても料理の提供には影響しない。しかし「注文の記録」が失敗したら料理が出てこないので、こちらは確実に成功させる必要がある。

### パターン 9: スロットリング

**使用頻度**: Slack API 呼び出し全般
**なぜ重要か**: Slack API の rate limit（呼び出し回数の上限）に抵触しないようにする

```
更新リクエスト: |||||||||||||||||| （大量に来る）

スロットリング後: |    |    |    |   （一定間隔に制限）
                  10秒  10秒  10秒
```

使用箇所: Canvas 更新（10 秒）、進捗通知（2-8 秒）、パトロールフック（15 秒）。

### パターン 10: 型ガード付きフィルタ

**使用頻度**: 配列のフィルタリング全般
**なぜ重要か**: TypeScript に「フィルタ後の配列の型」を正しく認識させる

```typescript
// TypeScript の is 述語でフィルタ後の配列の型を絞る
const textBlocks = content.filter(
  (block): block is Block & { text: string } =>
    block.type === "text" && typeof block.text === "string",
);
// textBlocks の型: (Block & { text: string })[]
// → .text に安全にアクセスできる
```

### 理解度チェック

1. `success: boolean` パターンにより、Slack Bot でどんな障害を防げるか？
2. テストのコロケーション配置のメリットを 3 つ挙げられるか？
3. Fire-and-forget パターンで Canvas 更新の失敗を許容できる理由は？
4. `fireAndForget()` を使わずに Promise を放置すると何が起こるか？
5. スロットリングが必要な理由は？

---

## 14. 面接想定 Q&A

> 各回答には **技術者向け** と **噛み砕いた説明** の両方を用意している。技術面接ではそのまま使い、非エンジニアへの説明では噛み砕いた方を参考にしてほしい。

### Q1: 「このプロジェクトのフォルダ構成を教えてください」

**回答例**:

> pnpm モノレポで、`apps/`（3 アプリ）と `packages/`（9 パッケージ）に分離しています。`apps/` が実行可能なアプリケーション（slack-bot, dashboard, orchestrator）で、`packages/` が共有ライブラリ（agent-core, db, knowledge 等）です。依存は常に `apps/ → packages/` の一方向で、パッケージ間の依存は最小限です。

**噛み砕いた説明**: 会社のフロアを想像してほしい。`apps/` は各部署のオフィス、`packages/` は全社共有の会議室や倉庫。各部署は共有設備を使うが、部署同士が直接干渉しない設計。

### Q2: 「agent-core パッケージの設計思想を説明してください」

**回答例**:

> agent-core は Claude Agent SDK のラッパーで、本番依存は SDK の 1 つだけという極めてスリムな設計です。DB への直接依存を避け、`SessionStore` や `ObservationDB` 等のインターフェースを定義して消費側に実装を注入する DI パターンを採用しています。これにより、テストが容易で、異なる永続化先への差し替えが可能です。

**噛み砕いた説明**: agent-core は「充電器の規格」のようなもの。本体（エージェント）とプラグ（データベースなど）を分離しておくことで、プラグを交換しても本体は変わらない。

### Q3: 「エラーハンドリングの設計方針を教えてください」

**回答例**:

> プロジェクト全体で `success: boolean` フラグパターンを統一しています。例外を throw するのではなく、`{ success: false, error: "..." }` のような結果オブジェクトを返します。これにより、呼び出し側が try-catch を忘れてクラッシュするリスクを排除し、型システムでエラーケースの処理を強制できます。

**噛み砕いた説明**: エラーが起きても「プログラム全体が止まる」のではなく、「この処理は失敗しました」という報告書を返す方式。ブレーカーが落ちて家中停電するのではなく、問題のある部屋だけ赤ランプが点く仕組み。

### Q4: 「Inbox パイプラインの設計を説明してください」

**回答例**:

> 4 段階のパイプラインです。(1) classifier で AI（Haiku）またはキーワードベースでメッセージを分類、(2) タスクキューに投入（同時実行制限 3、アトミックなステータス更新で二重実行防止）、(3) executor で Agent SDK を実行（intent 別タイムアウト付き）、(4) reporter で Block Kit レポートを生成。起動時リカバリ機能もあり、クラッシュで `running` のまま取り残されたタスクを自動復元します。

**噛み砕いた説明**: 届いたメッセージを「仕分け → 列に並べる → 処理する → 報告する」の 4 段階で処理する郵便局のような仕組み。同時に処理できる数に上限を設け、途中でシステムが落ちても未完了の仕事を自動で再開する。

### Q5: 「テスト戦略について教えてください」

**回答例**:

> Vitest 4 でソースと同ディレクトリにテストをコロケーション配置しています。DB 接続はせず、`vi.mock()` で Drizzle のチェーンメソッドをモックします。Dashboard では jsdom + Testing Library で Server Component のテストも行っています。Next.js の `Link` や `usePathname` は `vi.mock()` で置換し、API テストでは `globalThis.fetch` を `vi.spyOn` でモックします。

**噛み砕いた説明**: 各ソースファイルのすぐ隣にテストファイルを置く「コロケーション」方式。本物のデータベースや AI を使わず、「ダミー」に差し替えてテストするので、速く・安く・確実に品質を確認できる。

### Q6: 「MCP サーバーの実装パターンを説明してください」

**回答例**:

> `McpBaseServer` という抽象基底クラスを `agent-core` パッケージに用意し、全 4 つの MCP サーバー（knowledge, knowledge-personal, gmail, google-calendar）がこれを継承しています。サブクラスは `getTools()`（ツール一覧）と `handleToolCall()`（ツール実行ロジック）の 2 メソッドだけ実装すれば MCP サーバーとして動作します。ListTools / CallTool ハンドラの登録と StdioServerTransport 接続は基底クラスで共通化されています。knowledge パッケージでは Collector/Executor のロールベース権限分離を 2 層（ツール公開層 + ビジネスロジック層）で実装しています。

**噛み砕いた説明**: AI に「道具」を持たせるための統一テンプレート（McpBaseServer）を用意し、各サーバーは「どんな道具があるか」と「道具の使い方」だけを定義すればよい。マクドナルドのフランチャイズで、店舗の基本設計は本部が提供し、各店舗はメニューだけ独自に決めるのと同じ。

### Q7: 「Code Patrol の仕組みを教えてください」

**回答例**:

> 週次（土曜 3:00 JST）で自動実行される 12 ステップのパイプラインです。まず pnpm audit・シークレット検出・tsc を並列スキャンし、問題があれば Claude に修正を依頼します。修正前に git stash で安全ネットを張り、修正後は pnpm build && pnpm test で検証。検証失敗時は git checkout でロールバックし、成功時は Block Kit レポートを Slack に投稿します。修正中のリアルタイム通知フック（15 秒スロットル）も備えています。

**噛み砕いた説明**: 毎週土曜の深夜に「夜間警備員」が自動でコードの健康診断を行う仕組み。問題を見つけたら AI に修正を依頼し、修正が正しいか検証してから適用する。失敗したら元に戻すので安全。結果は Slack に報告書として届く。

### Q8: 「SNS 投稿管理システムの設計を教えてください」

**回答例**:

> 10 プラットフォーム（X, YouTube, TikTok, Threads, Instagram, note, Qiita, Zenn, GitHub, Podcast）に対応した自動投稿システムです。核心は `PhasedGenerator` という段階的パイプライン実行エンジンで、各プラットフォームのコンテンツ生成をフェーズ分割して順次実行します。長文コンテンツ（記事・動画スクリプト等）は 4 フェーズ（research → structure → content → optimize）、短文コンテンツ（X, Threads）は 2 フェーズ構成です。各フェーズの出力を JSON で次フェーズに渡し、途中失敗時はそのフェーズからリトライできます。スケジューラは毎朝 4:00 JST に全プラットフォームの投稿案を自動生成し、毎分ポーリングでスケジュール済み投稿を自動公開します。

**噛み砕いた説明**: 毎朝 4 時に AI が 10 個の SNS の投稿案を自動で作成する仕組み。記事は「調査→構成→執筆→校正」の 4 工程に分けて品質を確保する。各プラットフォームに最適な投稿時間（X なら 7:30, 12:15, 18:00）に自動で投稿する。Mac のスリープで朝の自動生成を逃しても、起動時に自動で追いつく機能もある。

### Q9: 「McpBaseServer を導入した理由を教えてください」

**回答例**:

> 4 つの MCP サーバー（knowledge, knowledge-personal, gmail, google-calendar）で共通のボイラープレートが重複していたため、`McpBaseServer` 抽象クラスに集約しました。Server インスタンス生成、ListTools / CallTool ハンドラ登録、StdioServerTransport 接続を基底クラスに共通化し、サブクラスは `getTools()` と `handleToolCall()` の 2 メソッドだけ実装すればよくなりました。MCP SDK のバージョンアップ時も 1 箇所の修正で全サーバーに反映でき、新規 MCP サーバー追加のコストも大幅に削減されます。

**噛み砕いた説明**: 4 つのお店（MCP サーバー）で毎回「入口の作り方」「レジの配置」「キッチンの設計」を個別に考えていたのを、「店舗テンプレート」を作って共通化した。新しいお店を出す時も、テンプレートに「メニュー」と「調理法」を追加するだけで開店できる。

---

> **このドキュメントの最終更新**: 2026-02-17
> **対応バージョン**: Argus v0.1.0（12 パッケージ構成）

---

# Part 8: Argus 技術スタック＆アーキテクチャ


> 面接対策・自己学習用の包括的リファレンス。
> 各選定の「なぜ」を ADR（Architecture Decision Record: 設計判断の記録）形式で解説する。

---

## 目次

1. [はじめに — このドキュメントの読み方 + プロジェクト概要](#1-はじめに)
2. [全体アーキテクチャ — 構成図 + スタック一覧](#2-全体アーキテクチャ)
3. [データベース: なぜ PostgreSQL か](#3-データベース-なぜ-postgresql-か)
4. [ORM: なぜ Drizzle か](#4-orm-なぜ-drizzle-か)
5. [AI エージェント: なぜ Claude Agent SDK か](#5-ai-エージェント-なぜ-claude-agent-sdk-か)
6. [パッケージ管理: なぜ pnpm か](#6-パッケージ管理-なぜ-pnpm-か)
7. [Slack Bot: なぜ Bolt (Socket Mode) か](#7-slack-bot-なぜ-bolt-socket-mode-か)
8. [Dashboard: なぜ Next.js か](#8-dashboard-なぜ-nextjs-か)
9. [API サーバー: なぜ Express か](#9-api-サーバー-なぜ-express-か)
10. [テスト: なぜ Vitest か](#10-テスト-なぜ-vitest-か)
11. [ホスティング: なぜ Railway + Supabase か](#11-ホスティング-なぜ-railway--supabase-か)
12. [ストレージ: なぜ Cloudflare R2 か](#12-ストレージ-なぜ-cloudflare-r2-か)
13. [設計パターンと原則](#13-設計パターンと原則)
14. [面接想定 Q&A](#14-面接想定-qa)
15. [用語集](#15-用語集)

---

## 1. はじめに

### このドキュメントの読み方

本ドキュメントは **学習科学の原則** に基づいて構成されている。

- **各セクション = 1 つの技術選定**（Feynman Technique: 1 つの概念を深く理解してから次へ）
- **ADR 形式**: 背景 → 選択肢の比較 → 決定 → 結果（メリット・デメリット）
- **Why → What → How** の順序（なぜ必要か → 何を選んだか → どう使っているか）
- 各セクション冒頭に **「このセクションで学ぶこと」**、末尾に **「理解度チェック」** を配置
- 専門用語の初出時に（）で平易な解説を入れている
- **「平たく言うと」** ボックスで非エンジニア向けの説明を随所に配置

### プロジェクト概要

Argus は **Slack ベースの AI エージェントプラットフォーム**。Claude（Anthropic 社の AI）を核として、メール管理、スケジュール管理、ナレッジベース（知識の蓄積庫）、SNS 投稿を自動化する。

> **平たく言うと**: Slack のチャットに話しかけると、AI が代わりにメールを読んだり、予定を確認したり、知識を検索したりしてくれるシステム。

| 項目     | 値                                                                                        |
| -------- | ----------------------------------------------------------------------------------------- |
| 種別     | pnpm モノレポ（12 パッケージ）— 複数のプログラムを 1 つのリポジトリで管理する構成         |
| 言語     | TypeScript 5.6（strict, ESM）— JavaScript に型チェックを加えた言語                        |
| Node.js  | >= 22.12.0 — JavaScript をサーバーで動かすための実行環境                                  |
| テスト   | 1,200+ テスト（Vitest 4）— プログラムが正しく動くかを自動確認する仕組み                   |
| デプロイ | Railway VPS + Docker + PM2 — クラウド上の仮想サーバーにコンテナ化して配置、プロセスを管理 |

---

## 2. 全体アーキテクチャ

### 構成図

```
┌─────────────────────────────────────────────────┐
│                    apps/                         │
│  ┌──────────┐ ┌───────────┐ ┌────────────────┐  │
│  │ slack-bot │ │ dashboard │ │  orchestrator  │  │
│  │ Bolt 4   │ │ Next.js 16│ │  Express 5     │  │
│  └────┬─────┘ └─────┬─────┘ └───────┬────────┘  │
│       │              │               │           │
├───────┼──────────────┼───────────────┼───────────┤
│       │          packages/           │           │
│  ┌────┴────┐  ┌────┐  ┌───────────┐ │           │
│  │agent-core│  │ db │  │ knowledge │ │           │
│  │ SDK wrap │  │Drizzle│ │  MCP    │ │           │
│  └─────────┘  └────┘  └───────────┘ │           │
│  ┌─────┐  ┌──────────────┐  ┌───────┴──┐        │
│  │gmail│  │google-calendar│  │r2-storage│        │
│  │OAuth│  │    MCP        │  │ S3互換   │        │
│  └─────┘  └──────────────┘  └──────────┘        │
└─────────────────────────────────────────────────┘
         ↓               ↓              ↓
   Supabase PG    Cloudflare R2    Railway VPS
```

### 技術スタック一覧

| レイヤー            | 技術                           | バージョン  |
| ------------------- | ------------------------------ | ----------- |
| **ランタイム**      | Node.js                        | >= 22.12.0  |
| **言語**            | TypeScript (strict ESM)        | ^5.6.0      |
| **パッケージ管理**  | pnpm                           | 10.23.0     |
| **DB**              | PostgreSQL (Supabase)          | -           |
| **ORM**             | Drizzle ORM + postgres.js      | ^0.45.0     |
| **AI エージェント** | Claude Agent SDK               | ^0.2.34     |
| **AI API**          | Anthropic SDK                  | ^0.74.0     |
| **Slack**           | Bolt (Socket Mode)             | ^4.0.0      |
| **Web UI**          | Next.js + React + Tailwind CSS | 16 / 19 / 4 |
| **API サーバー**    | Express                        | ^5.1.0      |
| **MCP**             | Model Context Protocol SDK     | ^1.26.0     |
| **ストレージ**      | Cloudflare R2 (S3 互換)        | -           |
| **テスト**          | Vitest                         | ^4.0.0      |
| **デプロイ**        | Railway + Docker + PM2         | -           |
| **CDN/トンネル**    | Cloudflare Tunnel + Access     | -           |

### バージョン表記の読み方

技術スタック表のバージョン欄には、semver（Semantic Versioning: セマンティックバージョニング）に基づく表記が使われている。

| 表記           | 意味                                                                                                   | 例                                        |
| -------------- | ------------------------------------------------------------------------------------------------------ | ----------------------------------------- |
| `>=`           | 「以上」。指定バージョン以上であれば動作する                                                           | `>= 22.12.0` → 22.12.0 以上の Node.js     |
| `^`            | メジャーバージョン内の互換範囲。semver に準拠し、メジャーバージョンが変わらない範囲で最新を許容する    | `^5.6.0` → 5.6.0 以上 6.0.0 未満          |
| `-`            | バージョン管理の対象外。カスタム設定やマネージドサービス側で管理されるため、固定バージョンを指定しない | PostgreSQL (Supabase) → Supabase 側で管理 |
| バージョンのみ | 特定バージョンに固定（pnpm 自体のバージョン等）                                                        | `10.23.0` → そのバージョンのみ            |

### 依存の方向

構成図において、apps（アプリケーション層）は packages（共通ライブラリ層）に依存するが、**packages が apps に依存することは許されない**。これを「一方向依存」と呼ぶ。

一方向依存にする理由は以下の 3 つ。

1. **循環依存の防止** — packages が apps を参照すると、apps → packages → apps という循環が発生し、ビルドや起動が不可能になる
2. **packages の独立性・再利用性確保** — packages は特定のアプリに依存しないため、別のプロジェクトでもそのまま再利用できる。例えば `@argus/db` は slack-bot でも dashboard でも orchestrator でも同じように使える
3. **テスト容易性** — packages はアプリのコンテキストなしに単体テストできる。依存が一方向なので、packages のテスト時にアプリ全体を起動する必要がない

### 理解度チェック

- [ ] Q1: 構成図の 3 層（apps / packages / 外部サービス）それぞれの役割を説明できるか？
- [ ] Q2: apps → packages の一方向依存にしている理由を説明できるか？
- [ ] Q3: 技術スタック表でバージョンに `>=` や `^` が使われている意味と、`-` が使われている場合の違いを説明できるか？

---

## 3. データベース: なぜ PostgreSQL か

> **このセクションで学ぶこと**:
>
> - リレーショナル DB とドキュメント DB の根本的な違い
> - Argus のデータモデルがなぜリレーショナルに適しているか
> - Supabase を選んだ理由とマネージド DB の比較

### 背景（なぜ選ぶ必要があったか）

Argus のデータは「セッション → メッセージ → ツール実行記録」のように **テーブル同士が外部キー（参照関係）で密に結ばれている**。14 テーブル中ほぼ全てが関連しており、「あるセッションのメッセージ一覧 + そこで実行されたツール + 結果」を一発で取得する場面が頻繁にある。

> **平たく言うと**: データが「Excel のシート同士がリンクで繋がっている」ような構造なので、そういう構造を扱うのが得意なデータベースを選んだ。

```
sessions (1) ──< messages (N)
sessions (1) ──< tasks (N)      ← ツール実行記録
agents   (1) ──< agent_executions (N)
inbox_tasks  ──> sessions       ← FK で紐付け
```

### 選択肢の比較

| 比較軸                                        | PostgreSQL                                                 | MongoDB                                 | MySQL                                 | DynamoDB                                |
| --------------------------------------------- | ---------------------------------------------------------- | --------------------------------------- | ------------------------------------- | --------------------------------------- |
| **リレーション**（テーブル間の紐付け）        | JOIN で自然に表現                                          | `$lookup` が必要、パフォーマンス劣化    | JOIN 対応だが機能が PostgreSQL に劣る | 単一テーブル設計が推奨、JOIN 不可       |
| **ACID トランザクション**（データ整合性保証） | ネイティブ対応（＝追加設定なしで最初から組み込まれている） | 4.0+ で対応だが制限あり                 | 対応（InnoDB）                        | 制限付き（25 項目まで）                 |
| **スキーマの柔軟性**                          | 厳密（変更にはマイグレーション）                           | スキーマレス（自由構造）                | 厳密                                  | スキーマレス                            |
| **全文検索**                                  | `tsvector` / `pg_trgm`                                     | 組み込みだが日本語が弱い                | FULLTEXT（日本語弱い）                | なし（別途 OpenSearch 必要）            |
| **集約クエリ**（データの集計・分析）          | SQL が圧倒的に書きやすい                                   | Aggregation Pipeline は複雑             | SQL 対応                              | 不得意（Scan ベース）                   |
| **JSON サポート**                             | `jsonb` でインデックス可能                                 | ネイティブ（JSON がそのままデータ形式） | `JSON` 型あり                         | ネイティブ（JSON がそのままデータ形式） |
| **コスト（Supabase 等）**                     | 無料枠 500MB                                               | Atlas 無料枠 512MB                      | PlanetScale 廃止済み                  | 25 RCU/WCU 無料                         |
| **エコシステム成熟度**                        | 35年以上の実績                                             | 15年以上                                | 30年以上                              | AWS 依存                                |

### MongoDB が適しているケース

Argus では PostgreSQL を選んだが、以下のようなプロジェクトでは MongoDB の方が適している。

- **スキーマが頻繁に変更される** — プロトタイプ段階や初期のスタートアップで、データ構造が固まっていない場合。スキーマレスなので、マイグレーションなしにフィールドを追加・削除できる
- **ドキュメント構造のデータ** — ブログ記事、商品カタログ、ユーザープロフィールなど、1 つのドキュメントに関連データがネストされる構造。JOIN を使わずに 1 回の読み取りで完結する
- **リレーションが少ないデータ** — テーブル間の外部キー参照がほとんどなく、各ドキュメントが独立している場合
- **水平スケールが最優先** — シャーディング（データの分散配置）が組み込みで、大量のデータを複数サーバーに分散させやすい

Argus のデータは逆に「セッション → メッセージ → ツール実行」のリレーションが密なため、MongoDB の `$lookup`（JOIN 相当）では効率が落ちる。

### 決定: PostgreSQL

Argus のデータモデルは明確にリレーショナルであり、以下の具体的な要件が決め手となった。

**具体例 1: Inbox Agent のタスクキュー**

```sql
-- PostgreSQL: トランザクションで「取得 + ステータス更新」を一括
BEGIN;
  SELECT * FROM inbox_tasks
  WHERE status = 'queued'
  ORDER BY priority DESC, created_at ASC
  LIMIT 1
  FOR UPDATE SKIP LOCKED;  -- 排他ロック、他ワーカーとの競合防止

  UPDATE inbox_tasks SET status = 'processing' WHERE id = $1;
COMMIT;
```

MongoDB でこれをやろうとすると `findOneAndUpdate` + `$set` になるが、`FOR UPDATE SKIP LOCKED` 相当の機能がなく、高負荷時に競合が起きやすい。DynamoDB では条件付き更新（ConditionExpression）で実現可能だが、キューパターンの実装が複雑になる。

**具体例 2: lessons テーブルのエピソード記憶**

```sql
-- 「同じエラーパターンが過去に何回発生し、どう解決したか」を集約
SELECT error_pattern, COUNT(*) as occurrences,
       array_agg(resolution ORDER BY created_at DESC) as resolutions
FROM lessons
WHERE agent_name = 'inbox-executor'
GROUP BY error_pattern
ORDER BY occurrences DESC;
```

この種のクエリは SQL の得意分野。MongoDB の Aggregation Pipeline で書くと `$group` + `$push` + `$sort` のパイプラインが長くなり、可読性が落ちる。

**なぜ Supabase か**:

| 比較軸               | Supabase                         | 自前 PostgreSQL    | PlanetScale (MySQL) |
| -------------------- | -------------------------------- | ------------------ | ------------------- |
| **無料枠**           | 500MB DB + Auth + Edge Functions | なし               | 廃止済み            |
| **接続方式**         | Pooler (pgBouncer) + Direct      | 自前               | HTTP API のみ       |
| **マイグレーション** | Drizzle Kit で push              | 同じ               | 同じ                |
| **リアルタイム**     | Realtime 機能あり                | 自前 LISTEN/NOTIFY | なし                |
| **バックアップ**     | 自動（Pro プラン）               | 自前               | 自動                |
| **運用コスト**       | ほぼゼロ（インハウス規模）       | 高い               | -                   |

**決め手**: 無料枠が寛大で、PostgreSQL がそのまま使えて、接続文字列を `DATABASE_URL` に入れるだけ。

### この選定のメリット・デメリット

**メリット**:

- JOIN による複雑なクエリが自然に書ける
- `FOR UPDATE SKIP LOCKED` で安全なタスクキューを実現
- `jsonb` で半構造化データも柔軟に扱える
- Supabase の無料枠で運用コストがほぼゼロ

**デメリット・トレードオフ**:

- スキーマ変更にマイグレーションが必要（MongoDB ならスキーマレスで柔軟）
- 水平スケールが DynamoDB ほど容易ではない（ただし現在の規模では不要）
- Supabase の無料枠には接続数上限がある（Pro プランで緩和可能）

### 理解度チェック

- [ ] Q1: PostgreSQL を選んだ主な理由を 3 つ挙げられるか？
- [ ] Q2: MongoDB が向いているプロジェクトの特徴を説明できるか？
- [ ] Q3: `FOR UPDATE SKIP LOCKED` がなぜタスクキューに重要かを説明できるか？

---

## 4. ORM: なぜ Drizzle か

> **このセクションで学ぶこと**:
>
> - ORM とは何か、なぜ必要か
> - Drizzle と Prisma の具体的な違い（コード例つき）
> - 他の ORM / クエリビルダーとの比較

### 背景（なぜ選ぶ必要があったか）

ORM（Object-Relational Mapping）は、プログラムからデータベースを操作するための「翻訳レイヤー」。SQL（データベースの言語）を直接書く代わりに、TypeScript のコードでデータベース操作を記述できる。

Argus は完全 ESM + TypeScript strict モードで構築されており、ORM にも同様の現代的な対応が求められた。

> **平たく言うと**: ORM とは、プログラムからデータベースを操作するための「翻訳レイヤー」。SQL を直接書く代わりに、TypeScript のコードでデータベース操作を記述できる。Drizzle と Prisma はどちらも ORM だが、Drizzle の方が軽量でシンプル。

### 選択肢の比較

| 比較軸                                                                                                                                              | Drizzle ORM                                   | Prisma                                                                   | Knex.js          | TypeORM                                       | Kysely         | 生 SQL       |
| --------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------- | ------------------------------------------------------------------------ | ---------------- | --------------------------------------------- | -------------- | ------------ |
| **バンドルサイズ**                                                                                                                                  | 数十 KB（純 JS）                              | 数 MB（Rust バイナリ + 生成クライアント）                                | 軽量             | 中程度                                        | 軽量           | なし         |
| **ESM 対応**                                                                                                                                        | ネイティブ ESM（最初から ESM で書かれている） | CJS 前提で後付け対応（元々は旧方式で作られ、後から ESM に対応した）      | 後付け           | 遅い・不安定                                  | 標準対応       | -            |
| **型推論**                                                                                                                                          | `select()` の戻り値が自動推論                 | `prisma generate` で生成                                                 | 弱い             | デコレータ（@記号で機能を付加する記法）ベース | 強い           | なし         |
| **SQL との距離**                                                                                                                                    | SQL の写し（学習コスト低）                    | 独自 DSL（Domain-Specific Language: 特定の目的に特化した専用の記述方式） | SQL に近い       | 独自 API                                      | SQL に近い     | SQL そのもの |
| **Docker ビルド**                                                                                                                                   | 追加ステップなし                              | `prisma generate` + Rust バイナリ互換問題                                | なし             | なし                                          | なし           | なし         |
| **マイグレーション**                                                                                                                                | `drizzle-kit push` / `generate`               | `prisma migrate`                                                         | knex migrate     | TypeORM migration                             | 外部ツール必要 | 自前管理     |
| **接続プーリング**                                                                                                                                  | postgres.js で直接制御                        | Prisma 側で管理（制御しづらい）                                          | 設定可能         | 設定可能                                      | 設定可能       | 直接制御     |
| **複雑なクエリ**（Window 関数（データの行ごとに集計しつつ元の行も保持できる SQL 機能）, CTE（クエリ内で一時的な名前付きテーブルを定義する仕組み）） | 自然に書ける                                  | `$queryRaw` に逃げがち                                                   | 書けるが型が弱い | 難しい                                        | 書ける         | 自由自在     |
| **エコシステム成熟度**                                                                                                                              | 急成長中                                      | 最大・最も成熟                                                           | 長い歴史         | 停滞気味                                      | 成長中         | -            |

### 決定: Drizzle ORM

ESM にネイティブ対応（最初から ESM 方式で作られている） + TypeScript 型推論 + SQL に近い + マイグレーションツール（drizzle-kit）の組み合わせが、Argus の要件にぴったりだった。

**具体例 1: スキーマ定義の比較**

**Drizzle（Argus の実際のコード）**:

```typescript
// packages/db/src/schema.ts
import {
  pgTable,
  text,
  timestamp,
  integer,
  jsonb,
  boolean,
} from "drizzle-orm/pg-core";

export const sessions = pgTable("sessions", {
  id: text("id").primaryKey(),
  threadTs: text("thread_ts").notNull(),
  channelId: text("channel_id").notNull(),
  agentSessionId: text("agent_session_id"),
  createdAt: timestamp("created_at").defaultNow().notNull(),
});

export const messages = pgTable("messages", {
  id: text("id").primaryKey(),
  sessionId: text("session_id")
    .references(() => sessions.id)
    .notNull(),
  role: text("role").notNull(), // "user" | "assistant"
  content: text("content").notNull(),
  costUsd: integer("cost_usd"),
  createdAt: timestamp("created_at").defaultNow().notNull(),
});
```

**同等の Prisma スキーマ**:

```prisma
// schema.prisma （比較用、Argus では使っていない）
model Session {
  id             String    @id
  threadTs       String    @map("thread_ts")
  channelId      String    @map("channel_id")
  agentSessionId String?   @map("agent_session_id")
  createdAt      DateTime  @default(now()) @map("created_at")
  messages       Message[]
}

model Message {
  id        String   @id
  sessionId String   @map("session_id")
  session   Session  @relation(fields: [sessionId], references: [id])
  role      String
  content   String
  costUsd   Int?     @map("cost_usd")
  createdAt DateTime @default(now()) @map("created_at")
}
```

**Drizzle の利点**: TypeScript ファイルの中で完結するため、IDE の補完・リファクタリングがそのまま効く。Prisma は `.prisma` ファイルという独自フォーマットで、VS Code の Prisma 拡張がないと補完が効かない。

**具体例 2: クエリの比較**

**Drizzle**:

```typescript
const result = await db
  .select({
    session: sessions,
    messageCount: sql<number>`count(${messages.id})`,
  })
  .from(sessions)
  .leftJoin(messages, eq(messages.sessionId, sessions.id))
  .where(eq(sessions.channelId, channelId))
  .groupBy(sessions.id)
  .orderBy(desc(sessions.createdAt))
  .limit(10);
// 型: { session: typeof sessions.$inferSelect; messageCount: number }[]
```

**Prisma**:

```typescript
const result = await prisma.session.findMany({
  where: { channelId },
  include: { _count: { select: { messages: true } } },
  orderBy: { createdAt: "desc" },
  take: 10,
});
// 型は生成された Prisma Client の型
```

Drizzle は SQL に近いので、**複雑なクエリ（Window 関数、CTE、サブクエリ）に強い**。Prisma は簡単なクエリは簡潔だが、複雑になると `$queryRaw` に逃げがち。

**具体例 3: Docker ビルドへの影響**

**Argus の Dockerfile（Drizzle）**:

```dockerfile
FROM node:22-alpine AS builder
COPY . .
RUN pnpm install --frozen-lockfile
RUN pnpm build  # TypeScript コンパイルのみ
# → 追加ステップなし

FROM node:22-alpine
COPY --from=builder /app .
CMD ["pm2-runtime", "ecosystem.config.cjs"]
```

**Prisma を使った場合**:

```dockerfile
FROM node:22-alpine AS builder
COPY . .
RUN pnpm install --frozen-lockfile
RUN npx prisma generate  # ← この追加ステップが必要
# alpine では Rust バイナリの互換性問題が発生しうる
# → binaryTargets = ["native", "linux-musl-arm64-openssl-3.0.x"] の指定が必要
RUN pnpm build
```

### この選定のメリット・デメリット

**メリット**:

- ESM に標準対応しており設定不要
- TypeScript の型推論がそのまま活きる（コード生成ステップ不要）
- SQL に近く、複雑なクエリも自然に書ける
- Docker ビルドがシンプル（Rust バイナリ互換問題なし）

**デメリット・トレードオフ**:

- Prisma と比べてエコシステム（ドキュメント、プラグイン）がまだ小さい
- Prisma Studio のような GUI データブラウザがない（Drizzle Studio は発展途上）
- リレーション API（Prisma の `include` のような宣言的な関連取得）が Prisma ほど洗練されていない

**Prisma が向いているケース**:

- **シンプルな CRUD 中心のアプリ** — Prisma の宣言的な API（`findMany`, `create`, `update`）は、複雑なクエリが少ないプロジェクトで生産性が高い
- **チームに SQL に不慣れなメンバーが多い** — Prisma の独自 DSL は SQL を知らなくても直感的に書ける。Drizzle は SQL に近いため、SQL の理解が前提になる
- **Prisma Studio で GUI 管理したい** — データの閲覧・編集を GUI で行いたい場合、Prisma Studio が便利（Drizzle Studio は発展途上）
- **CJS プロジェクト** — 既存の CJS（CommonJS）プロジェクトでは Prisma の方が安定している。ESM 移行が不要な場合は Prisma のエコシステムの成熟度が活きる

### 理解度チェック

- [ ] Q1: Drizzle を選んだ主な理由を 3 つ挙げられるか？
- [ ] Q2: Prisma のメリットとデメリットを説明できるか？
- [ ] Q3: どんなプロジェクトなら Prisma の方が適しているか？

---

## 5. AI エージェント: なぜ Claude Agent SDK か

> **このセクションで学ぶこと**:
>
> - Agent SDK と Anthropic SDK の根本的な違い
> - SDK のメッセージフロー（ストリーミング）と consumeSDKStream の設計
> - Max Plan 自動切り替え、Hooks 二層抽象化、MCP 接続パターン、テストモック

### 背景（なぜ選ぶ必要があったか）

Argus は AI に「自律的に作業させる」エージェントプラットフォーム。単純な 1 問 1 答ではなく、AI が自分でファイルを読み、コマンドを実行し、外部ツール（メール、カレンダー等）を操作する必要がある。

> **平たく言うと**: SDK とは「ある機能を簡単に使うための道具箱」のようなもの。Agent SDK を使うと、Claude（AI）に「このファイルを読んで」「このコマンドを実行して」と指示を出し、AI が自律的に作業を進める仕組みをプログラムに組み込める。
>
> 類似の概念で **API**（Application Programming Interface）があるが、API は「1回の質問に1回の回答」。Agent SDK は「目標を渡すと、AI が自分で考えてファイルを読んだりコマンドを実行したりしながら、最終結果を返す」というより高度なもの。

### 選択肢の比較

| 比較軸                                     | Claude Agent SDK                                                | Anthropic SDK (直接)          | LangChain                  | Vercel AI SDK            | OpenAI Assistants                    |
| ------------------------------------------ | --------------------------------------------------------------- | ----------------------------- | -------------------------- | ------------------------ | ------------------------------------ |
| **抽象レベル**                             | エージェントループ全体（自律作業）                              | API 呼び出し 1 回分（1問1答） | チェーン・エージェント抽象 | ストリーミング UI 特化   | スレッド + ランベースの自律実行      |
| **ツール実行**                             | SDK が自動でループ（Read, Write, Bash 等）                      | 自前でループ実装が必要        | ツールチェーンで定義       | サーバーアクションで定義 | Function calling + 自動実行          |
| **MCP 対応**                               | ネイティブ対応（`mcpServers` オプションを書くだけで接続できる） | なし（自前で接続）            | コミュニティプラグイン     | なし                     | なし                                 |
| **セッション管理**                         | `resume` で自動継続                                             | 自前でメッセージ履歴管理      | Memory モジュール          | なし                     | Thread API で管理                    |
| **ファイル操作**                           | 組み込み（Read, Write, Bash）                                   | なし                          | なし（自前で定義）         | なし                     | Code Interpreter（サンドボックス内） |
| **パーミッション制御**                     | `permissionMode` で制御                                         | なし                          | なし                       | なし                     | なし                                 |
| **モデルロックイン**（特定モデルへの依存） | Claude 専用                                                     | Claude 専用                   | マルチモデル対応           | マルチモデル対応         | OpenAI 専用                          |
| **実体**                                   | Claude Code CLI を子プロセスとして起動                          | HTTP API クライアント         | Python/JS ライブラリ       | React フック + サーバー  | OpenAI API                           |
| **料金**                                   | Max Plan なら追加コストなし / API キーなら従量課金              | 常に API 従量課金             | 使用するモデルに依存       | 使用するモデルに依存     | 常に API 従量課金                    |

### 決定: Claude Agent SDK

Argus の中核要件「AI が自律的にツールを使いながら作業を進める」に最も直接的に対応していた。特に MCP にネイティブ対応（追加ライブラリなしでそのまま使える）していることと、Max Plan による追加コストなしの運用が決定的だった。

### 5.1 SDK のメッセージフロー

> **平たく言うと**: SDK にリクエストを投げると、結果が一度にドカンと返るのではなく、「今システムを初期化しました」「今ファイルを読みました」「今回答を考えています」…のように、**進捗が逐次流れてくる**（ストリーミング）。Argus はこの流れを受け取って、必要な情報を拾い集める。

```
query({ prompt, options })
  │
  ▼
AsyncGenerator<SDKMessage, void>  ← メッセージが次々と流れてくる（ストリーミング）
  │
  ├── SDKSystemMessage (type: "system", subtype: "init")
  │     └── session_id を取得
  │
  ├── SDKAssistantMessage (type: "assistant")  ← 0回以上繰り返し
  │     └── message.content: TextBlock | ToolUseBlock
  │         ├── type: "text" → テキスト応答
  │         └── type: "tool_use" → ツール呼び出し（SDK が自動実行）
  │
  └── SDKResultMessage (type: "result")
        ├── subtype: "success" → result テキスト + total_cost_usd
        └── subtype: "error_*" → is_error: true
```

#### なぜ AsyncGenerator（ストリーミング）なのか

SDK の `query()` は `AsyncGenerator`（データを一度に全部ではなく、少しずつ返す非同期の仕組み）を返す。**なぜ普通の Promise（全部終わるまで待って一括で結果を返す方式）ではないのか？**

> **平たく言うと**: YouTube の動画を「全部ダウンロードしてから再生」するか、「ストリーミングで少しずつ再生」するかの違い。ストリーミングなら待ち時間が短く、途中で「やっぱり見ない」と止めることもできる。

**メリット 1: リアルタイムに途中経過を処理できる**

AI の応答はチャットのタイピングのように少しずつ届く。AsyncGenerator なら、届いた分から順次処理できる。

```
■ AsyncGenerator（ストリーミング）の場合:
  0秒: リクエスト送信
  1秒: [system] セッション開始 → セッションIDを記録
  3秒: [assistant] 「メールを確認します」 → Slackに進捗表示
  8秒: [assistant] ツール実行: gmail_search → 実行ログを記録
 15秒: [assistant] 「3件の未読メールがあります」 → Slackに表示
 16秒: [result] 完了 → コストを記録

■ 普通の Promise（一括取得）の場合:
  0秒: リクエスト送信
  1〜15秒: ......何も分からない。進捗も見えない......
 16秒: 全データが一度にドカンと届く → やっと処理開始
```

Promise 方式だと、ユーザーは16秒間「AIが動いているのか固まっているのか」すら分からない。AsyncGenerator なら、1秒後にはセッションが開始されたことが分かり、3秒後には「メールを確認しています」という進捗をSlackに表示できる。

**メリット 2: エラーが起きたら即座に中断できる**

10個のツールを順番に実行する途中で3個目がエラーになった場合、AsyncGenerator ならその時点で処理を中断できる。Promise 方式だと、残りの7個が全部終わるまで待たないとエラーに気付けない。

**メリット 3: メモリを節約できる**

全データを一度にメモリに保持する必要がない。AIが大量のツール実行を行うセッション（数百のメッセージ）でも、処理済みのメッセージはメモリから解放できる。

#### なぜ AbortController でタイムアウト制御するのか

AI 処理は数十秒〜数分かかることがある。**制限を設けないと、何らかの問題が起きた場合に無限に待ち続け、Slack Bot が応答不能になる。**

> **平たく言うと**: レストランで注文して30分待っても料理が来なかったら、「もう結構です」と言って帰れる仕組み。AbortController がないと、いつまでも料理を待ち続けることになり、その間は他のことが一切できなくなる。

```
■ AbortController ありの場合:
  ユーザーAがSlackで質問
  → AIが処理開始
  → 3分経っても終わらない
  → AbortControllerが強制終了
  → 「処理がタイムアウトしました。もう一度お試しください」とエラーメッセージを返す
  → ユーザーAは少なくとも応答を得られる
  → Slack Botは次のメッセージを受け付けられる

■ AbortController なしの場合:
  ユーザーAがSlackで質問
  → AIが処理開始
  → ネットワーク障害でAPIが応答しない
  → 5分経過...10分経過...
  → ユーザーAは何も応答を得られない
  → ユーザーBが質問しても、リソースが枯渇して応答が遅延する
```

AbortController は JavaScript 標準の仕組みで、`setTimeout` と組み合わせて「指定時間が経過したら処理を中断する」制御を実現する。

#### なぜ errorResult() で success: false を返すのか（throw しない理由）

Argus では、エラーが発生しても `throw new Error()` で例外を投げるのではなく、`{ success: false, message: "エラーの内容" }` という形で結果を返す。**なぜこうするのか？**

> **平たく言うと**: 1つの電話回線が故障しても、電話交換機全体が停止しないようにする仕組み。エラーを「報告」するだけで、システムは動き続ける。

**最大の理由: Slack Bot のプロセスを守る**

Slack Bot は Socket Mode で1本の WebSocket 接続を維持している。この接続は全ユーザーが共有する「1本の命綱」。もし未捕捉の例外（catch されない throw）でプロセスがクラッシュすると、**全ユーザーへの応答が停止する**。

```
■ throw 方式の場合（危険）:
  ユーザーAの質問でAI処理中にエラー発生
  → throw new Error("API timeout")
  → 呼び出し元が catch していない場合、未捕捉例外が発生
  → Node.js プロセスがクラッシュ
  → Socket Mode のWebSocket接続が切断
  → ユーザーB、C、Dも全員切断。ボット全体が停止。
  → PM2が再起動するまで数秒〜数十秒の完全停止

■ success: false 方式の場合（安全）:
  ユーザーAの質問でAI処理中にエラー発生
  → return { success: false, message: "タイムアウトしました" }
  → 呼び出し側は success: false を見て、ユーザーAにエラーメッセージを表示
  → ユーザーB、C、Dは通常通り使い続けられる
  → ボットは一切停止しない
```

**Go 言語の (result, error) パターンとの対比**:

```go
// Go 言語: 戻り値でエラーを返すのが標準
result, err := doSomething()
if err != nil {
    log.Printf("failed: %v", err)
    return  // エラー処理して続行
}
```

```typescript
// Argus（TypeScript）: Go と同じ思想
const result = await query(prompt);
if (!result.success) {
  console.error("failed:", result.message);
  return; // エラー処理して続行
}
```

この方式のもう1つのメリットは、**呼び出し側がエラー処理を「忘れにくい」** こと。`throw` 方式だと `try-catch` を書き忘れても TypeScript コンパイラは警告しない。しかし `success: boolean` を持つ戻り値なら、`result.success` を確認せずにデータにアクセスすると型エラーになるようにできる。

### 5.2 Argus の SDK ラッパー設計

`packages/agent-core/src/agent.ts` は SDK の薄いラッパー（包み紙のように SDK を薄く覆って使いやすくしたもの）。

> **平たく言うと**: SDK をそのまま使うと複雑なので、Argus 独自の「簡単な窓口」を 2 つだけ用意した。`query()`（新しい会話を始める）と `resume()`（前の会話を続ける）。この窓口の裏側で SDK と複雑なやり取りを行い、結果だけをきれいに返す。

**設計判断: なぜ薄いラッパーにしたか**

1. **SDK の進化に追従しやすい** — SDK がバージョンアップしても、ラッパーが薄ければ影響が少ない
2. **消費側の柔軟性** — slack-bot、orchestrator、dashboard がそれぞれ異なる `sdkOptions`（MCP サーバー、許可ツール等）を注入できる
3. **テストしやすい** — AsyncGenerator のモックだけで全ての消費パターンをテスト可能

> **もし厚いラッパー（多機能ラッパー）にしていたら**: SDK の API が変更されるたびに、ラッパーの大量のコードを書き直す必要がある。Agent SDK はまだ v0.x で頻繁にAPIが変わるため、薄いラッパーにしておくことで「SDK がバージョンアップしても変更は数行で済む」状態を維持できる。厚いラッパーに独自機能を詰め込むと、SDK のアップデートが「大工事」になり、追従を諦めてしまうリスクがある。

```typescript
// 公開 API はたった 2 関数
export async function query(
  prompt: string,
  options?: AgentOptions,
): Promise<AgentResult>;
export async function resume(
  sessionId: string,
  message: string,
  options?: AgentOptions,
): Promise<AgentResult>;
```

### 5.3 consumeSDKStream() — ストリーム消費の核心

```typescript
async function consumeSDKStream(
  stream: AsyncGenerator<SDKMessage, void>,
): Promise<AgentResult> {
  let sessionId: string | undefined;
  const contentBlocks: Block[] = [];
  const toolCalls: ToolCall[] = [];
  let costUsd = 0;
  let resultText = "";
  let isError = false;
  let hasResult = false;

  try {
    for await (const msg of stream) {
      switch (msg.type) {
        case "system":
          sessionId = msg.session_id;
          break;

        case "assistant":
          sessionId = msg.session_id;
          for (const block of msg.message.content) {
            if (block.type === "text") {
              contentBlocks.push({ type: "text", text: block.text });
            }
            if (block.type === "tool_use") {
              contentBlocks.push({
                type: "tool_use",
                name: block.name,
                input: block.input,
                tool_use_id: block.id,
              });
              toolCalls.push({
                name: block.name,
                input: block.input,
                status: "success",
              });
            }
          }
          break;

        case "result":
          costUsd = msg.total_cost_usd ?? 0;
          hasResult = true;
          if (msg.subtype === "success") {
            resultText = msg.result ?? "";
            isError = msg.is_error ?? false;
          } else {
            isError = true;
          }
          break;
      }
    }
  } catch (streamError) {
    // SDK が result 送信後に exit code 1 で終了するケースの回復
    if (hasResult) {
      console.warn("[agent-core] Process exited after result (ignoring)");
    } else {
      throw streamError;
    }
  }

  return {
    sessionId,
    message: {
      type: "assistant",
      content: contentBlocks,
      total_cost_usd: costUsd,
    },
    toolCalls,
    success: !isError,
  };
}
```

**注目ポイント**:

- `hasResult` フラグで「result メッセージ受信済みなのにプロセスが異常終了」というエッジケースに対応
- 例外を throw せず、常に `AgentResult` を返す設計（後述の設計原則参照）

**なぜ `hasResult` フラグが必要か（詳細）**:

SDK は子プロセスとして Claude Code CLI を起動する。稀に、SDK が正常に result メッセージを送信した **後に**、子プロセスが exit code 1（異常終了コード）で終了するケースがある。これは SDK 側のクリーンアップ処理の問題であり、Argus 側のエラーではない。

```
■ hasResult フラグなしの場合:
  stream から result メッセージを受信（AIの回答は正常に取得済み）
  → 子プロセスが exit code 1 で終了
  → for-await ループが例外を throw
  → catch ブロックで throw される
  → 正常な結果があるのに、エラーとして扱われてしまう
  → ユーザーには「エラーが発生しました」と表示される

■ hasResult フラグありの場合（Argus の実装）:
  stream から result メッセージを受信 → hasResult = true に設定
  → 子プロセスが exit code 1 で終了
  → for-await ループが例外を throw
  → catch ブロックで hasResult を確認
  → true なので「既に結果は取得済み」と判断し、例外を無視
  → ユーザーには正常な回答が表示される
```

> **平たく言うと**: 手紙の配達員が手紙を届けた後に転んだようなもの。手紙は届いているので、配達員が転んだことは無視して大丈夫。`hasResult` フラグは「手紙がちゃんと届いたか」を記録するための印。

### 5.4 Max Plan vs API キーの自動切り替え

```typescript
// macOS + CLI 存在 = Max Plan（API キー不要）
export function isMaxPlanAvailable(): boolean {
  if (process.platform !== "darwin") return false;
  return CLAUDE_CLI_PATHS.some((p) => existsSync(p));
}

// モデル自動選択
export function getDefaultModel(): string {
  if (isMaxPlanAvailable()) return "claude-opus-4-6"; // Max Plan → 最高品質
  return process.env.ANTHROPIC_API_KEY
    ? "claude-sonnet-4-5-20250929" // API → コスト効率
    : "claude-opus-4-6"; // ローカル → 最高品質
}
```

**なぜ `which` コマンドを使わないか**:

`which claude` コマンドで CLI の存在を確認する方法もあるが、Argus では `fs.existsSync()` で既知パスを直接チェックしている。

```
■ which コマンドを使った場合の問題:
  開発者のターミナルで `which claude` → /usr/local/bin/claude (見つかる)
  → PM2 経由でSlack Botが起動
  → PM2 の子プロセスのPATH環境変数はターミナルと異なる
  → `which claude` → command not found (見つからない!)
  → Max Plan が使えず、API キーモードにフォールバック
  → 意図せず従量課金が発生

■ fs.existsSync() を使った場合（Argus の実装）:
  Claude CLI の既知パス（/usr/local/bin/claude 等）を直接チェック
  → PATH環境変数に関係なく、ファイルの存在を確認
  → PM2 経由でもlaunchd経由でも同じ結果
  → 確実にMax Planを検出できる
```

> **平たく言うと**: 「あの人知ってますか？」と周りに聞く（which）のではなく、「あの人の家に直接行って確認する」（existsSync）方式。周りの人が知らなくても、家に行けば確実に分かる。

### 5.5 環境変数の制御 — envForSDKPublic()

SDK は子プロセスとして Claude Code CLI を起動する。親プロセスの環境変数がそのまま継承されると問題が起きる。**なぜ環境変数を除外する必要があるのか？**

> **平たく言うと**: 子どもを学校に送り出すとき、仕事用のIDカードやクレジットカードまで一緒に渡すと混乱する。「学校で必要なもの」だけを持たせるのが `envForSDKPublic()` の役割。

| 環境変数                 | Max Plan 時                            | API キー時   | 除外しないとどうなるか                                                       |
| ------------------------ | -------------------------------------- | ------------ | ---------------------------------------------------------------------------- |
| `ANTHROPIC_API_KEY`      | **除外**（ローカル接続を強制）         | そのまま渡す | Max Plan なのに API キーが使われ、意図せず従量課金が発生する                 |
| `CLAUDECODE`             | **除外**（CLI 自体の設定を汚染しない） | **除外**     | CLI が「自分は別のClaude Codeの子プロセスだ」と誤認し、設定が上書きされる    |
| `CLAUDE_CODE_ENTRYPOINT` | **除外**                               | **除外**     | エントリーポイントが親プロセスのものになり、意図しないモデルや設定が使われる |

```
■ 環境変数を除外しなかった場合の具体的な問題:
  開発者がClaude CodeのターミナルからArgusを起動
  → 親プロセス（Claude Code）の CLAUDECODE 環境変数が子プロセスに継承される
  → SDK が起動したCLIが「自分はClaude Codeのサブプロセスだ」と認識
  → 意図しないモデル設定やパーミッションが適用される
  → Argus が予期しない挙動をする
```

```typescript
function envForSDKPublic(): Record<string, string | undefined> | undefined {
  const {
    ANTHROPIC_API_KEY: _key,
    CLAUDECODE: _cc,
    CLAUDE_CODE_ENTRYPOINT: _cce,
    CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS: _ccat,
    ...rest
  } = process.env;

  if (!isMaxPlanAvailable()) {
    // API キーモード: CLAUDECODE 系のみ除外
    if (_cc || _cce || _ccat) {
      return { ...rest, ...(_key != null ? { ANTHROPIC_API_KEY: _key } : {}) };
    }
    return undefined; // クリーンなら継承
  }
  // Max Plan: API キーも除外してローカル接続を強制
  return rest;
}
```

### 5.6 フック（Hooks）の二層抽象化

> **平たく言うと**: 「フック」とは、特定のタイミングで自動的に呼ばれる処理のこと。例えば「AI がツールを使う直前」や「ツールを使った直後」に、自動的にログを記録したりチェックを入れたりできる。料理で言えば「材料を切る前に必ず手を洗う」ルールを自動化するようなもの。

SDK のフックは低レベル（細かすぎて扱いにくい）。Argus は二層にして消費側の負担を減らす。**なぜ 2 層にするのか？**

SDK のフック API は汎用性のために複雑で、消費側（slack-bot 等）が直接使うと以下の問題がある。

- **型キャストが必要**: SDK のフックは汎用的な型（`unknown` に近い）を使うため、`input as PostToolUseHookInput` のようなキャストが毎回必要。間違ったキャストをしてもコンパイルエラーにならず、実行時にクラッシュする危険がある
- **複雑なネスト構造**: SDK のフック定義は `{ PreToolUse: [{ hooks: [callback] }] }` のように3段階ネストしており、消費側のコードが読みにくくなる
- **SDK のバージョンアップの影響が全体に波及**: SDK のフック API が変更されたら、slack-bot、orchestrator、dashboard の全てを修正する必要がある

2 層にすることで、消費側は `ArgusHooks`（シンプル）だけを知っていればよく、SDK の複雑さは `buildSDKHooks()`（変換レイヤー）の中に閉じ込められる。SDK のフック API が変わっても、修正するのは変換レイヤーの 1 ファイルだけで済む。

```
消費側 (slack-bot)
  │
  │  ArgusHooks（シンプル）
  │  { onPreToolUse, onPostToolUse, onToolFailure }
  │
  ▼
buildSDKHooks() — 変換レイヤー
  │
  │  SDK HookCallbackMatcher[]（複雑）
  │  { PreToolUse: [{ hooks: [callback] }], ... }
  │
  ▼
SDK 内部
```

**消費側はこう書くだけ**:

```typescript
const hooks: ArgusHooks = {
  onPostToolUse: async ({ toolName, toolResult }) => {
    console.log(`${toolName} completed`);
  },
};
const result = await query("タスクを実行して", { hooks });
```

**SDK 直接だとこうなる**:

```typescript
const sdkHooks = {
  PostToolUse: [
    {
      hooks: [
        async (input, toolUseId, context) => {
          const postInput = input as PostToolUseHookInput;
          console.log(`${postInput.tool_name} completed`);
          return {};
        },
      ],
    },
  ],
};
```

`ArgusHooks` は型安全なイベントオブジェクトを渡すので、`input as PostToolUseHookInput` のような型キャストが不要になる。

### 5.7 MCP サーバーの接続パターン

> **平たく言うと**: MCP（Model Context Protocol）は、AI に「道具」を持たせるための規格。例えば「カレンダーを見る道具」「メールを送る道具」を MCP で定義すると、AI が必要に応じて自分でその道具を使える。USB のように「繋げば使える」標準規格のイメージ。

Argus では Knowledge、Gmail、Google Calendar を MCP サーバーとして実装している。

**なぜ REST API（従来の Web API）ではなく MCP か**:

REST API（従来の Web API）でもツール連携は可能だが、MCP を選んだ理由は「実装コストの低さ」と「再利用性の高さ」にある。

| 比較軸         | MCP                                                  | REST API                              |
| -------------- | ---------------------------------------------------- | ------------------------------------- |
| **SDK 統合**   | `mcpServers` に登録するだけ                          | 自前で HTTP クライアント + ツール定義 |
| **ツール定義** | `server.tool()` で宣言的                             | OpenAPI / JSON Schema を自前管理      |
| **型安全性**   | Zod スキーマで自動バリデーション                     | 自前バリデーション                    |
| **テスト**     | MCP クライアントでユニットテスト                     | HTTP モックが必要                     |
| **再利用性**   | 他の MCP クライアント（Claude Desktop 等）でも使える | Argus 専用                            |

**具体例: Knowledge MCP サーバーの登録**:

```typescript
// apps/slack-bot/src/session-manager.ts
const sdkOptions = {
  mcpServers: {
    knowledge: {
      type: "stdio",
      command: "node",
      args: ["../../packages/knowledge/dist/index.js"],
      env: { DATABASE_URL: process.env.DATABASE_URL },
    },
    "google-calendar": {
      type: "stdio",
      command: "node",
      args: ["../../packages/google-calendar/dist/index.js"],
      env: { DATABASE_URL: process.env.DATABASE_URL },
    },
  },
  allowedTools: [
    "mcp__knowledge__*", // Knowledge の全ツール
    "mcp__google-calendar__*", // Calendar の全ツール
  ],
};
```

エージェントは `mcp__knowledge__search_knowledge` のようなツール名で自動的にアクセスできる。

**もし REST API でツールを実装していたら**:

```
■ REST API の場合（実装が多い）:
  1. Express でエンドポイント定義（/api/knowledge/search, /api/calendar/events 等）
  2. エンドポイントごとにリクエスト/レスポンスの JSON Schema を定義
  3. HTTP クライアント（fetch / axios）でリクエストを送るツール定義を書く
  4. 認証ミドルウェア（API キー検証等）を自前で実装
  5. エラーハンドリング（HTTP ステータスコード → エラーメッセージ変換）を自前で実装
  6. SDK にツール定義（名前、説明、パラメータスキーマ）を登録
  → 各ツールごとに 100行以上のコードが必要

■ MCP の場合（Argus の実装）:
  1. server.tool("search_knowledge", { query: z.string() }, handler) と書くだけ
  2. SDK の mcpServers にパスを登録するだけで自動認識
  → 各ツール 10〜20行で完結
  → さらに Claude Desktop からも同じサーバーを使える（再利用性）
```

> **平たく言うと**: REST API は「工具を1つずつ手作り」するイメージ。MCP は「規格化された工具セット」を買ってきて「コンセントに繋ぐだけ」で使えるイメージ。しかも、同じ工具セットを別のワークベンチ（Claude Desktop 等）でも使い回せる。

### 5.8 テストでの SDK モック

```typescript
// fakeStream — AsyncGenerator を簡単に作るヘルパー
async function* fakeStream(
  messages: SDKMessage[],
): AsyncGenerator<SDKMessage, void> {
  for (const msg of messages) yield msg;
}

// テスト例: 正常系
it("should return text response", async () => {
  vi.mocked(sdkQuery).mockReturnValue(
    fakeStream([
      { type: "system", subtype: "init", session_id: "sess-1", ...defaults },
      {
        type: "assistant",
        session_id: "sess-1",
        message: {
          content: [{ type: "text", text: "Hello!" }],
          ...defaults,
        },
      },
      {
        type: "result",
        subtype: "success",
        session_id: "sess-1",
        result: "Hello!",
        total_cost_usd: 0.01,
        is_error: false,
        ...defaults,
      },
    ]) as unknown as Query,
  );

  const result = await query("Hi");
  expect(result.success).toBe(true);
  expect(result.sessionId).toBe("sess-1");
  expect(result.message.total_cost_usd).toBe(0.01);
});
```

**重要な注意**: `session_id` は全メッセージで一致させること。`result` メッセージが最後に `sessionId` を上書きするため、不一致だとテストが意図しない結果になる。

### この選定のメリット・デメリット

**メリット**:

- エージェントループ、ツール実行、セッション管理が全て組み込み
- MCP にネイティブ対応しており、外部ツール連携が容易
- Max Plan なら追加コストなしで運用可能
- `resume` で会話を継続でき、Slack のスレッドモデルと自然にマッチ

**デメリット・トレードオフ**:

- Claude 専用（モデルロックイン）— 将来 OpenAI や Gemini に切り替えるには全面書き換えが必要
- SDK が子プロセスとして CLI を起動するため、メモリ消費が大きい
- SDK のバージョンアップで breaking change（既存コードが動かなくなる破壊的変更）が起きる可能性（まだ v0.x）
- LangChain や Vercel AI SDK のようなマルチモデル対応がない

**もし LangChain を選んでいたら**:

LangChain はマルチモデル対応の汎用フレームワークで、Claude・GPT・Gemini を統一的に扱える。しかし Argus の要件には以下の点でミスマッチがあった。

- **マルチモデル対応の恩恵** — LangChain ならベンダーロックインを避け、将来別のモデルへの切り替えが容易になる。ただし Argus は Claude の能力に特化した設計であり、モデルを切り替えるメリットが薄い
- **MCP 連携の追加実装** — LangChain は MCP を標準機能としてサポートしていないため、MCP サーバーとの接続を自前で実装する必要がある。Agent SDK なら `mcpServers` オプションに登録するだけで済む
- **抽象化層のオーバーヘッド** — LangChain の Chain/Agent 抽象は汎用性のために複雑で、デバッグ時にレイヤーを掘り下げる必要がある。Agent SDK は Claude に特化しているため、挙動が予測しやすい
- **Claude の最新機能への追従遅れ** — Agent SDK は Anthropic 公式のため、Claude の新機能（extended thinking、新ツール等）に即座に対応する。LangChain ではコミュニティ対応を待つ必要がある

### 理解度チェック

- [ ] Q1: Agent SDK と Anthropic SDK の違いを 3 点説明できるか？（ヒント: 抽象レベル、ツール実行、セッション管理）
- [ ] Q2: consumeSDKStream() の `hasResult` フラグがなぜ必要かを説明できるか？（ヒント: SDK が result 送信後に exit code 1 で終了するケース）
- [ ] Q3: LangChain を選んでいたら何が違っていたか？（ヒント: MCP対応、抽象化オーバーヘッド、最新機能追従）
- [ ] Q4: AsyncGenerator で応答を受け取るメリットを 3 つ挙げられるか？（ヒント: リアルタイム処理、エラー時の中断、メモリ節約）
- [ ] Q5: AbortController によるタイムアウト制御がなぜ必要かを説明できるか？（ヒント: 無限待ち、応答不能、リソース枯渇）
- [ ] Q6: errorResult() で success: false を返す理由を説明できるか？（ヒント: Socket Mode接続、プロセスクラッシュ、全ユーザー影響）

---

## 6. パッケージ管理: なぜ pnpm か

> **このセクションで学ぶこと**:
>
> - モノレポとは何か、なぜ使うか
> - pnpm が npm / yarn と異なる点（幽霊依存の防止）
> - workspace プロトコルとディスク効率

### 背景（なぜ選ぶ必要があったか）

Argus は 12 パッケージから成るモノレポ。共通部品（`@argus/db`, `@argus/agent-core` 等）を複数のアプリ（slack-bot, dashboard, orchestrator）が共有する。パッケージマネージャの選択は、依存管理の安全性とビルド速度に直結する。

> **平たく言うと**: 「モノレポ」とは、複数のプログラム（Slack Bot、管理画面、スケジューラなど）を 1 つのフォルダにまとめて管理する方法。別々に管理するより、共通部品の共有やバージョン管理が楽になる。pnpm は npm や yarn と同じ「パッケージマネージャ」（ライブラリの管理ツール）だが、より厳密で高速。

### 選択肢の比較

| 比較軸                   | pnpm                                                                                                       | npm                                                              | yarn (v4/Berry)            | Bun                           |
| ------------------------ | ---------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------- | -------------------------- | ----------------------------- |
| **幽霊依存の防止**       | シンボリックリンク（ファイルやフォルダへの"ショートカット"のようなもの）で厳密分離                         | ホイスティング（依存を上の階層にまとめる仕組み）で幽霊依存が発生 | PnP モードで防止可能       | ホイスティング（npm 互換）    |
| **ディスク効率**         | Content-addressable store（ファイルの中身からアドレスを決め、同じ中身は1つだけ保存する方式）               | 各プロジェクトにコピー                                           | PnP なら node_modules 不要 | 各プロジェクトにコピー        |
| **workspace プロトコル** | `workspace:*` で成熟                                                                                       | v7+ で対応                                                       | 対応                       | 対応                          |
| **インストール速度**     | 高速（ハードリンク（同じファイルの実体を複数の場所から参照する仕組み。コピーと違いディスクを消費しない）） | 中程度                                                           | 高速（PnP）                | 最速                          |
| **エコシステム互換性**   | 高い                                                                                                       | 最も高い                                                         | PnP で互換性問題あり       | 一部非互換（native addon 等） |
| **Node.js 互換性**       | 完全互換                                                                                                   | 完全互換                                                         | 完全互換                   | 独自ランタイム（一部非互換）  |
| **モノレポ支援**         | `--filter` が強力                                                                                          | workspaces 基本対応                                              | workspaces 対応            | workspaces 対応               |
| **成熟度**               | 安定（v8+）                                                                                                | 最も成熟                                                         | 安定だが PnP 移行コスト高  | 急成長中だがまだ若い          |

### 決定: pnpm

**一言で**: 厳密な依存管理（幽霊依存の防止）+ ディスク効率 + ワークスペースプロトコルの成熟度。

**幽霊依存（Phantom Dependencies）問題**:

> **平たく言うと**: 「幽霊依存」とは、自分が使っていないはずのライブラリが、たまたま隣のプログラムがインストールしたおかげで動いてしまう問題。本番環境で突然動かなくなる原因になる。pnpm はこれを厳密に防ぐ。

```
# npm の場合
@argus/slack-bot が drizzle-orm を使いたい
→ @argus/db が drizzle-orm をインストール済み
→ npm のホイスティングにより、slack-bot からも import できてしまう
→ slack-bot の package.json には drizzle-orm がない = 幽霊依存
→ @argus/db を外したら、slack-bot が壊れる（原因特定が困難）
```

```
# pnpm の場合
→ pnpm はシンボリックリンクで厳密に分離
→ slack-bot の package.json に drizzle-orm がなければ import できない
→ 幽霊依存が起きない
```

**workspace プロトコル**:

```json
// apps/slack-bot/package.json
{
  "dependencies": {
    "@argus/agent-core": "workspace:*",
    "@argus/db": "workspace:*"
  }
}
```

`workspace:*` により、常にローカルのパッケージを参照。npm publish 時には自動的にバージョン番号に置換される。

**ディスク効率**: pnpm は **Content-addressable store** (`~/.pnpm-store/`) を使い、同じパッケージの同じバージョンは 1 回しか保存しない。12 パッケージが同じバージョンの `drizzle-orm` を使っていても、ディスク上は 1 コピー。

### この選定のメリット・デメリット

**メリット**:

- 幽霊依存を構造的に防止（「ローカルでは動くが CI で壊れる」事故を防止）
- ディスク使用量を大幅に削減
- `--filter` コマンドで特定パッケージだけビルド・テストが可能

**デメリット・トレードオフ**:

- npm と比べて知名度が低く、新規メンバーの学習コストがある
- 一部のパッケージがシンボリックリンク構成で動かないことがある（稀）
- Bun ほどのインストール速度は出ない

**yarn PnP（Plug'n'Play）モードの補足**:

yarn v2 以降（Berry）では PnP モードが導入された。従来の `node_modules/` ディレクトリを廃止し、`.pnp.cjs` という 1 つのファイルで全ての依存関係を解決する仕組み。

- **仕組み**: `node_modules/` を作らず、`.pnp.cjs` が「どのパッケージがどこにあるか」のマッピングを保持する。パッケージ自体は `.yarn/cache/` に zip として格納される
- **メリット**: ゼロインストール（`yarn install` 不要で `git clone` 直後から動く）、起動高速化（`node_modules` のファイルシステム探索が不要）、ディスク効率
- **デメリット**: IDE 対応に追加設定が必要（VS Code では `@yarnpkg/sdks` の実行が必要）、ネイティブモジュール（C++ アドオン等）との互換性問題、既存プロジェクトからの移行コストが高い、一部の npm パッケージが PnP 環境で動作しない

pnpm はシンボリックリンク方式で `node_modules/` 構造を維持するため、PnP のような互換性問題が起きにくい。

**Bun を選ばなかった理由**:

Bun はインストール速度が最速だが、Argus では以下の理由で採用を見送った。

- **幽霊依存を防げない** — Bun は npm 互換のホイスティングを採用しており、pnpm のような厳密な依存分離ができない。12 パッケージのモノレポでは幽霊依存のリスクが高い
- **独自ランタイムの Node.js 非互換リスク** — Bun は独自ランタイムであり、Node.js の API を全て再実装している。一部の Node.js API（`node:vm`, `node:worker_threads` 等）の挙動が異なる場合があり、Claude Agent SDK のような Node.js 依存のライブラリで問題が発生しうる
- **エコシステムの成熟度不足** — npm や pnpm と比べて歴史が浅く、エッジケースでのバグ報告がまだ多い
- **native addon の互換性** — C++ で書かれたネイティブモジュール（例: `better-sqlite3`）が Bun で動作しないケースがある

### 理解度チェック

- [ ] Q1: 幽霊依存が起きる原理と pnpm がそれをどう防ぐかを説明できるか？
- [ ] Q2: yarn PnP モードのメリットとデメリットを説明できるか？
- [ ] Q3: Bun を選ばなかった理由を説明できるか？

---

## 7. Slack Bot: なぜ Bolt (Socket Mode) か

> **このセクションで学ぶこと**:
>
> - Socket Mode と Webhook Mode の違い
> - AI エージェント処理における通信方式の制約
> - Bolt を選んだ理由と代替ライブラリとの比較

### 背景（なぜ選ぶ必要があったか）

Argus の Slack Bot は AI エージェント処理を行うため、1 つのリクエストに数十秒〜数分かかることがある。通信方式の選択は、この長時間処理への対応が最も重要な判断基準だった。

> **平たく言うと**: Slack Bot の通信方式には「Webhook Mode」（Slack からサーバーに電話をかけてもらう方式）と「Socket Mode」（こちらから Slack に常時電話を繋ぎっぱなしにする方式）がある。AI の処理は数分かかることもあるため、3秒以内に応答しないといけない Webhook Mode は不向き。Socket Mode なら「受け取りました」と即答して、裏で時間をかけて処理できる。

### 選択肢の比較

| 比較軸                   | Bolt (Socket Mode)         | Bolt (Webhook Mode)      | slack-api 直接 | Discord.js (参考) |
| ------------------------ | -------------------------- | ------------------------ | -------------- | ----------------- |
| **長時間処理**           | `ack()` 後に非同期処理可能 | 3 秒以内にレスポンス必須 | 自前で実装     | 問題なし          |
| **HTTPS エンドポイント** | 不要                       | 必要（SSL 証明書管理）   | 必要           | 不要（Gateway）   |
| **開発環境**             | ローカルでそのまま動作     | ngrok 等のトンネル必要   | トンネル必要   | そのまま動作      |
| **イベントパターン**     | `app.message()` 等が強力   | 同じ                     | 自前でパース   | 同等の API        |
| **公式サポート**         | Slack 公式 SDK             | Slack 公式 SDK           | 低レベル API   | Discord 専用      |
| **再接続処理**           | 組み込み                   | N/A（HTTP）              | 自前           | 組み込み          |
| **VPS / サーバーレス**   | VPS 向き（常駐プロセス）   | サーバーレスでも可能     | どちらでも     | VPS 向き          |

### 決定: Bolt 4 (Socket Mode)

```
Webhook Mode:
  Slack → HTTPS → (Cloudflare Tunnel →) Express → Bolt
  → HTTPS エンドポイントの公開が必要
  → SSL 証明書の管理が必要
  → 3 秒以内にレスポンスしないと再送される

Socket Mode:
  Slack ← WebSocket → Bolt
  → ポートの公開不要
  → 長時間処理も問題なし（acknowledge 後に非同期処理）
  → VPS でもローカル開発でも同じコードで動く
```

エージェント処理は数十秒〜数分かかるため、Webhook の 3 秒制限は厳しい。Socket Mode なら `ack()` した後にゆっくり処理できる。

**なぜ Bolt か**:

- Slack 公式 SDK。コミュニティ製ライブラリより安定
- Socket Mode で **インバウンド HTTP 不要**（Webhook URL を公開しなくていい）
- `app.message()`, `app.event()`, `app.command()` のパターンマッチが強力

### この選定のメリット・デメリット

**メリット**:

- 長時間の AI 処理に対応（3 秒制限なし）
- HTTPS エンドポイント不要で運用が簡単
- ローカル開発と本番で同じコードが動く

**デメリット・トレードオフ**:

- 常駐プロセスが必要（サーバーレスでは動かない）
- WebSocket 接続の管理が必要（切断時の再接続等）
- Webhook Mode と比べてスケールアウトが複雑（複数インスタンス時のラウンドロビン配信）

**Socket Mode で複数インスタンスを動かすとどうなるか**:

Socket Mode では、複数のインスタンス（サーバー）がそれぞれ Slack と WebSocket 接続を張ると、Slack はメッセージを **ラウンドロビン配信**（各サーバーに順番に振り分ける方式：A→B→C→A→B→C...）する。つまり、ユーザーAのスレッド内のメッセージが「1通目はサーバーA」「2通目はサーバーB」に振られる可能性がある。セッション情報（会話の文脈）をサーバーのメモリに保持している場合、2通目のサーバーBには文脈がないため、会話が途切れてしまう。対策として、セッション情報をデータベースに保持し、どのサーバーが処理しても同じ結果になるようにする（ステートレス設計）必要がある。

### 理解度チェック

- [ ] Q1: Socket Mode と Webhook Mode の違いを説明できるか？
- [ ] Q2: なぜ AI エージェント処理に Webhook Mode が不向きかを説明できるか？
- [ ] Q3: Socket Mode で複数インスタンスを動かすとどうなるかを説明できるか？

---

## 8. Dashboard: なぜ Next.js か

> **このセクションで学ぶこと**:
>
> - SSR（Server-Side Rendering）/ SSG（Static Site Generation）/ SPA（Single Page Application）の違いと使い分け
> - Server Components がなぜ管理画面に適しているか
> - 他のフレームワークとの比較

### 背景（なぜ選ぶ必要があったか）

Argus の Dashboard はセッション監視、ナレッジ管理、エージェント実行ログの閲覧を行う管理画面。サーバーサイドからデータベースに直接アクセスし、結果を表示するのが主な用途。

> **平たく言うと**: 管理画面を作るための「フレームワーク」（開発の土台）を選ぶ話。Next.js の **Server Components** は「サーバー側でデータを取得して、完成したページをブラウザに送る」仕組み。従来の SPA（Single Page Application: ブラウザ側でデータを取得して画面を組み立てる方式）と違い、ブラウザが重い処理をしなくて済むので表示が速い。

### 選択肢の比較

| 比較軸                 | Next.js 16                         | Vite + React Router                       | Remix                           | SvelteKit                         |
| ---------------------- | ---------------------------------- | ----------------------------------------- | ------------------------------- | --------------------------------- |
| **データ取得**         | Server Components で DB 直アクセス | API エンドポイント + クライアントフェッチ | loader でサーバーサイドフェッチ | load 関数でサーバーサイドフェッチ |
| **API エンドポイント** | 不要（Server Components 内で完結） | 別途構築が必要                            | action/loader で統合            | +server.ts で統合                 |
| **Docker 最適化**      | `output: "standalone"`             | 自前で設定                                | 自前で設定                      | adapter-node                      |
| **型安全ルーティング** | `typedRoutes: true`                | react-router v7 で対応                    | v7 で対応                       | 型安全                            |
| **React エコシステム** | 完全互換                           | 完全互換                                  | 完全互換                        | Svelte 独自                       |
| **学習コスト**         | 中程度（App Router の理解が必要）  | 低い                                      | 中程度                          | 高い（Svelte 学習が必要）         |
| **SSR/SSG**            | 両方対応                           | SPA のみ（SSR は別途設定）                | SSR 対応                        | SSR/SSG 両対応                    |
| **デプロイ**           | Vercel 最適化 / standalone         | 静的ファイル配信                          | どこでも                        | どこでも                          |

### 決定: Next.js 16

**なぜ Next.js か**:

- **App Router + Server Components** でデータフェッチが簡単 — Server Components でサーバーサイドから DB 直アクセスすれば、API エンドポイントを別途作る必要がない
- `output: "standalone"` で Docker に最適化
- `typedRoutes: true` でルーティングが型安全

**なぜ Vite + React Router ではないか**:

- SPA だと API エンドポイント + CORS（異なるドメイン間でのデータやり取りを許可する設定）設定 + クライアントサイドフェッチの実装が必要
- Server Components で完結する方がコード量が少ない

**なぜ SvelteKit ではないか**:

- チームの React 経験を活かせる
- React エコシステム（Testing Library, Tailwind 統合等）がそのまま使える

**SvelteKit が適しているケース**:

- **パフォーマンス最重視の消費者向けアプリ** — Svelte はコンパイル時に最適化された vanilla JS を出力するため、ランタイムのオーバーヘッドが極めて小さい。ECサイトやメディアサイトなどの Core Web Vitals が重要な場面で威力を発揮する
- **バンドルサイズを最小化したい** — React のランタイム（約 40KB gzip）が不要で、送信するJSの量を最小限に抑えられる
- **React エコシステムに依存しない** — 既存の React コンポーネントライブラリやテストツールを使わない新規プロジェクトで、技術選定に制約がない場合
- **開発者体験を重視する新規プロジェクト** — Svelte のリアクティビティ（データの変更を検知して画面を自動的に再描画する仕組み）構文はシンプルで、ボイラープレート（定型的なコード）が少ない

### この選定のメリット・デメリット

**メリット**:

- Server Components で API レイヤーが不要
- Docker standalone モードでイメージサイズが最適化
- React エコシステムの豊富なライブラリがそのまま使える

**デメリット・トレードオフ**:

- App Router の学習コストが高い（Server / Client Components の境界理解が必要）
- Vercel 以外へのデプロイは standalone モードの設定が必要
- バンドルサイズは Vite + React Router の SPA より大きくなりがち

### 理解度チェック

- [ ] Q1: Server Components が管理画面に適している理由を説明できるか？
- [ ] Q2: SPA（Vite + React Router）と比べた Next.js の利点を説明できるか？
- [ ] Q3: どんなプロジェクトなら SvelteKit の方が適しているか？

---

## 9. API サーバー: なぜ Express か

> **このセクションで学ぶこと**:
>
> - API サーバーフレームワークの選定基準
> - Express 5 の async/await 標準搭載
> - 薄い API サーバーにおけるフレームワーク選択の考え方

### 背景（なぜ選ぶ必要があったか）

Orchestrator は 4 つのエンドポイント + Cron スケジューラ（指定した時刻に自動でプログラムを実行する仕組み）という薄い API サーバー。フレームワークの高機能さよりも、シンプルさとエコシステムの広さが重要だった。

### 選択肢の比較

| 比較軸               | Express 5                                                                                  | Hono                       | Fastify                        | NestJS                                                                           |
| -------------------- | ------------------------------------------------------------------------------------------ | -------------------------- | ------------------------------ | -------------------------------------------------------------------------------- |
| **async/await 対応** | ネイティブ（v5 で標準搭載）                                                                | ネイティブ（標準搭載）     | ネイティブ（標準搭載）         | ネイティブ（標準搭載）                                                           |
| **パフォーマンス**   | 中程度                                                                                     | 高い（Edge 最適化）        | 高い（Express の 2-3 倍）      | 中程度（Express ベース）                                                         |
| **エコシステム**     | 最大（ミドルウェア（リクエストとレスポンスの間で認証・ログ等の共通処理を行う部品）が豊富） | 成長中                     | 中程度                         | 大きい（エンタープライズ向け）                                                   |
| **学習コスト**       | 最低（ほぼ全員が知っている）                                                               | 低い                       | 低い                           | 高い（DI（依存性注入）, デコレータ（@記号で機能を付加する記法））                |
| **型安全性**         | 基本的（@types/express）                                                                   | 優秀（型付きルーティング） | 良い（スキーマバリデーション） | TypeScript ネイティブ（TypeScript で書かれているため型安全が最初から保証される） |
| **最適環境**         | 汎用                                                                                       | Edge / Cloudflare Workers  | 高スループット API             | 大規模エンタープライズ                                                           |
| **設定量**           | 最小                                                                                       | 最小                       | 中程度（プラグインシステム）   | 多い（モジュール構成）                                                           |
| **バンドルサイズ**   | 小さい                                                                                     | 最小                       | 中程度                         | 大きい                                                                           |

### 決定: Express 5

**Express 5 の主な変更点（Express 4 との違い）**:

Express 5 は長年 beta だったが、2024 年に正式リリースされた。Express 4 からの主な変更点は以下の通り。

- **async/await のエラーハンドリングが標準搭載** — async ルートハンドラで throw されたエラーが自動的にエラーハンドリングミドルウェアに渡される。v4 では async 関数内のエラーを手動で `next(err)` に渡す必要があった
- **`next(err)` パターンが不要** — 上記により、`try { ... } catch (err) { next(err) }` というボイラープレートが不要になった
- **パスマッチングエンジンの改善** — `path-to-regexp` がアップグレードされ、`/user/:id` のようなパスパラメータの解析がより厳密に。正規表現ベースのルートにも改善あり
- **非推奨メソッドの削除** — `app.del()`（`app.delete()` の旧エイリアス）、`req.param()`、`res.json(obj, status)` 等の非推奨 API が削除された
- **`req.query` のパーサー変更** — デフォルトのクエリパーサーが変更され、`?a[b]=c` のようなネストされたオブジェクト解析の挙動が異なる

**なぜ Express か**:

- 4 つのエンドポイント + Cron スケジューラという薄い API に対して、Express 5 の async/await 標準搭載で十分
- エコシステムが最大（ミドルウェアの選択肢が豊富）
- Express 5 は v4 の `next(err)` パターンが不要

**なぜ Hono ではないか**:

- Hono は Edge / Cloudflare Workers に最適化されている
- Argus の Orchestrator は Railway VPS の Docker 上で動くので、Edge 最適化は不要
- Hono の型システムは優秀だが、4 エンドポイントではその恩恵が薄い

**なぜ Fastify ではないか**:

- Fastify の強みは高スループット（ベンチマーク上 Express の 2〜3 倍）
- Orchestrator の負荷は低い（Cron + 管理 API）ため、パフォーマンス差が問題にならない

**なぜ NestJS ではないか**:

- NestJS はエンタープライズ向けの大規模フレームワーク
- 4 エンドポイントに対してモジュール構成、DI コンテナ、デコレータは過剰

### この選定のメリット・デメリット

**メリット**:

- 最も広く知られたフレームワークで、新規メンバーの学習コストがゼロ
- Express 5 で async/await が標準搭載され、エラーハンドリングが簡潔に
- ミドルウェアのエコシステムが最も充実

**デメリット・トレードオフ**:

- Hono / Fastify と比べてパフォーマンスが劣る（ただし Orchestrator の負荷では問題にならない）
- 型安全性は Hono に劣る（4 エンドポイントでは影響が小さい）
- フレームワーク自体の革新性は低い

### 理解度チェック

- [ ] Q1: Express 5 と Express 4 の主な違いを説明できるか？
- [ ] Q2: Hono が Express より適しているのはどんなケースか？
- [ ] Q3: NestJS を選ぶべきプロジェクトの特徴を説明できるか？

---

## 10. テスト: なぜ Vitest か

> **このセクションで学ぶこと**:
>
> - ESM 環境でのテストフレームワーク選択の課題
> - Vitest と Jest の具体的な違い
> - テストコロケーションの考え方

### 背景（なぜ選ぶ必要があったか）

Argus は完全 ESM（ECMAScript Modules: `import/export` を使う現代的な JavaScript のモジュール方式）プロジェクト。テストフレームワークも ESM に標準対応（追加設定なしで ESM をそのまま扱える）している必要がある。1,200 以上のテストを高速に実行できることも重要な要件。

> **平たく言うと**: ESM と CJS（CommonJS: `require()` を使う旧来の方式）は、JavaScript のファイルを分割・共有する2つの方式。ESM が現在の標準で、CJS は過去の方式。ESM で書かれたプロジェクトに CJS 前提のテストツールを使おうとすると、「新しい規格の電化製品を古い規格のコンセントに繋ぐ」ような互換性問題が起きる。

### 選択肢の比較

| 比較軸              | Vitest 4                                                                              | Jest                                         | Mocha                   | node:test        |
| ------------------- | ------------------------------------------------------------------------------------- | -------------------------------------------- | ----------------------- | ---------------- |
| **ESM 対応**        | 標準搭載（設定不要）                                                                  | `--experimental-vm-modules` が必要（不安定） | 対応だが設定が必要      | 標準搭載         |
| **TypeScript 対応** | 設定不要（Vite 経由）                                                                 | ts-jest / babel-jest が必要                  | 別途設定                | tsx 等が必要     |
| **API 互換性**      | Jest 互換（`describe`, `it`, `expect`）                                               | -                                            | `describe`, `it` + chai | 独自 API         |
| **実行速度**        | 高速（Vite のモジュール解決）                                                         | 中程度                                       | 中程度                  | 高速             |
| **Watch モード**    | 高速（HMR（Hot Module Replacement: 変更したファイルだけ即座に反映する仕組み）ベース） | 中程度                                       | 対応                    | `--watch`        |
| **モック**          | `vi.mock()` 組み込み                                                                  | `jest.mock()` 組み込み                       | sinon 等が必要          | 組み込み mock    |
| **ブラウザテスト**  | `environment: "jsdom"` 1行                                                            | jest-environment-jsdom                       | jsdom 設定必要          | 非対応           |
| **エコシステム**    | 急成長中                                                                              | 最大                                         | 長い歴史                | Node.js 組み込み |
| **設定量**          | 最小                                                                                  | 中程度（ESM の場合は多い）                   | 中程度                  | 最小             |

### 決定: Vitest 4

**一言で**: ESM 標準対応 + 高速 + Jest 互換 API。

**ESM 問題の具体例**:

```
# Jest で ESM プロジェクトをテストしようとすると:
$ npx jest

SyntaxError: Cannot use import statement outside a module
# → --experimental-vm-modules フラグが必要
# → 不安定で、テストが落ちることがある
# → transform 設定（babel-jest, ts-jest）が複雑

# Vitest なら:
$ npx vitest
# → そのまま動く（ESM 標準対応）
```

**テストコロケーション**:

```
packages/agent-core/src/
  ├── agent.ts
  ├── query.test.ts        ← テストが隣にある
  ├── hooks.ts
  ├── hooks.test.ts
  ├── text-utils.ts
  └── text-utils.test.ts
```

ファイルを開くと、すぐ隣にテストがある。`__tests__/` ディレクトリに分離するパターンより、関連ファイルを見つけやすい。

**Dashboard のテスト設定**:

```typescript
// apps/dashboard/vitest.config.ts
import { defineConfig } from "vitest/config";

export default defineConfig({
  test: {
    environment: "jsdom", // ブラウザ環境エミュレーション
    globals: true, // describe, it, expect をグローバルに
    setupFiles: ["./vitest.setup.ts"],
  },
});
```

React コンポーネントテストには `@testing-library/react` + `jsdom` を使用。Vitest は `environment: "jsdom"` の 1 行で設定完了。

### この選定のメリット・デメリット

**メリット**:

- ESM に標準対応しており設定不要
- Jest 互換 API で移行コストが低い
- Vite ベースの高速な Watch モード

**デメリット・トレードオフ**:

- Jest と比べてエコシステム（プラグイン、情報量）がまだ小さい
- node:test と比べて外部依存が増える
- Vitest 固有のバグに遭遇する可能性がある（まだ比較的新しい）

**node:test が適しているケース**:

- **外部依存ゼロを目指す場合** — node:test は Node.js に組み込まれているため、`devDependencies` にテストフレームワークを追加する必要がない。依存の少なさがセキュリティやメンテナンス性に直結するプロジェクトに向いている
- **ライブラリ開発で依存を最小化したい** — npm パッケージとして公開するライブラリでは、依存が少ないほどインストールが軽く、バージョン競合のリスクが減る
- **シンプルなユニットテストのみ** — ブラウザ環境エミュレーション（jsdom）やスナップショットテストが不要で、純粋な関数やモジュールのテストだけで十分な場合
- **Node.js 標準に準拠したい** — Node.js 公式のテストランナーに合わせておくことで、将来のエコシステム変化に左右されにくくなる

Argus では jsdom 環境でのコンポーネントテスト、Watch モード、Jest 互換 API が必要だったため、node:test では機能不足だった。

### 理解度チェック

- [ ] Q1: ESM プロジェクトで Jest が問題になる理由を説明できるか？
- [ ] Q2: テストコロケーションのメリットを説明できるか？
- [ ] Q3: node:test を選んだ方がいいのはどんなケースか？

---

## 11. ホスティング: なぜ Railway + Supabase か

> **このセクションで学ぶこと**:
>
> - 常駐プロセスとサーバーレスの違い
> - 個人/インハウスプロジェクトのコスト最適化戦略
> - Docker + PM2 によるマルチプロセス管理

### 背景（なぜ選ぶ必要があったか）

Argus は 3 つの常駐プロセス（Slack Bot, Orchestrator, Dashboard）を 24 時間動かす必要がある。**「個人/インハウスプロジェクトのコスト最適化」** が最優先。

> **平たく言うと**: 「インフラ」とは、プログラムを動かすための土台。自分のパソコンではなくクラウド（インターネット上のサーバー）で 24 時間動かすために、どのサービスを使うかを選ぶ。家で言えば「どの土地に建てるか」「電気・水道はどの会社にするか」に相当する。

### 選択肢の比較

| 比較軸               | Railway                               | Vercel                 | Fly.io          | Render            | AWS (EC2 + RDS) |
| -------------------- | ------------------------------------- | ---------------------- | --------------- | ----------------- | --------------- |
| **常駐プロセス**     | Docker で自由                         | サーバーレス（不可）   | VM で可能       | 可能              | 完全自由        |
| **Socket Mode**      | 問題なし                              | WebSocket 制限         | 可能            | 可能              | 問題なし        |
| **PM2 (3プロセス)**  | Docker 内で自由                       | 不可                   | Procfile で可能 | 不可              | 自由            |
| **料金**             | $5/月〜                               | Hobby 無料だが常駐不可 | $1.94/月〜      | $7/月〜           | $15/月〜        |
| **Docker サポート**  | 標準搭載（Docker をそのまま動かせる） | なし                   | Dockerfile 対応 | Dockerfile 対応   | 完全対応        |
| **デプロイ**         | `git push` で自動                     | `git push` で自動      | `fly deploy`    | `git push` で自動 | 手動 or CI/CD   |
| **DB マネージド**    | なし（外部利用）                      | Postgres（Neon）       | Postgres 内蔵   | Postgres 内蔵     | RDS             |
| **運用負荷**         | 低い                                  | 最低                   | 中程度          | 低い              | 高い            |
| **スケーラビリティ** | 垂直スケール                          | 自動スケール           | 水平スケール    | 垂直スケール      | 完全自由        |

### 決定: Railway + Supabase

**決め手**: Slack Bot (Socket Mode) + Orchestrator (Cron) + Dashboard (Next.js) の 3 つの常駐プロセスを 1 つの VPS で PM2 管理できる。Vercel は常駐プロセスが動かせないので不可。

**なぜ Fly.io ではなく Railway か**:

Fly.io は料金が Railway より安い（$1.94/月〜）が、以下の点で Railway を選んだ。

- **Docker デプロイの簡単さ** — Railway は Dockerfile を置いて `git push` するだけで自動デプロイされる。Fly.io は `fly.toml` の設定ファイルでリージョン、VM サイズ、ヘルスチェック等を自前で定義し、`fly deploy` コマンドを実行する必要がある
- **GitHub 連携の自動デプロイ** — Railway は GitHub リポジトリと連携するだけで、push 時に自動でビルド・デプロイが走る。Fly.io では GitHub Actions 等の CI パイプラインを自前で構築する必要がある
- **PM2 との相性** — Railway の Docker 環境では PM2 がそのまま動作する。Fly.io は Procfile ベースのプロセス管理が推奨されており、PM2 の全機能（ログ管理、クラスタモード等）を活用するには追加設定が必要
- **運用のシンプルさ** — Fly.io はリージョン管理（マルチリージョン対応）やボリューム管理など、より細かい制御が可能だが、個人プロジェクトではその複雑さがオーバーヘッドになる

### インフラ構成図

```
┌──────────────┐     ┌──────────────────┐
│   Slack API   │────▶│  Railway VPS     │
│  (WebSocket)  │     │  ┌────────────┐  │
└──────────────┘     │  │  PM2       │  │
                      │  │ ┌─────────┐│  │
                      │  │ │slack-bot ││  │──▶ Supabase PostgreSQL
                      │  │ ├─────────┤│  │
                      │  │ │dashboard ││  │──▶ Cloudflare R2
                      │  │ ├─────────┤│  │
┌──────────────┐     │  │ │orchestr. ││  │──▶ Google API (Gmail, Calendar)
│  Cloudflare   │────▶│  │ └─────────┘│  │
│  Tunnel       │     │  └────────────┘  │
└──────────────┘     └──────────────────┘
```

### Docker 2 段階ビルド（マルチステージビルド）

> **平たく言うと**: Docker の 2 段階ビルド（マルチステージビルド）は、「調理場で料理を作ってから、完成品だけをお客さんのテーブルに運ぶ」イメージ。調理場（Stage 1）には包丁や鍋（ビルドツール）が必要だが、テーブル（Stage 2）には完成した料理（ビルド成果物）だけがあればいい。こうすることで、最終的なパッケージ（Docker イメージ）が軽くなる。

```dockerfile
# Stage 1: ビルド
FROM node:22-alpine AS builder
WORKDIR /app
COPY . .
RUN corepack enable && corepack prepare pnpm@10.23.0 --activate
RUN pnpm install --frozen-lockfile
RUN pnpm build

# Stage 2: 本番
FROM node:22-alpine
WORKDIR /app
# PM2 + Claude Code CLI をインストール
RUN npm install -g pm2
# 本番依存のみコピー
COPY --from=builder /app .
RUN pnpm install --prod --frozen-lockfile
CMD ["pm2-runtime", "ecosystem.config.cjs"]
```

**2 段階ビルドのメリット**:

- **イメージサイズ削減** — Stage 1（builder）にはビルドツール（TypeScript コンパイラ、pnpm、devDependencies）が含まれるが、Stage 2（本番）にはコピーされない。ビルド成果物と本番依存のみが最終イメージに残るため、イメージサイズが大幅に小さくなる
- **攻撃対象面の縮小** — 最終イメージにコンパイラや開発ツールが含まれないため、仮にコンテナが侵害されても、ビルドツールを悪用される危険性が下がる
- **ビルドキャッシュの効率化** — Docker はレイヤー単位でキャッシュするため、依存が変わらなければ `pnpm install` のレイヤーが再利用される。2 段階に分けることで、本番イメージのキャッシュヒット率も上がる

**alpine を使う理由**: イメージサイズが ~50MB（debian ベースだと ~300MB）。Railway の料金はストレージにも依存するため、小さいほうがいい。

### Cloudflare Tunnel + Access

```
ユーザー → Cloudflare Access（メール認証）→ Cloudflare Tunnel → Railway VPS
```

- **Tunnel**: VPS のポートを公開せずに HTTPS アクセスを提供
- **Access**: メールアドレスベースのゼロトラスト認証（「社内ネットワークだから安全」と信用せず、毎回本人確認する方式。無料 50 ユーザーまで）
- Dashboard にアクセスする前に Cloudflare のログイン画面が表示される

### この選定のメリット・デメリット

**メリット**:

- 月額 $5 程度で 3 プロセスを常時稼働
- `git push` で自動デプロイ
- Docker で環境を完全に再現可能

**デメリット・トレードオフ**:

- 単一 VPS なので、サーバーダウン時に全サービスが停止する
- Vercel のような自動スケールはない
- Railway の無料枠は月 500 時間（常駐には足りないので有料プラン必須）

### 理解度チェック

- [ ] Q1: 常駐プロセスが必要なアプリに Vercel が不向きな理由を説明できるか？
- [ ] Q2: Docker 2 段階ビルドのメリットを説明できるか？
- [ ] Q3: Fly.io ではなく Railway を選んだ理由を説明できるか？

---

## 12. ストレージ: なぜ Cloudflare R2 か

> **このセクションで学ぶこと**:
>
> - オブジェクトストレージの選択基準
> - エグレスコスト（データ転送料）の重要性
> - S3 互換 API の利点

### 背景（なぜ選ぶ必要があったか）

Argus は動画・画像・音声ファイルを保存・配信する必要がある。特に動画配信ではデータ転送量が大きくなるため、エグレスコスト（サーバーからインターネットに出ていくデータの転送料）が重要な選定基準となる。

### 選択肢の比較

| 比較軸             | Cloudflare R2                    | AWS S3                | Google Cloud Storage (GCS) | MinIO (自前)       |
| ------------------ | -------------------------------- | --------------------- | -------------------------- | ------------------ |
| **ストレージ料金** | $0.015/GB/月                     | $0.023/GB/月          | $0.020/GB/月               | サーバー費用のみ   |
| **エグレス料金**   | **無料**                         | $0.09/GB              | $0.12/GB                   | サーバー帯域に依存 |
| **S3 互換 API**    | 完全互換                         | 本家（S3 API の元祖） | 互換レイヤーあり           | 完全互換           |
| **CDN 統合**       | Cloudflare CDN（組み込み）       | CloudFront（別料金）  | Cloud CDN（別料金）        | 自前で構築         |
| **無料枠**         | 10GB ストレージ + 無制限エグレス | 5GB（12ヶ月）         | 5GB（12ヶ月）              | なし               |
| **運用負荷**       | ゼロ                             | 低い                  | 低い                       | 高い（自前運用）   |
| **リージョン**     | 自動分散                         | 選択制                | 選択制                     | 自前サーバーの場所 |
| **エコシステム**   | 成長中                           | 最大・最も成熟        | 大きい                     | コミュニティ       |

### 決定: Cloudflare R2

```
月間コスト比較（10GB ストレージ、100GB エグレスの場合）:

AWS S3:
  ストレージ: 10GB × $0.023 = $0.23
  エグレス:   100GB × $0.09 = $9.00
  合計: $9.23/月

Cloudflare R2:
  ストレージ: 10GB × $0.015 = $0.15
  エグレス:   100GB × $0.00 = $0.00  ← 無料！
  合計: $0.15/月

差額: $9.08/月（年間 $108.96 の節約）
```

動画や画像の配信が多い Argus では、エグレス無料は大きい。

**S3 互換 API がなぜ重要か**: R2 は AWS S3 と同じ API（プログラムからの操作方法）を提供している。つまり、AWS S3 用に書かれたプログラム（`@aws-sdk/client-s3` ライブラリ）が **そのまま R2 でも動く**。接続先の URL を S3 から R2 に変えるだけで移行が完了するため、移行コストがほぼゼロ。将来 R2 から S3 に戻したい場合も、URL を戻すだけで済む。

> **平たく言うと**: S3 互換とは「同じ形状のプラグ」を使っているということ。A社の充電器がB社のケーブルでも使えるように、R2 は S3 と同じ「差し込み口」を持っている。既存の道具（AWS SDK）をそのまま使い回せるので、わざわざ専用の道具を作り直す必要がない。

### この選定のメリット・デメリット

**メリット**:

- エグレス無料で動画配信コストが大幅に削減
- S3 互換 API で移行コストがゼロ
- Cloudflare CDN との統合で配信が高速

**デメリット・トレードオフ**:

- S3 と比べて一部の高度な機能（S3 Select, Glacier（超低コスト長期アーカイブストレージ。取り出しに数時間かかる）等）が未対応
- AWS エコシステムとの統合は S3 の方が深い
- Cloudflare に依存するベンダーロックインのリスク

**AWS S3 が適しているケース**:

- **AWS エコシステム全体を活用するプロジェクト** — EC2, Lambda, RDS, SQS 等の AWS サービスと深く統合する場合、S3 との連携（イベント通知、IAM（誰が何にアクセスできるかを管理するAWSの権限制御）ポリシー、VPC（クラウド上の仮想プライベートネットワーク）エンドポイント等）がシームレスに行える
- **S3 Select でサーバーサイドフィルタリングが必要** — S3 Select を使うと、オブジェクト全体をダウンロードせずに CSV/JSON/Parquet（大量データの分析に最適化された列指向ファイル形式）の中身を SQL でフィルタリングできる。大量のログ分析やデータ処理パイプラインで有用
- **Glacier で長期アーカイブが必要** — コンプライアンス要件や法的保持義務で、数年〜数十年のデータ保持が必要な場合。Glacier / Glacier Deep Archive は極めて低コストで長期保存できる
- **IAM / VPC との深い統合が必須** — AWS の IAM ポリシーでバケットレベル・オブジェクトレベルの細かいアクセス制御を行いたい場合や、VPC 内からのみアクセスを許可するエンドポイントポリシーが必要な場合

Argus ではこれらの高度な AWS 統合機能は不要であり、エグレス無料の R2 の方がコスト面で有利だった。

### 理解度チェック

- [ ] Q1: エグレスコストが重要な理由を説明できるか？
- [ ] Q2: S3 互換 API がなぜ重要かを説明できるか？
- [ ] Q3: どんなプロジェクトなら AWS S3 の方が適しているか？

---

## 13. 設計パターンと原則

> **平たく言うと**: ここでは、コードの書き方の「ルール」を紹介する。チームで開発するとき、全員が同じルールに従うことで、コードの品質が安定し、バグが減る。料理で言えば「レシピの書き方ルール」のようなもの。

### 13.1 例外を投げない規約

> **平たく言うと**: 通常のプログラミングでは、エラーが起きると「例外（Exception）」を投げて処理を中断する。しかしこの方法だと、誰もそのエラーを捕まえないとプログラム全体が止まってしまう。Argus では代わりに「成功/失敗のフラグ」を返す方式にして、エラーが起きてもプログラムが止まらないようにしている。家電で言えば「ブレーカーが落ちる」のではなく「赤ランプが点く」方式。

```typescript
// NG: throw する
async function query(prompt: string): Promise<AgentResult> {
  const result = await sdkQuery({ prompt, options });
  if (result.error) throw new Error(result.error); // ← これをしない
  return result;
}

// OK: success フラグで返す
async function query(prompt: string): Promise<AgentResult> {
  try {
    const stream = sdkQuery({ prompt, options });
    return await consumeSDKStream(stream);
  } catch (error) {
    return {
      message: {
        type: "assistant",
        content: [{ type: "text", text: error.message }],
        total_cost_usd: 0,
      },
      toolCalls: [],
      success: false, // ← フラグで通知
    };
  }
}
```

**理由**: Slack Bot のメッセージハンドラで未捕捉例外が発生すると、Socket Mode 接続が切れてボット全体が停止する。全ての関数が `{ success, data }` パターンで返せば、呼び出し側は必ず結果を処理できる。

**throw した場合の具体的な障害シナリオ**:

```
■ シナリオ1: 連鎖障害（1人のエラーが全員に影響）
  09:00 ユーザーAが「メールを確認して」と質問
  09:01 Gmail API がレート制限でエラーを返す
  09:01 → throw new Error("Gmail API rate limited")
  09:01 → メッセージハンドラが catch していない
  09:01 → 未捕捉例外でNode.jsプロセスがクラッシュ
  09:01 → Socket Mode のWebSocket接続が切断
  09:01 → ユーザーB, C, D（全く別の質問をしていた人たち）も全員切断
  09:01 → PM2が異常を検知してプロセスを再起動（5〜15秒）
  09:01 → 再起動中はBotが完全に無応答

■ シナリオ2: success:false 方式（Argusの実装）
  09:00 ユーザーAが「メールを確認して」と質問
  09:01 Gmail API がレート制限でエラーを返す
  09:01 → return { success: false, message: "Gmail APIの制限に達しました" }
  09:01 → ユーザーAに「メールの確認に失敗しました」とSlackで返答
  09:01 → ユーザーB, C, Dは何も影響なし。通常通り会話を続けられる
  09:01 → プロセスは健全に動き続ける
```

**success: boolean と throw の違いまとめ**:

| 比較軸                     | `throw` 方式                                 | `success: boolean` 方式                        |
| -------------------------- | -------------------------------------------- | ---------------------------------------------- |
| **エラー発生時の影響範囲** | 未捕捉ならプロセス全体がクラッシュ           | エラーを返した関数の呼び出し元だけに限定       |
| **エラー処理の強制力**     | try-catch を忘れてもコンパイルが通る（危険） | success を確認しないと型エラーにできる（安全） |
| **Go 言語の類似パターン**  | panic（Go でも使用を推奨されない）           | (result, error) パターン（Go の標準）          |

### 13.2 依存性逆転（DI）

> **平たく言うと**: 「依存性逆転」とは、部品 A が部品 B を直接使うのではなく、「こういう機能を持ったものなら何でもいい」という **仕様書（インターフェース）** だけを定義して、実際の部品は後から差し込む設計。コンセントのようなもので、「100V の電源なら何でも挿せる」仕組みにしておけば、テスト時にはダミー電源を挿せるし、将来別の電源に変えても本体を改造する必要がない。

```typescript
// packages/agent-core/src/observation-hooks.ts
// @argus/db に直接依存しない！

export interface ObservationDB {
  db: DrizzleInstance;      // 抽象インターフェース
  tables: {
    tasks: TaskTable;
    lessons: LessonTable;
  };
}

export function createDBObservationHooks(obsDB: ObservationDB): ArgusHooks {
  return {
    onPostToolUse: async ({ toolName, toolResult }) => {
      await obsDB.db.insert(obsDB.tables.tasks).values({ ... });
    },
  };
}
```

**消費側で注入**:

```typescript
// apps/slack-bot/src/...
import { db, tasks, lessons } from "@argus/db";
import { createDBObservationHooks } from "@argus/agent-core";

const hooks = createDBObservationHooks({ db, tables: { tasks, lessons } });
```

**利点**:

- `agent-core` は `@argus/db` の具体的なスキーマ定義に依存しない
- テスト時にモック DB を注入できる
- 将来 DB を変更しても `agent-core` は修正不要

**もし DI を採用しなかった場合の具体的な問題**:

```typescript
// NG例: agent-core が @argus/db を直接 import する
// packages/agent-core/src/observation-hooks.ts
import { db, tasks, lessons } from "@argus/db"; // ← 直接依存！

export function createDBObservationHooks(): ArgusHooks {
  return {
    onPostToolUse: async ({ toolName }) => {
      await db.insert(tasks).values({ ... }); // db を直接使用
    },
  };
}
```

この書き方だと以下の3つの問題が発生する。

1. **循環依存のリスク** — `agent-core → db` という依存が固定される。もし将来 `db` が `agent-core` の型を参照したくなったら、`db → agent-core → db` という循環依存が発生し、ビルドが通らなくなる。DI なら `agent-core` は **インターフェースだけ** を定義するので、循環が起きない

2. **テストが困難になる** — テスト時に本物のデータベースへの接続が必要になる。DI なら、テスト用のモック（偽物）DB を差し込むだけでテストできる

   ```typescript
   // DI ありの場合: テストが簡単
   const mockDB = { db: fakeDB, tables: { tasks: fakeTasksTable } };
   const hooks = createDBObservationHooks(mockDB); // モックを注入

   // DI なしの場合: 本物のDBが必要
   // → vi.mock("@argus/db") で強引にモックする必要がある
   // → モジュールモックは脆く、内部実装の変更でテストが壊れやすい
   ```

3. **packages の独立性が失われる** — `agent-core` が `@argus/db` の具体的なテーブル定義を知ってしまう。テーブル名を変更したら `agent-core` も修正が必要になる。DI なら、テーブル構造が変わっても `ObservationDB` インターフェースを満たしていれば `agent-core` の修正は不要

### 13.3 Lazy Proxy パターン（DB クライアント）

> **平たく言うと**: 「遅延初期化」とは、実際に使う瞬間まで準備を後回しにする仕組み。レストランで例えると、「お客さんが来てからコーヒーを淹れる」方式。開店準備（ビルド）の段階でコーヒーを淹れようとすると、まだ豆（DATABASE_URL）が届いていなくてエラーになる。Proxy（代理人）が間に立って、お客さんが来た時だけ豆を挽く。

```typescript
// packages/db/src/client.ts
let _db: DrizzleDB | null = null;

function getDB(): DrizzleDB {
  if (!_db) {
    const connectionString = process.env.DATABASE_URL;
    if (!connectionString) throw new Error("DATABASE_URL is required");
    const client = postgres(connectionString, {
      max: 10,
      idle_timeout: 20,
      connect_timeout: 10,
    });
    _db = drizzle(client);
  }
  return _db;
}

// Proxy で遅延初期化
export const db = new Proxy({} as DrizzleDB, {
  get(_, prop) {
    return Reflect.get(getDB(), prop);
  },
});
```

**なぜ Proxy か（`getDB()` 関数呼び出しではダメなのか）**:

遅延初期化だけなら `getDB()` 関数を用意して、使う側で `getDB().select(...)` と書いてもいい。しかし Argus では Proxy を採用している。その理由は **既存コードの変更が不要** だから。

```
■ getDB() 関数方式の場合:
  // 今まで: db.select(...) と書いていた全てのコードを...
  db.select().from(sessions).where(...)

  // こう書き換える必要がある（全ファイル）:
  getDB().select().from(sessions).where(...)
  // → 数十ファイル、数百箇所の修正が必要

■ Proxy 方式の場合（Argus の実装）:
  // 今まで通り db.select(...) と書ける。変更不要！
  db.select().from(sessions).where(...)
  // → Proxy が裏で getDB() を呼んでいるが、消費側は気付かない
  // → 0ファイル、0箇所の修正で済む
```

Proxy（JavaScript の言語機能で、オブジェクトへのアクセスを途中で捕捉して別の処理を挟み込む仕組み）を使うことで、**消費側のコードを一切変更せずに、遅延初期化を透過的に導入できる**。

**Lazy Proxy のメリット 3 つ**:

1. **ビルド時エラーの回避** — Next.js のビルド時（`next build`）に全モジュールが import される。DB クライアントが import 時に接続すると、ビルド環境に `DATABASE_URL` がないとビルドが失敗する。Proxy で遅延初期化すれば、実際に DB アクセスする時まで接続しない
2. **既存コードの変更不要** — 上記の通り、`db.select(...)` という既存のコードを一切変更せずに遅延初期化を導入できる
3. **接続のライフサイクル管理** — 接続は最初にDBアクセスした時に1回だけ作られ、以降は同じ接続が再利用される。不要な接続の乱立を防ぎ、DB の接続数制限（Supabase の無料枠では接続数に上限がある）を節約できる

### 13.4 フック耐障害性

```typescript
// Observation Hooks 内の全 DB 操作
onPostToolUse: async (event) => {
  try {
    await db.insert(tasks).values({ ... });
  } catch (error) {
    console.error("[observation] Failed to record task:", error);
    // ← throw しない。フックの失敗がメインの実行を止めない
  }
},
```

**なぜ観測データの欠損を許容するのか（ビジネス判断の根拠）**:

Argus のフック（Hooks）は「AI がどんなツールを使い、どんな結果が出たか」を記録する **観測（Observation）** の仕組み。この観測データは運用改善や分析に使うもので、**ユーザーへの応答に直接は使わない**。

```
■ もしフック内で throw していたら:
  ユーザー: 「明日の予定を教えて」
  → AI: Google Calendar を検索（成功）
  → フック: 「Calendar検索を実行した」をDBに記録しようとする
  → DB が一時的に過負荷でタイムアウト
  → throw new Error("DB insert timeout")
  → エージェント処理全体が中断
  → ユーザーには「エラーが発生しました」と表示される
  → 実は予定データはちゃんと取得できていたのに、ログ記録の失敗で応答できない

■ Argus の実装（throw しない）:
  ユーザー: 「明日の予定を教えて」
  → AI: Google Calendar を検索（成功）
  → フック: 「Calendar検索を実行した」をDBに記録しようとする
  → DB が一時的に過負荷でタイムアウト
  → console.error でログ出力して続行
  → ユーザーには「明日は10時に会議があります」と正常に応答
  → 観測データは1件欠損するが、ユーザー体験には影響なし
```

> **平たく言うと**: 防犯カメラの録画が一時的に止まったからといって、お店を閉めたりはしない。防犯カメラ（観測）は大事だが、お客さんへのサービス（応答）を止める理由にはならない。

**判断基準**: 「この処理が失敗したとき、ユーザーへの応答を止めるべきか？」。答えが No なら、try-catch で囲んで黙殺（ログ出力のみ）する。

### 13.5 理解度チェック

- [ ] Q1: `success: boolean` パターンと `throw` パターンの違いを 3 つ挙げられるか？（ヒント: 影響範囲、強制力、Go言語の類似パターン）
- [ ] Q2: DI（依存性逆転）を使わなかった場合に発生する問題を 3 つ挙げられるか？（ヒント: 循環依存、テスト、独立性）
- [ ] Q3: Lazy Proxy パターンのメリットを 3 つ挙げられるか？（ヒント: ビルド、既存コード、接続管理）
- [ ] Q4: フック内で throw しない理由を説明できるか？（ヒント: 観測 vs 応答の優先度）

---

## 14. 面接想定 Q&A

> 各回答には **技術者向け** と **噛み砕いた説明** の両方を用意している。技術面接ではそのまま使い、非エンジニアへの説明では噛み砕いた方を参考にしてほしい。

### Q1: 「なぜ MongoDB ではなく PostgreSQL を選んだのですか？」

**回答例**:

> データモデルがリレーショナルだったからです。セッション、メッセージ、ツール実行記録が外部キーで紐付いており、「あるセッションのメッセージとツール実行結果を一覧で取得」という JOIN が頻繁に発生します。また、Inbox Agent のタスクキューでは `FOR UPDATE SKIP LOCKED` を使った排他制御が必要で、PostgreSQL の ACID トランザクションが適していました。ホスティングは Supabase を使い、運用コストをほぼゼロに抑えています。

**噛み砕いた説明**: データ同士が「親子関係」や「参照関係」で繋がっているので、そういう関係を扱うのが得意な PostgreSQL を選んだ。MongoDB は「バラバラのメモを箱に入れる」のが得意だが、今回は「整理されたファイルキャビネット」が必要だった。

### Q2: 「Prisma ではなく Drizzle を選んだ理由は？」

**回答例**:

> 3つの理由があります。第一に、プロジェクトが完全 ESM で、Prisma は歴史的に CJS 前提のため ESM 環境でトラブルが起きやすかった。第二に、Docker の alpine イメージで Prisma の Rust バイナリの互換性問題を避けたかった。第三に、Drizzle は TypeScript の型推論をそのまま活用するので、`prisma generate` のようなコード生成ステップが不要です。SQL に近いクエリビルダーなので、Window 関数や CTE などの複雑なクエリも自然に書けます。

**噛み砕いた説明**: どちらも「プログラムからデータベースを操作する翻訳ツール」だが、Drizzle は軽量で、プロジェクトの技術方針（ESM）との相性が良く、本番環境への配置も簡単だった。Prisma は高機能だが重く、一部環境で動かない問題があった。

### Q3: 「Claude Agent SDK と Anthropic SDK の違いは？使い分けは？」

**回答例**:

> Anthropic SDK は API 呼び出し 1 回分の低レベルクライアントです。ツール実行ループ、セッション管理、パーミッション制御は全て自前で実装する必要があります。一方、Agent SDK は Claude Code のエンジンそのもので、ファイル読み書き、コマンド実行、MCP サーバー接続を含むエージェントループ全体を提供します。Argus では Agent SDK を採用し、`query()` の AsyncGenerator をストリーム消費する薄いラッパーを書いています。MCP サーバーの接続も `mcpServers` オプションに設定を渡すだけで完了するため、実装コストが大幅に下がりました。

**噛み砕いた説明**: Anthropic SDK は「AI に 1 回質問して 1 回答えをもらう電話」。Agent SDK は「AI に目標を伝えると、AI が自分でファイルを調べたりコマンドを実行したりして、最終結果を報告してくれる秘書」。Argus では秘書型（Agent SDK）を採用し、AI が自律的に作業できるようにした。

### Q4: 「なぜ REST API ではなく MCP でツールを実装したのですか？」

**回答例**:

> Agent SDK が MCP を標準サポート（追加ライブラリなしで使える）しているためです。REST API だと、エンドポイント定義、HTTP クライアント、エラーハンドリング、ツール定義の JSON Schema を全て自前で書く必要があります。MCP なら `server.tool()` で名前・説明・Zod スキーマを宣言するだけで、SDK が自動的にツールとして認識します。さらに、MCP サーバーは Claude Desktop など他のクライアントからも再利用できるため、Argus 専用にならない汎用性があります。

**噛み砕いた説明**: 「道具を AI に持たせる」方法として、従来の Web API ではなく MCP という標準規格を使った。USB のように「繋げば使える」ので、他のアプリからも同じ道具が使える。

### Q5: 「Vercel ではなく Railway を選んだ理由は？」

**回答例**:

> Slack Bot の Socket Mode が常時 WebSocket 接続を維持する常駐プロセスで、Vercel のサーバーレスモデルでは動かせません。Orchestrator も node-cron で定期実行する常駐プロセスです。Railway は Docker をそのままデプロイでき、PM2 で 3 プロセスを 1 つの VPS で管理できます。月額 $5 程度で全てをカバーでき、個人プロジェクトのコスト要件にも合致しました。

**噛み砕いた説明**: Vercel は「使った瞬間だけ電源が入るマシン」なので、24 時間ずっと動いていないといけない Slack Bot には使えない。Railway は「自分専用の常時稼働サーバー」を安く借りられるサービス。

### Q6: 「テストで Agent SDK をどうモックしていますか？」

**回答例**:

> SDK の `query()` は `AsyncGenerator<SDKMessage>` を返すので、テストでは `fakeStream()` というヘルパーで SDKMessage の配列を AsyncGenerator に変換してモックしています。system メッセージ、assistant メッセージ、result メッセージの 3 種類を適切な順序で yield するだけで、正常系・異常系を網羅できます。重要な注意点として、全メッセージの `session_id` を一致させる必要があります。result メッセージが最後に sessionId を上書きするためです。

**噛み砕いた説明**: テスト時に本物の AI を呼ぶとお金も時間もかかるので、「AI のフリをするダミー」（モック）を使う。ダミーは「初期化しました」「こう答えます」「完了しました」と台本通りに応答するだけ。これで、AI を呼ばずにプログラムの正しさを確認できる。

### Q7: 「このアーキテクチャのスケーラビリティの限界は？」

**回答例**:

> 現在の構成は単一 VPS + 単一 DB なので、同時接続数が数百を超えるとボトルネックになります。スケールアウトする場合、Socket Mode は複数インスタンスに接続するとラウンドロビン配信（メッセージを各サーバーに順番に振り分ける方式）されるため、ステートレス（サーバーが過去のリクエスト情報を保持しない設計）であれば水平スケール可能です。DB は Supabase の接続プーラー（pgBouncer）経由でアクセスしているので、アプリケーション側のスケールアウトには耐えられます。ただし、現在の用途（個人/インハウス、数人の利用者）では過剰な最適化は不要で、YAGNI の原則に従っています。

**噛み砕いた説明**: 今は「1 台のサーバー + 1 つのデータベース」で動いている。数人で使う分には十分だが、数百人が同時に使うと処理が追いつかなくなる。必要になったらサーバーを増やすことはできるが、今はまだその段階ではないので、必要になるまで複雑化させない（YAGNI = "You Ain't Gonna Need It" = 「今必要ないものは作らない」）。

### Q8: 「例外を throw せず success フラグで返す設計の理由は？」

**回答例**:

> Slack Bot のメッセージハンドラで未捕捉例外が発生すると、Socket Mode の WebSocket 接続が切れてボット全体が停止します。これを防ぐため、全ての公開関数が `{ success: boolean, ... }` パターンで結果を返す規約にしています。フック内部の DB 操作も try-catch で囲んで黙殺し、観測データの欠損はユーザー体験に影響しない設計です。Go 言語の `(result, error)` パターンに近い思想です。

**噛み砕いた説明**: エラーが起きた時に「プログラム全体がクラッシュする」のではなく、「エラーが起きましたよ、というフラグを返す」方式にしている。これにより、1 つの処理が失敗しても他の処理は続けられる。ブレーカーが落ちて家中停電するのではなく、その部屋だけ赤ランプが点く仕組み。

### Q9: 「pnpm の幽霊依存防止はどう役立っていますか？」

**回答例**:

> 12 パッケージのモノレポで、`drizzle-orm` は `@argus/db` と各アプリの両方で使われています。npm だとホイスティングにより、`package.json` に書いていないパッケージも import できてしまう幽霊依存が発生します。pnpm はシンボリックリンクで厳密に分離するため、`package.json` にない依存は import 時にエラーになります。CI で新しいパッケージを追加した際に「ローカルでは動くが CI で壊れる」という問題を未然に防いでいます。

**噛み砕いた説明**: 「隣の部屋の道具を勝手に借りて使っていた」状態を防ぐ仕組み。npm だと隣の部屋の道具がたまたま使えてしまうが、pnpm は「自分の持ち物リストにないものは使えない」ように厳密に管理する。これにより「自分の PC では動くけど本番環境では動かない」という事故を防げる。

### Q10: 「Max Plan と API キーの自動切り替えはどう実装していますか？」

**回答例**:

> `isMaxPlanAvailable()` 関数で、macOS かつ Claude CLI のバイナリが既知パスに存在するかを `fs.existsSync()` でチェックしています。`which` コマンドではなく直接パスチェックする理由は、子プロセスの PATH が親と異なる場合があるためです。Max Plan 利用時は環境変数から `ANTHROPIC_API_KEY` を除外して、SDK がローカルの Claude Code 経由で動作するよう強制します。Linux サーバーでは常に API キーモードにフォールバックし、モデルも Sonnet にしてコスト効率を優先します。

**噛み砕いた説明**: Argus は「開発者の Mac」でも「クラウドのサーバー」でも動く。Mac では Claude の月額プラン（Max Plan）をそのまま使い、サーバーでは従量課金の API キーを使う。どちらの環境かを自動判別し、それぞれに最適な設定に切り替える。携帯電話が Wi-Fi と 4G を自動切り替えするのと似たイメージ。

---

## 15. 用語集

エンジニアでない方にも伝わるよう、本ドキュメントで使われる主要な専門用語を解説する。

### インフラ・デプロイ関連

| 用語         | 読み方              | 説明                                                                                                                             |
| ------------ | ------------------- | -------------------------------------------------------------------------------------------------------------------------------- |
| **VPS**      | ブイピーエス        | Virtual Private Server。クラウド上に借りる自分専用のサーバー（仮想的なパソコン）                                                 |
| **Docker**   | ドッカー            | アプリケーションを「コンテナ」という箱に入れて、どの環境でも同じように動かせるようにする技術。引っ越し用のダンボール箱のイメージ |
| **PM2**      | ピーエムツー        | Node.js のプロセスマネージャ。プログラムが落ちたら自動で再起動してくれる「見守り役」                                             |
| **デプロイ** | —                   | プログラムを本番サーバーに配置して動かすこと。「お店をオープンする」に相当                                                       |
| **CI/CD**    | シーアイ/シーディー | Continuous Integration / Continuous Delivery。コードを変更するたびに自動でテスト・配置する仕組み                                 |
| **alpine**   | アルパイン          | Linux の超軽量版。Docker イメージを小さくするために使われる                                                                      |
| **エグレス** | —                   | サーバーからインターネットに出ていくデータ転送。多くのクラウドサービスで課金対象                                                 |
| **CDN**      | シーディーエヌ      | Content Delivery Network。世界中にコンテンツのコピーを配置して高速配信するネットワーク                                           |

### データベース関連

| 用語                 | 読み方                 | 説明                                                                                                                           |
| -------------------- | ---------------------- | ------------------------------------------------------------------------------------------------------------------------------ |
| **PostgreSQL**       | ポストグレスキューエル | オープンソースのリレーショナルデータベース。Excel の表のようにデータを整理して管理する                                         |
| **MongoDB**          | モンゴディービー       | ドキュメント型データベース。JSON（構造化テキスト）をそのまま保存できる。自由度が高いが、テーブル間の関連付けは苦手             |
| **ORM**              | オーアールエム         | Object-Relational Mapping。プログラムの言葉でデータベースを操作できる翻訳レイヤー                                              |
| **スキーマ**         | —                      | データの構造定義。「この表にはどんな列があるか」を定めたもの。設計図に相当                                                     |
| **マイグレーション** | —                      | データベースの構造を変更する作業。「テーブルに列を追加する」など                                                               |
| **JOIN**             | ジョイン               | 複数のテーブルのデータを結合して取得する SQL 操作                                                                              |
| **トランザクション** | —                      | 複数のデータ操作を「全部成功するか、全部なかったことにするか」のどちらかにまとめる仕組み。銀行送金のイメージ                   |
| **ACID**             | アシッド               | Atomicity（原子性）、Consistency（一貫性）、Isolation（分離性）、Durability（永続性）。トランザクションが満たすべき 4 つの性質 |
| **接続プーリング**   | —                      | DB との接続を使い回す仕組み。毎回新しく接続を作るより効率的。「シェアオフィスの共用デスク」のイメージ                          |

### プログラミング関連

| 用語                  | 読み方                 | 説明                                                                                            |
| --------------------- | ---------------------- | ----------------------------------------------------------------------------------------------- |
| **TypeScript**        | タイプスクリプト       | JavaScript に「型」（データの種類チェック）を追加した言語。書き間違いを実行前に検出できる       |
| **ESM**               | イーエスエム           | ECMAScript Modules。JavaScript の現代的なモジュール（ファイル分割）方式。`import/export` で書く |
| **CJS**               | シージェーエス         | CommonJS。JavaScript の旧来のモジュール方式。`require()` で書く。ESM が後継                     |
| **strict mode**       | ストリクトモード       | TypeScript の厳密チェックモード。型チェックをより厳しく行い、バグを未然に防ぐ                   |
| **型推論**            | かたすいろん           | プログラマが型を明示的に書かなくても、コンパイラが自動的に型を推測してくれる機能                |
| **AsyncGenerator**    | アシンクジェネレーター | データを「一度に全部」ではなく「少しずつ」返す非同期の仕組み。水道の蛇口から水が流れるイメージ  |
| **モック**            | —                      | テスト時に本物の代わりに使う「偽物」。本物の AI や DB を呼ばずにテストするために使う            |
| **依存性注入（DI）**  | ディーアイ             | 部品の具体的な実装を外部から差し込む設計パターン。テストしやすく、部品の交換が容易になる        |
| **例外（Exception）** | —                      | プログラムで予期しないエラーが発生した時に、通常の処理を中断して投げられるエラー信号            |

### AI・エージェント関連

| 用語               | 読み方         | 説明                                                                                                           |
| ------------------ | -------------- | -------------------------------------------------------------------------------------------------------------- |
| **SDK**            | エスディーケー | Software Development Kit。特定の機能を簡単に使うための開発道具箱                                               |
| **API**            | エーピーアイ   | Application Programming Interface。プログラム同士が通信するための「窓口」                                      |
| **Agent SDK**      | —              | Claude に自律的な作業をさせるための SDK。「1問1答」ではなく、AI が自分で判断してツールを使いながら作業を進める |
| **MCP**            | エムシーピー   | Model Context Protocol。AI に外部ツール（メール、カレンダー等）を使わせるための標準規格                        |
| **セッション**     | —              | 一連の会話のまとまり。Argus では Slack の 1 スレッド = 1 セッション                                            |
| **ストリーミング** | —              | データを一括ではなく、逐次的に送受信する方式。AI の応答がリアルタイムに流れてくるイメージ                      |
| **フック（Hook）** | —              | 特定のタイミングで自動的に実行される処理。「ツール実行の前後に自動でログを取る」など                           |
| **パーミッション** | —              | 権限。「ファイルの読み書きを許可するか」などの設定                                                             |
| **Max Plan**       | マックスプラン | Claude の月額定額プラン。API 従量課金と異なり、月額料金内で使い放題                                            |

### アーキテクチャ関連

| 用語                 | 読み方             | 説明                                                                                                                                                                             |
| -------------------- | ------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **モノレポ**         | —                  | Monorepo。複数のパッケージ・アプリを 1 つのリポジトリ（コード置き場）で管理する方式                                                                                              |
| **マイクロサービス** | —                  | 機能ごとに独立したサービスに分割するアーキテクチャ。対義語はモノリス（一枚岩）                                                                                                   |
| **サーバーレス**     | —                  | サーバーの管理が不要で、リクエストが来た時だけプログラムが動く方式。Vercel や AWS Lambda など                                                                                    |
| **Socket Mode**      | ソケットモード     | Slack Bot の通信方式の一つ。サーバーから Slack に常時接続を張り、メッセージを受け取る                                                                                            |
| **Webhook**          | ウェブフック       | イベント発生時に指定 URL に HTTP リクエストを送る仕組み。「何かあったら電話してね」方式                                                                                          |
| **WebSocket**        | ウェブソケット     | ブラウザとサーバー間で双方向のリアルタイム通信を行うための技術                                                                                                                   |
| **REST API**         | レストエーピーアイ | HTTP メソッド（GET, POST 等）でデータをやり取りする Web API の設計スタイル                                                                                                       |
| **YAGNI**            | ヤグニ             | "You Ain't Gonna Need It"（「それ、いらないよ」）。今必要ないものは作らない原則                                                                                                  |
| **ラッパー**         | —                  | 既存の機能を包み込んで、使いやすい別のインターフェースを提供するもの。「カバー」や「ケース」のイメージ                                                                           |
| **ネイティブ対応**   | —                  | ある機能が最初から組み込まれていて、追加のライブラリや設定なしでそのまま使えること。「後付け対応」の反対。例: 「ESM にネイティブ対応」＝ 最初から ESM で作られているので設定不要 |
| **ホイスティング**   | —                  | npm がライブラリを上の階層（ルートの node_modules）にまとめて配置する仕組み。これにより、本来使えないはずのライブラリが使えてしまう「幽霊依存」の原因になる                      |
| **ラウンドロビン**   | —                  | 複数のサーバーにリクエストを順番に振り分ける方式。A→B→C→A→B→C… のように均等に分配する                                                                                            |
| **ゼロトラスト**     | —                  | 「社内ネットワークだから安全」と信用せず、全てのアクセスに対して毎回本人確認する設計思想。従来の「社内は信用する」方式より安全                                                   |
| **ステートレス**     | —                  | サーバーが過去のリクエスト情報を保持しない設計。毎回のリクエストが独立しているので、サーバーを増やしてもどのサーバーが処理しても同じ結果になる                                   |
| **DSL**              | ディーエスエル     | Domain-Specific Language。特定の目的に特化した専用言語。Prisma の独自クエリ記法など                                                                                              |
| **ミドルウェア**     | —                  | リクエストとレスポンスの間に挟まって、認証・ログ・エラー処理などの共通処理を行う部品                                                                                             |
| **CORS**             | コルス             | Cross-Origin Resource Sharing。異なるドメイン間でデータをやり取りするための許可設定                                                                                              |
| **SSR**              | エスエスアール     | Server-Side Rendering。サーバー側で HTML を生成してからブラウザに送る方式                                                                                                        |
| **SSG**              | エスエスジー       | Static Site Generation。ビルド時にページの HTML を事前に生成しておく方式                                                                                                         |
| **SPA**              | エスピーエー       | Single Page Application。1 つの HTML ページでページ遷移せずに動くアプリケーション                                                                                                |

### ツール・サービス関連

| 用語              | 読み方                      | 説明                                                                              |
| ----------------- | --------------------------- | --------------------------------------------------------------------------------- |
| **Supabase**      | スパベース                  | PostgreSQL のマネージド（運用おまかせ）サービス。無料枠が大きく、個人開発に人気   |
| **Cloudflare R2** | クラウドフレア アールツー   | ファイルを保存するストレージサービス。AWS S3 互換だがデータ転送料が無料           |
| **Railway**       | レイルウェイ                | Docker コンテナをそのままデプロイできるクラウドサービス。Git push で自動デプロイ  |
| **Vitest**        | ヴィテスト                  | JavaScript/TypeScript のテストフレームワーク。高速で ESM に標準対応               |
| **Drizzle**       | ドリズル                    | TypeScript 向けの軽量 ORM。SQL に近い書き方ができ、型推論が強力                   |
| **Prisma**        | プリズマ                    | 人気の ORM だが、コード生成ステップが必要で、ESM 対応やバイナリサイズに課題がある |
| **Next.js**       | ネクストジェーエス          | React ベースの Web フレームワーク。サーバーサイドレンダリングや API Routes を提供 |
| **Tailwind CSS**  | テイルウィンド シーエスエス | HTML に直接スタイルを書けるユーティリティファーストの CSS フレームワーク          |

---

# Appendix A: ポートフォリオ戦略


**プロフィール**: 九工大情報工学卒(2025.3)、実務1年、TypeScript/Next.js/Claude Code/Firebase

---

## 募集要項の再精査結果

調査の結果、当初の想定より経験年数のハードルが高い企業が多い。

| 企業 | 実際の必須経験 | 実務1年で応募可能か |
|------|---------------|-------------------|
| **ラッコ** | 1年以上（明記） | **OK** |
| **エックスポイントワン** | 柔軟（年数不明確） | **OK** |
| **GameWith** | 年数不明確 | **挑戦可** |
| **コミューン** | 募集終了（シニア向け880万〜） | **NG** |
| **SmartHR** | HTML/CSS/JS 3年 + React 2年 | **NG** |
| **note** | 実務3年 + AI活用必須 | **ダメ元挑戦** |
| **ちゅらデータ** | 3年 + リード経験 | **NG** |
| **ミラティブ** | 2年以上 | **NG** |
| **TimeTree** | 非公開（Ruby on Rails中心） | **微妙** |
| **Nature** | Go + 1万人規模の開発経験 | **NG** |

現実的に今応募できるのは2〜3社。ポートフォリオで経験不足を補う戦略が重要。

---

## 結論: Argus をメインポートフォリオにする + 補強1つ

### なぜ Argus か

- 11パッケージ、899+テスト、Claude Agent SDK統合 → 実務1年とは思えない規模
- MCP サーバー設計、マルチエージェントシステム → AI駆動開発の実力証明として最強
- Next.js + TypeScript + Drizzle ORM + Supabase → 技術スタックが候補企業と合致
- 実際に運用されているプロダクト → 「動くものを作れる」証明

### 唯一の課題

- ラッコがAWS必須 → **AWS要素を補強する小さなサブプロジェクト1つ**を追加

---

## 作るべき成果物: 3つ

| # | 成果物 | 目的 | 期間目安 |
|---|--------|------|----------|
| 1 | **Argus を公開用に整備** | フルスタック力 + AI活用力の証明 | 2〜3週間 |
| 2 | **技術ブログ連載（Zenn）** | 思考プロセス + 学習速度の証明 | 週1記事 × 継続 |
| 3 | **GitHub Profile + ポートフォリオサイト** | 全体を繋ぐハブ | 1〜2週間 |

---

## 成果物1: Argus の公開整備

### やるべきこと

1. **公開用READMEの作成**
   - 「なぜ作ったか」（課題と動機）
   - アーキテクチャ図（Mermaid）
   - 技術選定の理由（なぜ Claude SDK か、なぜ Drizzle か、なぜ MCP か）
   - スクリーンショット / 動画デモ
   - テストカバレッジ情報

2. **機密情報の除去**
   - .env の完全除去確認
   - API キー・トークンの痕跡チェック
   - 個人的な Slack チャンネル ID 等のサニタイズ

3. **AWS 補強サブプロジェクト（1つ）**
   - 例: Argus の一部機能を AWS Lambda + API Gateway + DynamoDB で再実装
   - または: AWS ECS でのデプロイ構成を Terraform で記述
   - 目的: ラッコの「AWS を用いた Web アプリ開発経験」必須要件を満たす

### Argus が各社要件にどう刺さるか

| 要件 | Argus での証明 |
|------|---------------|
| TypeScript/React/Next.js | Dashboard (Next.js 16 + React 19) |
| AI/LLM活用 | Claude Agent SDK 統合、MCP サーバー設計 |
| テスト設計 | 899+ テスト、Vitest |
| CI/CD | GitHub Actions（推定） |
| DB設計 | Drizzle ORM + PostgreSQL スキーマ設計 |
| チーム開発 | monorepo 設計、パッケージ分離 |
| プロダクト思考 | 実際に運用、Slack Bot で日常利用 |

---

## 成果物2: 技術ブログ（Zenn連載）

### 5社が「技術発信」を歓迎スキルとして明記

- SmartHR: OSS公開・コントリビュート
- note: オープンソース活動・個人Webサービス
- ミラティブ: 勉強会登壇・技術書執筆
- Nature: OSS開発経験
- GameWith: GitHub活用文化

### 書くべき記事テーマ（優先順）

| # | テーマ | ターゲット企業 |
|---|--------|---------------|
| 1 | 「Claude Code でマルチエージェントシステムを開発した全記録」 | ラッコ、note |
| 2 | 「個人開発で 11パッケージ pnpm monorepo を設計した話」 | 全社 |
| 3 | 「AI駆動開発の CLAUDE.md 設計パターン」 | ラッコ、note |
| 4 | 「Claude Agent SDK で Slack Bot を作った話」 | ラッコ、note |
| 5 | 「TypeScript + Vitest でテスト戦略を設計した話（899テスト）」 | SmartHR、ちゅらデータ |
| 6 | 「MCP サーバーの設計と実装」 | 全社（AI活用アピール） |
| 7 | 「Firebase から Supabase + Drizzle に移行した話」 | 技術選定力アピール |
| 8 | 「実務1年で身についたこと・まだ足りないこと」 | 成長意欲アピール |

記事数の目安: 転職活動開始までに **5〜10本**。質 > 量。

---

## 成果物3: ポートフォリオサイト + GitHub Profile

### 技術選定: Astro（推奨）

理由: 静的コンテンツ中心のサイトに Next.js を選ぶと「なぜ？」と聞かれる → 技術選定の妥当性を示す

### 必須コンテンツ

1. 自己紹介（経歴、技術スタック、キャリアの方向性）
2. プロジェクト一覧（スクショ + 動画デモ + 技術選定理由 + GitHub + デプロイURL）
3. 技術スタック（習熟度付き）
4. Zenn記事へのリンク
5. 連絡先（GitHub, X, メール）

### GitHub Profile README の整備

- ピン留めリポジトリ（Argus + AWS サブプロジェクト）
- 技術スタックバッジ
- Zenn記事の自動更新

---

## 3ヶ月ロードマップ

| 期間 | やること |
|------|---------|
| **Month 1** | Argus の公開整備（README、機密除去、デモ動画）。週1でZenn記事開始。 |
| **Month 2** | AWS サブプロジェクト開発。ポートフォリオサイト構築。記事5本目標。 |
| **Month 3** | GitHub整備。ブログ総まとめ記事。**ラッコ・note・GameWith に応募開始。** |

---

## 各社が選考で重視するポイント

### ラッコ（最有力候補）
- AI活用を前向きに受け入れ、自ら学び、チームに展開できること
- 「人間ならではの価値ある判断や設計」に集中する姿勢
- フルリモートのテキストコミュニケーション能力
- **AWS を用いた Web アプリ開発経験**（必須）

### note（ダメ元挑戦枠）
- **生成AIツールやAIコーディングエディタを日常的に活用**（必須・希少な要件）
- オープンソース活動や個人でのウェブサービス開発の経験（歓迎）
- ミッション・ビジョン・バリューへの共感

### GameWith
- 数字を持って成果を説明することが求められる（面接口コミ）
- GitHub活用文化（採用リポジトリを公開）
- 「情熱では受からない、実績を持って臨むべき」（口コミ）

### エックスポイントワン
- paiza のコーディングテストあり → アルゴリズム対策必要
- DX推進への課題意識
- 顧客と真摯に向き合う姿勢

---

## AI駆動開発時代のポートフォリオ戦略

### AI活用は明確にプラス

2025年時点で57%の企業が採用面接時にAI活用経験を評価に含める（2024年の18.1%から3倍増）。

### 評価されるレベル

1. レベル1（差別化不可）: 「Copilotでコード補完しています」
2. レベル2（標準）: 「Claude Code / Cursorで効率的に開発しています」
3. レベル3（高評価）: 「AIを活用して、従来X時間かかっていた作業をY時間に短縮しました」
4. **レベル4（最高評価）: 「AIを活用したワークフローを設計し、チーム全体の生産性を向上させました」**

→ Argus の hooks 設計、CLAUDE.md、MCP サーバー設計はレベル4に該当。これを記事化すれば最強のアピール。

### 注意点

- 面接時にAIなしでコーディングできる基礎力は必須
- 「AIに書いてもらっただけ」と見なされないよう、技術的な理解の深さを別途証明する必要がある
- paiza 対策（エックスポイントワン）では純粋なアルゴリズム力が問われる

---

## 最も重要なポイント

**「何を作ったか」より「なぜ作ったか」「どう考えたか」を示す。**

Argus を見せる際のストーリー:
1. 「なぜ作ったか」→ AI エージェントの運用を自動化したかった
2. 「なぜ Claude SDK か」→ CLI ラッパーの限界を感じ、SDK に移行した判断
3. 「なぜ MCP か」→ エージェントのツール拡張を疎結合にしたかった
4. 「なぜ monorepo か」→ 依存関係の一元管理と型安全性の確保
5. 「なぜ 899テストか」→ エージェントの挙動の再現性と安全性の担保

---

*作成日: 2026年2月13日*
*情報源: 各社採用ページ、OpenWork、Green、Findy、Wantedly、転職ドラフト、Zenn、Qiita等*

---

# Appendix B: ベストプラクティス レポート


> 作成日: 2026-02-14
> 対象: Claude Code を活用したAI駆動開発ができるフルスタックエンジニア

---

## 1. エージェント vs 直接応募 vs リファラル

### 1-1. 転職エージェント

**メリット**

- 非公開求人へのアクセス（全求人の60-80%は非公開とされる）
- 書類添削・面接対策・年収交渉を代行してくれる
- 企業の内部情報（面接で聞かれること、社風など）を教えてもらえる
- 選考スケジュールの調整を一任できる
- **求職者側は完全無料**（企業が年収の30-35%を手数料として支払う）

**デメリット**

- エージェントの質にばらつきがある
- エージェントの売上目標に合わせて、必ずしも最適でない企業を勧められる可能性
- 企業側から見ると採用コストが高いため、同等スキルなら直接応募者を優先するケースも

**フルスタックエンジニアにとっての評価: ★★★★☆**

### 1-2. 直接応募（企業HP・採用ページ）

**メリット**

- 企業にとって採用コストが低いため、コスト面で有利に働くことがある
- 自分のペースで活動できる
- エージェント経由では扱わない企業にも応募可能

**デメリット**

- 書類選考の通過率が低くなりがち（推薦状がない）
- 年収交渉を自力で行う必要がある
- 企業の内部情報を得にくい

**フルスタックエンジニアにとっての評価: ★★★☆☆**

### 1-3. リファラル（社員紹介）

**メリット**

- 書類選考の通過率が圧倒的に高い
- 企業のリアルな内部情報を紹介者から直接聞ける
- 入社後の定着率が高い
- 紹介報酬（10万〜100万円程度）が紹介者に支払われることが多く、協力を得やすい

**デメリット**

- 自分の人脈に依存するため、選択肢が限られる
- 不採用の場合、紹介者との人間関係に配慮が必要

**フルスタックエンジニアにとっての評価: ★★★★★（最も合格率が高い）**

### 1-4. 推奨戦略（併用）

```
リファラル（最優先）
  + スカウト型サービス（Findy, LAPRAS, ビズリーチ）
  + IT/Web特化エージェント 1-2社
  + 総合型エージェント 1社
  = 合計 3-4 チャネルを並行運用
```

---

## 2. おすすめの転職エージェント・プラットフォーム

### 2-1. IT/Web エンジニア特化型エージェント（最も相性が良い）

| サービス                 | 特徴                                                       | 費用（求職者） |
| ------------------------ | ---------------------------------------------------------- | -------------- |
| **レバテックキャリア**   | IT特化最大手。5人に4人が年収UP。フルスタック向け求人が豊富 | 無料           |
| **Geekly（ギークリー）** | IT/Web/ゲーム特化。内定まで平均1ヶ月。スピード重視         | 無料           |
| **マイナビIT AGENT**     | 20-30代に強い。転職後年収74%UP実績。第二新卒にも手厚い     | 無料           |

> **なぜ「AI特化型エージェント」ではないのか？**
> AI特化型（Symbiorise等）はデータサイエンティストやMLエンジニア向け。
> 「AIを使って開発する」フルスタックエンジニアには、IT/Web特化型のほうが
> TypeScript/React/Next.js の求人が圧倒的に多く、マッチ精度が高い。

### 2-2. スカウト型プラットフォーム（特に推奨）

| サービス       | 特徴                                                                                                 | 費用（求職者） |
| -------------- | ---------------------------------------------------------------------------------------------------- | -------------- |
| **Findy**      | GitHubの開発履歴からスキルを可視化し、マッチする企業からスカウト。monorepo + 899テストが高評価になる | 無料           |
| **LAPRAS**     | GitHub, Qiita, Zenn, Twitter, Connpass の活動を自動収集してポートフォリオ生成                        | 無料           |
| **ビズリーチ** | ハイクラス転職。年収600万以上向け。プラチナスカウトは面接確約                                        | 無料プランあり |
| **Green**      | IT/Web業界特化。カジュアルな「気になる」機能。フルリモート検索しやすい                               | 無料           |
| **Wantedly**   | 「何をやるか」「なぜやるか」で企業を探す。カジュアル面談が活発                                       | 無料           |

### 2-3. 推奨登録順

1. **Findy** — GitHub（Argus プロジェクト）がそのまま武器になる
2. **LAPRAS** — Zenn 記事 + GitHub が自動的にポートフォリオ化される
3. **レバテックキャリア** — 年収交渉力が強く、フルスタック求人が豊富
4. **ビズリーチ** — ハイクラス案件のスカウトを受動的に受ける

---

## 3. 転職活動の進め方（フェーズ別）

### Phase 1: 準備期間（1-2ヶ月）

- 転職ドラフトやビズリーチで自分の市場価値（想定年収）を把握
- 企業のリストアップ（外資系、メガベンチャー、スタートアップの3カテゴリ）
- 技術スキルの棚卸し（Argus の成果を定量化）
- 「課題 → 解決 → 成果」の STAR 形式でエピソードを5つ以上用意
- GitHub 整備（README 充実、アーキテクチャ図、デモ動画）
- 職務経歴書作成 → エージェントに添削依頼

### Phase 2: 応募期間（1-2ヶ月）

- スカウト型サービス（Findy, LAPRAS, ビズリーチ）に登録してスカウトを待つ
- エージェント経由で 10-15 社に応募
- 志望度の低い企業から順に面接を受ける（練習戦略）
- カジュアル面談を積極的に活用

### Phase 3: 面接期間（1-2ヶ月）

- 各社の面接フェーズを並行して進める
- **内定のタイミングを揃える**のが年収交渉の最大のコツ
- 面接後は必ず振り返りメモを作成

### Phase 4: 内定・交渉期間（2-4週間）

- 複数オファーを比較検討
- オファー面談で年収交渉
- 現職への退職交渉（最低1ヶ月前、できれば2ヶ月前）

---

## 4. 練習用の企業選び戦略

### 基本方針

```
第1段階（練習）: 志望度 低 × 難易度 低 → 面接の基本所作、自己紹介の練度向上
第2段階（実戦練習）: 志望度 中 × 難易度 中 → 技術面接の経験値蓄積
第3段階（本命）: 志望度 高 × 難易度 高 → 準備万全の状態で臨む
```

### 練習企業の選び方

- SES企業の面接（難易度が低めで、面接形式に慣れるのに最適）
- 急成長中のスタートアップ（面接プロセスがカジュアル、フィードバックをもらいやすい）
- カジュアル面談を多数実施している企業（Wantedly で「気になる」を押す）

### 注意点

- 練習であっても手を抜かない（面接官のネットワークは狭い業界では繋がっている）
- 必ず面接後に改善点をメモする
- 練習企業で内定が出ても、承諾期限を延ばしてもらう交渉を練習する

---

## 5. ポートフォリオの見せ方

### GitHub（最大の武器）

| 要素       | 内容                                 | アピール方法                                   |
| ---------- | ------------------------------------ | ---------------------------------------------- |
| 規模       | 11パッケージ、899+ テスト            | README に badge で表示                         |
| 設計力     | pnpm monorepo 構成                   | アーキテクチャ図を README に掲載               |
| AI駆動開発 | Claude Code で開発フロー自体をAI化   | 「開発生産性を劇的に向上させた事例」として訴求 |
| 実用性     | Slack Bot、Gmail連携、TikTok自動投稿 | デモ動画を撮影して README にリンク             |
| 品質意識   | 899+ テスト                          | テストカバレッジの badge                       |

### 差別化ストーリー：「AIを使って開発できるフルスタックエンジニア」

> AIを「作る」エンジニアは多い。だが、AIを「使いこなして」開発プロセス自体を
> 変革できるエンジニアはまだ少ない。Claude Code / Agent SDK / MCP を使って
> 個人で11パッケージ・899テストの規模を実現したこと自体が、
> AI駆動開発の生産性を証明している。

面接でのキーメッセージ：

- 「AIを道具として使い、**チーム全体の開発速度を上げられる**エンジニアです」
- 「Claude Code のスキル・フック・MCPサーバーを設計し、開発ワークフローをAI化しました」
- 「個人で monorepo 11パッケージ・899テストを維持できているのは、AI駆動開発の成果です」

### Zenn 技術記事

- 公開済み3本がそのままアピール素材になる
- LAPRAS が自動的にポートフォリオに取り込む
- 記事が拡散されれば、リファラルの機会も増える

### デモ動画

- Slack Bot が実際に動いている様子（30秒〜1分）
- Deep Research 機能でレポートが生成される様子
- Loom や YouTube にアップロードして README からリンク

---

## 6. 年収交渉のコツ

### フルスタックエンジニアの市場相場（2025-2026年）

| カテゴリ                                                 | 年収レンジ                          |
| -------------------------------------------------------- | ----------------------------------- |
| フルスタック（経験1-2年、国内企業）                      | 400万〜600万円                      |
| フルスタック（経験3-5年、国内企業）                      | 550万〜800万円                      |
| メガベンチャー（LINEヤフー、サイバーエージェント等）     | 600万〜1,000万円                    |
| 外資系テック（Google、Amazon等）                         | 1,000万〜1,800万円+                 |
| スタートアップ（テックリード）                           | 700万〜1,200万円 + SO               |
| **AI駆動開発ができるフルスタック（希少価値プレミアム）** | **上記 +50万〜150万円の上乗せ余地** |

> **ポイント**: 「AIエンジニア」として年収交渉するのではなく、
> 「AI駆動開発で生産性が高いフルスタックエンジニア」として交渉する。
> AI活用を推進している企業ほど、このスキルに高い価値を感じる。

### 交渉の最大のコツ: 内定タイミングを揃える

```
A社 内定: 550万円
B社 内定: 600万円
C社 内定: 500万円（本命）

→ C社に「他社から600万円のオファーをいただいている。
   御社が第一志望なので、同水準まで検討いただけないか」と交渉
```

- 嘘はつかない
- エージェント経由だと選考スピードを調整しやすい
- 年収交渉はエージェントに任せるのが楽で効果的

---

## 7. 面接対策

### 技術面接 — コーディング

| サービス       | 特徴                                                  |
| -------------- | ----------------------------------------------------- |
| **LeetCode**   | 2,000問以上。企業ごとの出題傾向あり。外資系対策の定番 |
| **AtCoder**    | 日本語対応。緑レート（Rating 800+）を目指す           |
| **HackerRank** | 企業が実際のテストに利用                              |

**推奨学習プラン（3ヶ月）:**

```
月1: LeetCode Easy 50問（配列、文字列、ハッシュマップ中心）
月2: LeetCode Medium 30問（木、グラフ、DP中心）
月3: LeetCode Medium/Hard 20問 + AtCoder 週末コンテスト参加
```

### 技術面接 — システム設計（フルスタック向け）

聞かれやすいテーマ:

- リアルタイム通知機能のアーキテクチャ（WebSocket vs SSE vs ポーリング）
- 大規模SPAのパフォーマンス最適化（SSR/SSG/ISR の使い分け）
- マイクロサービス vs モノリスの設計判断
- CI/CD パイプラインの設計と自動テスト戦略
- APIレート制限・キャッシュ戦略の設計

**AI駆動開発に絡めて聞かれそうなテーマ:**

- チャットボットUIのストリーミングレスポンス設計
- LLM APIのコスト管理とキャッシュ戦略
- AI機能のフォールバック設計（API障害時にどうするか）

### 行動面接（STAR メソッド）

| 質問テーマ                               | 準備すべき内容                                                                 |
| ---------------------------------------- | ------------------------------------------------------------------------------ |
| 技術的に最も困難だった問題は？           | monorepo の依存関係管理、CLI → Agent SDK 移行                                  |
| チームの生産性を上げた経験は？           | Claude Code のスキル・フックで開発ワークフローを自動化                         |
| 失敗から学んだことは？                   | worktree + 未コミット変更での問題、Slack Bot 多重起動問題                      |
| なぜフルスタックエンジニアを目指すのか？ | フロント〜バックエンドまで一気通貫で作れることで、AI駆動開発の効果が最大化する |
| 5年後のキャリアビジョンは？              | AI駆動開発をチームに導入し、開発組織全体の生産性を変革するテックリード         |

---

## 即座にやること（1週間以内）

1. **Findy と LAPRAS に登録する**（GitHub と Zenn を連携）
2. **レバテックキャリアに登録**して初回面談で市場価値を確認
3. 職務経歴書を作成 → エージェントに添削依頼

## あなたの強みの整理

| 強み                                            | 市場での希少性                                       |
| ----------------------------------------------- | ---------------------------------------------------- |
| Claude Code を使ったAI駆動開発の実践経験        | **極めて高い**（まだ実務で使いこなせる人が少ない）   |
| MCP サーバー・スキル・フックの設計              | **高い**（開発ワークフロー自体をカスタマイズできる） |
| TypeScript + monorepo でのフルスタック開発      | **中〜高**                                           |
| 899+ テストによる品質管理                       | **中**（個人開発でこの規模は稀）                     |
| Next.js / React / Node.js / Firebase の実務経験 | **中**（需要は高いが母数も多い）                     |
| Zenn での技術発信                               | **中**                                               |

**差別化の核心**: 技術スタック自体は珍しくないが、
**「Claude Code でAI駆動開発ができる」という掛け合わせが希少**。
面接では常にこの切り口で語る。

---

## 参考情報ソース

- [ITエンジニアにおすすめの転職エージェント - すべらない転職](https://axxis.co.jp/magazine/)
- [レバテックキャリア](https://career.levtech.jp/)
- [Geekly](https://www.geekly.co.jp/)
- [コーディング面接対策 LeetCode 60問](https://1kohei1.com/leetcode/)
- [STARメソッド - Indeed Japan](https://jp.indeed.com/career-advice/interviewing/how-to-use-the-star-interview-response-technique)
- [LAPRAS - ITエンジニア採用プラットフォーム](https://scout.lapras.com/)
- [Findy - エンジニア向けスカウト](https://findy-code.io/)
